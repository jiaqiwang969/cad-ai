#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒè¯•æ ‘å½¢ç»“æ„æ„å»ºé—®é¢˜
"""

import json
import sys
sys.path.append('/Users/jqwang/50-çˆ¬è™«01')
from src.crawler.classification_optimized import OptimizedClassificationCrawler

def analyze_tree_structure():
    """åˆ†ææ ‘å½¢ç»“æ„é—®é¢˜"""
    
    # åŠ è½½test-06æ•°æ®
    with open('results/traceparts_classification_tree_full.json', 'r', encoding='utf-8') as f:
        test06_data = json.load(f)
    
    # è½¬æ¢æ ¼å¼
    records = [{'name': r['name'], 'url': r['url']} for r in test06_data['records']]
    print(f"ğŸ“Š Test-06æ€»è®°å½•æ•°: {len(records)}")
    
    # ä½¿ç”¨ä¿®å¤åçš„åˆ†ç±»å™¨æ„å»ºæ ‘
    crawler = OptimizedClassificationCrawler()
    root, leaves = crawler.build_classification_tree(records)
    
    print(f"ğŸŒ³ æ„å»ºçš„å¶èŠ‚ç‚¹æ•°: {len(leaves)}")
    print(f"ğŸ“‰ å·®å¼‚: {len(records) - len(leaves)}")
    
    # åˆ†ææ ‘ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹
    all_nodes = []
    def collect_nodes(node):
        if node.get('level', 0) > 1:  # æ’é™¤æ ¹èŠ‚ç‚¹
            all_nodes.append(node)
        for child in node.get('children', []):
            collect_nodes(child)
    
    collect_nodes(root)
    print(f"ğŸ”¢ æ ‘ä¸­æ€»èŠ‚ç‚¹æ•°: {len(all_nodes)}")
    
    # ç»Ÿè®¡å¶èŠ‚ç‚¹å’Œéå¶èŠ‚ç‚¹
    leaf_nodes = [n for n in all_nodes if n.get('is_leaf', False)]
    non_leaf_nodes = [n for n in all_nodes if not n.get('is_leaf', False)]
    
    print(f"ğŸŒ¿ å¶èŠ‚ç‚¹æ•°: {len(leaf_nodes)}")
    print(f"ğŸ—ï¸ éå¶èŠ‚ç‚¹æ•°: {len(non_leaf_nodes)}")
    
    # æ‰¾å‡ºtest-06ä¸­å­˜åœ¨ä½†åœ¨æ ‘ä¸­å˜æˆéå¶èŠ‚ç‚¹çš„è®°å½•
    test06_urls = set(r['url'] for r in records)
    tree_leaf_urls = set(n['url'] for n in leaf_nodes)
    tree_non_leaf_urls = set(n['url'] for n in non_leaf_nodes)
    
    # åœ¨test-06ä¸­æ˜¯è®°å½•ï¼Œä½†åœ¨æ ‘ä¸­å˜æˆäº†éå¶èŠ‚ç‚¹
    became_non_leaf = test06_urls & tree_non_leaf_urls
    print(f"\nğŸ“‹ åœ¨test-06ä¸­å­˜åœ¨ï¼Œä½†åœ¨æ ‘ä¸­å˜æˆéå¶èŠ‚ç‚¹çš„URLæ•°: {len(became_non_leaf)}")
    
    if became_non_leaf:
        print("å‰10ä¸ªå˜æˆéå¶èŠ‚ç‚¹çš„ä¾‹å­:")
        for i, url in enumerate(sorted(became_non_leaf)[:10]):
            # æ‰¾åˆ°å¯¹åº”çš„èŠ‚ç‚¹
            node = next((n for n in non_leaf_nodes if n['url'] == url), None)
            if node:
                child_count = len(node.get('children', []))
                print(f"  {i+1}. {node['name'][:50]}... (Level {node['level']}, {child_count} å­èŠ‚ç‚¹)")
                print(f"     Code: {node['code']}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„code
    codes = [n['code'] for n in all_nodes]
    duplicate_codes = set([code for code in codes if codes.count(code) > 1])
    if duplicate_codes:
        print(f"\nâš ï¸  å‘ç°é‡å¤çš„code: {len(duplicate_codes)}")
        for code in sorted(duplicate_codes)[:5]:
            nodes_with_code = [n for n in all_nodes if n['code'] == code]
            print(f"  Code '{code}' å‡ºç° {len(nodes_with_code)} æ¬¡:")
            for node in nodes_with_code:
                print(f"    - {node['name'][:30]}... (Level {node['level']})")
    
    return root, leaves, all_nodes

if __name__ == "__main__":
    analyze_tree_structure()