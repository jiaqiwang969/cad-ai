#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TraceParts å…¨æµç¨‹ä¸€é”®æŠ“å–è„šæœ¬
========================================================
æœ¬è„šæœ¬é›†æˆä¹‹å‰çš„æ‰€æœ‰æ­¥éª¤ï¼š
1. test/06-test_classification_tree_recursive.py  â€”â€” æŠ“å–å®Œæ•´åˆ†ç±»æ‰å¹³æ ‘
2. test/07-test_classification_tree_nested.py    â€”â€” ç”ŸæˆåµŒå¥—æ ‘å¹¶è¾“å‡ºå¶èŠ‚ç‚¹åˆ—è¡¨
3. test/09-test_batch_leaf_product_links.py      â€”â€” æ‰¹é‡æŠ“å–æ¯ä¸ªå¶èŠ‚ç‚¹çš„äº§å“è¯¦æƒ…é¡µé“¾æ¥
4. test/09-1-test_product_specifications_extractor.py â€”â€” æå–å•ä¸ªäº§å“çš„æ‰€æœ‰è§„æ ¼

æœ€ç»ˆç”Ÿæˆä¸€ä¸ª JSONï¼šresults/traceparts_full_data_<timestamp>.json
ç»“æ„ç¤ºä¾‹ï¼š
{
  "generated": "2025-06-01T12:00:00",
  "root": {              # åµŒå¥—åˆ†ç±»æ ‘ï¼ˆå« children / is_leafï¼‰
     ...
  },
  "leaves": [
     {
       "name": "Bearings",
       "code": "TP01002002006",
       "url": "...",
       "products": [
           {
              "product_url": "...&Product=90-31032023-039178",
              "product_id": "90-31032023-039178",
              "specifications": [
                  {"reference": "TXCE-H1-6-1515-L100", ...},
                  ...
              ]
           },
           ...
       ]
     },
     ...
  ]
}

è¿è¡Œï¼š
$ python pipeline_traceparts_allinone.py --workers 12
"""

import os
import json
import time
import logging
import argparse
import subprocess
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from urllib.parse import urlparse, parse_qs

# -------- é…ç½®æ—¥å¿— -------- #
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
LOG = logging.getLogger("allinone")

# ç›®å½•å¸¸é‡
RESULTS_DIR = Path("results")
PRODUCTS_DIR = RESULTS_DIR / "products"
PRODUCTS_DIR.mkdir(parents=True, exist_ok=True)

# -------- ä¾èµ–è„šæœ¬è·¯å¾„ -------- #
TEST06 = Path("test/06-test_classification_tree_recursive.py")
TEST07 = Path("test/07-test_classification_tree_nested.py")
TEST09 = Path("test/09-test_batch_leaf_product_links.py")
TEST09_1 = Path("test/09-1-test_product_specifications_extractor.py")

# -------- è¾…åŠ©å‡½æ•° -------- #

def run_subprocess(cmd: str):
    """è¿è¡Œå­è¿›ç¨‹å¹¶å®æ—¶è¾“å‡º"""
    LOG.info(f"âš™ï¸ è¿è¡Œå‘½ä»¤: {cmd}")
    proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    for line in proc.stdout:
        print(line.rstrip())
    proc.wait()
    if proc.returncode != 0:
        raise RuntimeError(f"å‘½ä»¤å¤±è´¥: {cmd}")

# -------- æ­¥éª¤ 1 & 2: åˆ†ç±»æ ‘ & å¶èŠ‚ç‚¹ -------- #

def ensure_classification_tree():
    """ç¡®ä¿å·²ç”ŸæˆåµŒå¥—æ ‘å’Œå¶èŠ‚ç‚¹æ–‡ä»¶"""
    leaves_file = RESULTS_DIR / "traceparts_tree_leaves.jsonl"
    if leaves_file.exists():
        LOG.info("âœ… å·²å­˜åœ¨å¶èŠ‚ç‚¹æ–‡ä»¶ï¼Œè·³è¿‡æ ‘æŠ“å–")
        return leaves_file

    # è¿è¡Œ test-06
    run_subprocess(f"python {TEST06}")
    # è¿è¡Œ test-07
    run_subprocess(f"python {TEST07}")

    if not leaves_file.exists():
        raise FileNotFoundError("å¶èŠ‚ç‚¹æ–‡ä»¶ç”Ÿæˆå¤±è´¥ï¼")
    return leaves_file

# -------- æ­¥éª¤ 3: å¶èŠ‚ç‚¹ -> äº§å“é“¾æ¥ -------- #

def ensure_product_links(leaves_file: Path, workers: int):
    """æ‰¹é‡æŠ“å–æ‰€æœ‰å¶èŠ‚ç‚¹çš„äº§å“é“¾æ¥"""
    run_subprocess(f"python {TEST09} --leaves {leaves_file} --workers {workers}")

# -------- æ­¥éª¤ 4: äº§å“ -> è§„æ ¼ -------- #
# å¤ç”¨ test-09-1 ä¸­çš„å‡½æ•°
import importlib.util
spec = importlib.util.spec_from_file_location("tp_spec", TEST09_1)
TP_SPEC = importlib.util.module_from_spec(spec)
spec.loader.exec_module(TP_SPEC)  # type: ignore


def extract_specs_for_product(product_url: str) -> dict:
    """ä½¿ç”¨å·²æœ‰å‡½æ•°æå–äº§å“è§„æ ¼ï¼Œè¿”å› dict {product_url, product_id, specifications}"""
    try:
        base_info = TP_SPEC.extract_base_product_info(product_url)
        driver = TP_SPEC.prepare_driver()
        try:
            driver.get(product_url)
            time.sleep(2)
            specs = TP_SPEC.extract_all_product_specifications(driver)
            if not specs:
                LOG.warning(f"âš ï¸ è§„æ ¼ä¸ºç©º: {product_url}")
            return {
                "product_url": product_url,
                "product_id": base_info.get("product_id", "UNKNOWN") if base_info else "UNKNOWN",
                "specifications": specs
            }
        finally:
            driver.quit()
    except Exception as e:
        LOG.error(f"âŒ æå–è§„æ ¼å¤±è´¥: {e}")
        return {
            "product_url": product_url,
            "error": str(e),
            "specifications": []
        }

# -------- ä¸»æµç¨‹ -------- #

def main(workers: int = 8):
    LOG.info("ğŸš€ TraceParts å…¨æµç¨‹æŠ“å–å¼€å§‹")
    leaves_file = ensure_classification_tree()

    # è¯»å–å¶èŠ‚ç‚¹åˆ—è¡¨
    leaves = []
    with open(leaves_file, 'r', encoding='utf-8') as f:
        for line in f:
            leaves.append(json.loads(line))
    LOG.info(f"ğŸ“„ å¶èŠ‚ç‚¹æ•°é‡: {len(leaves)}")

    # æŠ“å–äº§å“åˆ—è¡¨
    ensure_product_links(leaves_file, workers)

    # èšåˆäº§å“åˆ—è¡¨æ•°æ®
    leaf_code_to_links = {}
    for file in PRODUCTS_DIR.glob("product_links_*.json"):
        try:
            data = json.loads(file.read_text())
            leaf_code_to_links[data.get('tp_code')] = data.get('links', [])
        except Exception:
            continue

    # å¹¶å‘æå–äº§å“è§„æ ¼
    final_leaves = []
    with ThreadPoolExecutor(max_workers=workers) as executor:
        future_to_leaf = {}
        for leaf in leaves:
            code = leaf.get('code')
            prod_links = leaf_code_to_links.get(code, [])
            leaf_info = {
                "name": leaf.get('name'),
                "code": code,
                "url": leaf.get('url'),
                "products": []
            }
            if not prod_links:
                final_leaves.append(leaf_info)
                continue
            # é’ˆå¯¹å½“å‰ leaf ä¸­çš„æ‰€æœ‰ product é“¾æ¥æäº¤ä»»åŠ¡
            futures = [executor.submit(extract_specs_for_product, url) for url in prod_links]
            for fut in as_completed(futures):
                leaf_info['products'].append(fut.result())
            final_leaves.append(leaf_info)

    # è¯»å–åµŒå¥—æ ‘æ ¹
    nested_file = RESULTS_DIR / "traceparts_tree_nested.json"
    with open(nested_file, 'r', encoding='utf-8') as f:
        nested_data = json.load(f)
    root = nested_data.get('root')

    # è¾“å‡ºæœ€ç»ˆ JSON
    timestamp = int(time.time())
    out_file = RESULTS_DIR / f"traceparts_full_data_{timestamp}.json"
    with open(out_file, 'w', encoding='utf-8') as f:
        json.dump({
            "generated": time.strftime('%Y-%m-%dT%H:%M:%S'),
            "root": root,
            "leaves": final_leaves
        }, f, ensure_ascii=False, indent=2)

    LOG.info(f"âœ… å…¨éƒ¨å®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶: {out_file.resolve()}")
    print("âœ… pipeline_allinone æˆåŠŸ")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="TraceParts å…¨æµç¨‹æŠ“å–")
    parser.add_argument('--workers', type=int, default=8, help='å¹¶å‘çº¿ç¨‹æ•° (é»˜è®¤ 8)')
    args = parser.parse_args()
    main(workers=args.workers) 