#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TraceParts æ¸è¿›å¼ç¼“å­˜ç®¡ç†å™¨
==========================
æ”¯æŒä¸‰é˜¶æ®µç¼“å­˜æ„å»ºï¼š
1. åˆ†ç±»æ ‘
2. äº§å“é“¾æ¥
3. äº§å“è§„æ ¼
"""

import argparse
from src.pipelines.cache_manager import CacheManager, CacheLevel
import logging
import json
from pathlib import Path


def main():
    parser = argparse.ArgumentParser(description='TraceParts æ¸è¿›å¼ç¼“å­˜ç®¡ç†')
    
    # ç¼“å­˜çº§åˆ«é€‰æ‹©
    parser.add_argument(
        '--level', 
        type=str, 
        choices=['classification', 'products', 'specifications'],
        default='specifications',
        help='ç›®æ ‡ç¼“å­˜çº§åˆ« (é»˜è®¤: specifications)'
    )
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--workers', type=int, default=16, help='æœ€å¤§å¹¶å‘æ•° (é»˜è®¤: 16)')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶åˆ·æ–°æ‰€æœ‰ç¼“å­˜')
    parser.add_argument('--cache-dir', type=str, default='results/cache', help='ç¼“å­˜ç›®å½•')
    
    # æ–°å¢ï¼šçŠ¶æ€å’Œå†å²æŸ¥çœ‹åŠŸèƒ½
    parser.add_argument('--status', action='store_true', help='æ˜¾ç¤ºç¼“å­˜çŠ¶æ€ä¿¡æ¯')
    parser.add_argument('--history', action='store_true', help='æ˜¾ç¤ºç‰ˆæœ¬å†å²è®°å½•')
    parser.add_argument('--cleanup', action='store_true', help='æ¸…ç†æ—§ç‰ˆæœ¬æ–‡ä»¶')
    parser.add_argument('--errors', action='store_true', help='æ˜¾ç¤ºæœ€æ–°çš„é”™è¯¯æ—¥å¿—')
    
    args = parser.parse_args()
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s',
        handlers=[
            logging.StreamHandler()
        ]
    )
    
    # å‡å°‘å…¶ä»–æ¨¡å—çš„æ—¥å¿—å™ªéŸ³
    logging.getLogger('selenium').setLevel(logging.WARNING)
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    
    try:
        # åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
        cache_manager = CacheManager(
            cache_dir=args.cache_dir,
            max_workers=args.workers
        )
        
        # å¤„ç†çŠ¶æ€æŸ¥çœ‹è¯·æ±‚
        if args.status:
            print("\n" + "="*60)
            print("ğŸ“Š ç¼“å­˜çŠ¶æ€ä¿¡æ¯")
            print("="*60)
            
            status = cache_manager.get_cache_status()
            print(f"ğŸ“ ç¼“å­˜ç›®å½•: {status['cache_directory']}")
            print(f"ğŸ“ˆ å½“å‰çº§åˆ«: {status['current_level']}")
            
            if status['latest_files']:
                print("\nğŸ“„ æœ€æ–°ç¼“å­˜æ–‡ä»¶:")
                for level, filename in status['latest_files'].items():
                    size = status['file_sizes'].get(level, 'N/A')
                    print(f"   â€¢ {level.upper()}: {filename} ({size})")
            
            if status['metadata']:
                metadata = status['metadata']
                print(f"\nğŸ·ï¸ å…ƒæ•°æ®ä¿¡æ¯:")
                print(f"   â€¢ ç‰ˆæœ¬: {metadata.get('version', 'N/A')}")
                print(f"   â€¢ ç”Ÿæˆæ—¶é—´: {metadata.get('generated', 'N/A')}")
                print(f"   â€¢ å¶èŠ‚ç‚¹æ•°: {metadata.get('total_leaves', 0)}")
                print(f"   â€¢ äº§å“æ€»æ•°: {metadata.get('total_products', 0)}")
                print(f"   â€¢ è§„æ ¼æ€»æ•°: {metadata.get('total_specifications', 0)}")
            
            print("="*60)
            return
        
        # å¤„ç†å†å²æŸ¥çœ‹è¯·æ±‚
        if args.history:
            print("\n" + "="*60)
            print("ğŸ“‹ ç‰ˆæœ¬å†å²è®°å½•")
            print("="*60)
            
            history = cache_manager.get_version_history()
            if not history:
                print("æš‚æ— ç‰ˆæœ¬å†å²è®°å½•")
                return
            
            for record in history[:10]:  # åªæ˜¾ç¤ºæœ€è¿‘10ä¸ªç‰ˆæœ¬
                level = record.get('level', 'UNKNOWN')
                version = record.get('version', 'N/A')
                timestamp = record.get('timestamp', 'N/A')
                filename = record.get('filename', 'N/A')
                
                if timestamp != 'N/A':
                    try:
                        from datetime import datetime
                        dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                        timestamp = dt.strftime('%Y-%m-%d %H:%M:%S')
                    except:
                        pass
                
                print(f"ğŸ”¸ [{level}] {version} - {timestamp}")
                print(f"   æ–‡ä»¶: {filename}")
                print()
            
            print("="*60)
            return
        
        # å¤„ç†æ¸…ç†è¯·æ±‚
        if args.cleanup:
            print("\nğŸ§¹ å¼€å§‹æ¸…ç†æ—§ç‰ˆæœ¬æ–‡ä»¶...")
            
            for level in [CacheLevel.CLASSIFICATION, CacheLevel.PRODUCTS, CacheLevel.SPECIFICATIONS]:
                cache_manager._cleanup_old_versions(level, keep_versions=3)
            
            print("âœ… æ¸…ç†å®Œæˆï¼")
            return
        
        # å¤„ç†é”™è¯¯æ—¥å¿—æŸ¥çœ‹è¯·æ±‚
        if args.errors:
            print("\n" + "="*60)
            print("ğŸš¨ é”™è¯¯æ—¥å¿—æŸ¥çœ‹")
            print("="*60)
            
            error_logs_dir = Path(args.cache_dir) / 'error_logs'
            if not error_logs_dir.exists():
                print("æš‚æ— é”™è¯¯æ—¥å¿—ç›®å½•")
                return
            
            # æŸ¥æ‰¾æœ€æ–°çš„é”™è¯¯æ—¥å¿—æ–‡ä»¶
            error_files = list(error_logs_dir.glob('error_log_v*.json'))
            if not error_files:
                print("æš‚æ— é”™è¯¯æ—¥å¿—æ–‡ä»¶")
                return
            
            # é€‰æ‹©æœ€æ–°çš„é”™è¯¯æ—¥å¿—
            latest_error_file = max(error_files, key=lambda x: x.stat().st_mtime)
            
            try:
                with open(latest_error_file, 'r', encoding='utf-8') as f:
                    error_data = json.load(f)
                
                print(f"ğŸ“„ é”™è¯¯æ—¥å¿—æ–‡ä»¶: {latest_error_file.name}")
                print(f"ğŸ• ç”Ÿæˆæ—¶é—´: {error_data.get('generated', 'N/A')}")
                print(f"ğŸ“Œ ç‰ˆæœ¬: {error_data.get('version', 'N/A')}")
                
                summary = error_data.get('summary', {})
                print(f"\nğŸ“Š é”™è¯¯ç»Ÿè®¡:")
                print(f"   â€¢ äº§å“é“¾æ¥å¤±è´¥: {summary.get('total_product_errors', 0)} ä¸ª")
                print(f"   â€¢ è§„æ ¼çˆ¬å–å¤±è´¥: {summary.get('total_specification_errors', 0)} ä¸ª")
                print(f"   â€¢ é›¶è§„æ ¼äº§å“: {summary.get('zero_specs_count', 0)} ä¸ª")
                print(f"   â€¢ å¼‚å¸¸æ•°é‡: {summary.get('exception_count', 0)} ä¸ª")
                
                # æ˜¾ç¤ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                details = error_data.get('details', {})
                
                if details.get('products'):
                    print(f"\nğŸ”´ äº§å“é“¾æ¥é”™è¯¯:")
                    for i, error in enumerate(details['products'][:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                        print(f"   {i}. [{error.get('error_type', 'unknown')}] {error.get('leaf_code', 'N/A')}")
                        print(f"      URL: {error.get('leaf_url', 'N/A')}")
                        if 'exception' in error:
                            print(f"      é”™è¯¯: {error['exception']}")
                        print()
                    
                    if len(details['products']) > 5:
                        print(f"   ... è¿˜æœ‰ {len(details['products']) - 5} ä¸ªé”™è¯¯è®°å½•")
                
                if details.get('specifications'):
                    print(f"\nğŸ”´ äº§å“è§„æ ¼é”™è¯¯:")
                    for i, error in enumerate(details['specifications'][:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                        print(f"   {i}. [{error.get('error_type', 'unknown')}] è§„æ ¼æ•°: {error.get('spec_count', 0)}")
                        print(f"      URL: {error.get('product_url', 'N/A')}")
                        if 'exception' in error:
                            print(f"      é”™è¯¯: {error['exception']}")
                        print()
                    
                    if len(details['specifications']) > 5:
                        print(f"   ... è¿˜æœ‰ {len(details['specifications']) - 5} ä¸ªé”™è¯¯è®°å½•")
                
            except Exception as e:
                print(f"è¯»å–é”™è¯¯æ—¥å¿—å¤±è´¥: {e}")
            
            print("="*60)
            return
        
        # è·å–ç›®æ ‡çº§åˆ«
        target_level_map = {
            'classification': CacheLevel.CLASSIFICATION,
            'products': CacheLevel.PRODUCTS,
            'specifications': CacheLevel.SPECIFICATIONS
        }
        target_level = target_level_map[args.level]
        
        # è¿è¡Œæ¸è¿›å¼ç¼“å­˜
        cache_manager.run_progressive_cache(
            target_level=target_level,
            force_refresh=args.force
        )
    except Exception as e:
        print(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == '__main__':
    main() 