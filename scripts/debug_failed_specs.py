#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤±è´¥è§„æ ¼è°ƒè¯•å·¥å…·
=============
ä¸“é—¨è°ƒè¯• failed_specs.jsonl ä¸­çš„å¤±è´¥æ¡ˆä¾‹
"""

import sys
import json
import logging
import time
from pathlib import Path
from typing import List, Dict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.crawler.specifications_optimized import OptimizedSpecificationsCrawler

def load_failed_specs(failed_specs_file: Path) -> List[Dict]:
    """åŠ è½½å¤±è´¥çš„è§„æ ¼è®°å½•"""
    failed_records = []
    
    if not failed_specs_file.exists():
        print(f"âŒ å¤±è´¥è®°å½•æ–‡ä»¶ä¸å­˜åœ¨: {failed_specs_file}")
        return failed_records
    
    with open(failed_specs_file, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                record = json.loads(line.strip())
                failed_records.append(record)
            except:
                continue
    
    return failed_records

def analyze_failed_specs(failed_records: List[Dict]):
    """åˆ†æå¤±è´¥è®°å½•"""
    print(f"ğŸ“Š å¤±è´¥è®°å½•åˆ†æ:")
    print(f"   â€¢ æ€»å¤±è´¥è®°å½•: {len(failed_records)}")
    
    # æŒ‰å¤±è´¥åŸå› åˆ†ç»„
    reasons = {}
    for record in failed_records:
        reason = record.get('reason', 'Unknown')
        if reason not in reasons:
            reasons[reason] = []
        reasons[reason].append(record)
    
    print(f"\nğŸ” å¤±è´¥åŸå› åˆ†å¸ƒ:")
    for reason, records in sorted(reasons.items(), key=lambda x: len(x[1]), reverse=True):
        print(f"   â€¢ {reason}: {len(records)} ä¸ª")
    
    # æŒ‰ä¾›åº”å•†åˆ†æ
    print(f"\nğŸ­ ä¾›åº”å•†åˆ†æ:")
    vendors = {}
    for record in failed_records:
        url = record.get('url', '')
        if 'industrietechnik' in url.lower():
            vendor = 'industrietechnik'
        elif 'apostoli' in url.lower():
            vendor = 'apostoli'
        elif 'skf' in url.lower():
            vendor = 'skf'
        elif 'timken' in url.lower():
            vendor = 'timken'
        elif 'traceparts-site' in url.lower():
            vendor = 'traceparts'
        else:
            vendor = 'other'
        
        if vendor not in vendors:
            vendors[vendor] = []
        vendors[vendor].append(record)
    
    for vendor, records in sorted(vendors.items(), key=lambda x: len(x[1]), reverse=True):
        print(f"   â€¢ {vendor}: {len(records)} ä¸ª")
    
    return reasons, vendors

def debug_specific_urls(urls: List[str], max_debug: int = 5):
    """è°ƒè¯•å…·ä½“çš„å¤±è´¥URL"""
    print(f"\nğŸ” å¼€å§‹è°ƒè¯•å…·ä½“URL (æœ€å¤š {max_debug} ä¸ª):")
    print("=" * 60)
    
    # åˆ›å»ºè§„æ ¼çˆ¬å–å™¨ï¼ˆä½¿ç”¨æ›´è¯¦ç»†çš„æ—¥å¿—ï¼‰
    crawler = OptimizedSpecificationsCrawler(log_level=logging.DEBUG)
    
    results = []
    for i, url in enumerate(urls[:max_debug]):
        print(f"\n[{i+1}/{min(max_debug, len(urls))}] è°ƒè¯•URL:")
        print(f"ğŸ”— {url}")
        print("-" * 60)
        
        try:
            # å°è¯•æå–è§„æ ¼
            start_time = time.time()
            result = crawler.extract_specifications(url)
            elapsed = time.time() - start_time
            
            print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}s")
            print(f"âœ… æˆåŠŸ: {result.get('success', False)}")
            print(f"ğŸ“‹ è§„æ ¼æ•°: {result.get('count', 0)}")
            
            if result.get('success') and result.get('count', 0) > 0:
                print(f"ğŸ‰ æˆåŠŸæå–åˆ°è§„æ ¼ï¼")
                specs = result.get('specifications', [])
                if specs:
                    print(f"ğŸ“„ è§„æ ¼ç¤ºä¾‹: {specs[0] if isinstance(specs[0], dict) else str(specs[0])[:100]}")
            else:
                print(f"âŒ æå–å¤±è´¥")
                if 'error' in result:
                    print(f"ğŸš¨ é”™è¯¯ä¿¡æ¯: {result['error']}")
            
            results.append({
                'url': url,
                'result': result,
                'elapsed': elapsed
            })
            
        except Exception as e:
            print(f"ğŸ’¥ å¼‚å¸¸: {e}")
            results.append({
                'url': url,
                'result': {'success': False, 'error': str(e)},
                'elapsed': 0
            })
        
        # é—´éš”ä¸€ä¸‹é¿å…è¢«æ£€æµ‹
        if i < min(max_debug, len(urls)) - 1:
            print(f"\nâ³ ç­‰å¾… 3 ç§’...")
            time.sleep(3)
    
    return results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” Failed Specs è°ƒè¯•å·¥å…·")
    print("=" * 50)
    
    # è®¾ç½®è¯¦ç»†æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
        datefmt='%H:%M:%S'
    )
    
    # åŠ è½½å¤±è´¥è®°å½•
    failed_specs_file = PROJECT_ROOT / 'results' / 'cache' / 'failed_specs.jsonl'
    failed_records = load_failed_specs(failed_specs_file)
    
    if not failed_records:
        print("âœ… æ²¡æœ‰å¤±è´¥è®°å½•éœ€è¦è°ƒè¯•")
        return
    
    # åˆ†æå¤±è´¥è®°å½•
    reasons, vendors = analyze_failed_specs(failed_records)
    
    # é€‰æ‹©è¦è°ƒè¯•çš„URL
    print(f"\nğŸ¯ é€‰æ‹©è°ƒè¯•æ¨¡å¼:")
    print(f"1. è°ƒè¯•æœ€æ–°çš„ 5 ä¸ªå¤±è´¥æ¡ˆä¾‹")
    print(f"2. è°ƒè¯• industrietechnik å¤±è´¥æ¡ˆä¾‹")
    print(f"3. è°ƒè¯• ZeroSpecifications å¤±è´¥æ¡ˆä¾‹")
    print(f"4. è°ƒè¯•æ‰€æœ‰ä¸åŒåŸå› çš„ä»£è¡¨æ¡ˆä¾‹")
    
    choice = input(f"\nè¯·é€‰æ‹© (1-4ï¼Œé»˜è®¤1): ").strip() or "1"
    
    urls_to_debug = []
    
    if choice == "1":
        # æœ€æ–°çš„å¤±è´¥æ¡ˆä¾‹
        latest_records = sorted(failed_records, key=lambda x: x.get('ts', ''), reverse=True)[:5]
        urls_to_debug = [r['url'] for r in latest_records]
        print(f"\nğŸ• è°ƒè¯•æœ€æ–°çš„ {len(urls_to_debug)} ä¸ªå¤±è´¥æ¡ˆä¾‹")
        
    elif choice == "2":
        # industrietechnik æ¡ˆä¾‹
        industrietechnik_records = [r for r in failed_records if 'industrietechnik' in r.get('url', '').lower()]
        urls_to_debug = [r['url'] for r in industrietechnik_records[:5]]
        print(f"\nğŸ­ è°ƒè¯• industrietechnik çš„ {len(urls_to_debug)} ä¸ªå¤±è´¥æ¡ˆä¾‹")
        
    elif choice == "3":
        # ZeroSpecifications æ¡ˆä¾‹
        zero_specs_records = [r for r in failed_records if r.get('reason') == 'ZeroSpecifications']
        urls_to_debug = [r['url'] for r in zero_specs_records[:5]]
        print(f"\nğŸ“Š è°ƒè¯• ZeroSpecifications çš„ {len(urls_to_debug)} ä¸ªå¤±è´¥æ¡ˆä¾‹")
        
    elif choice == "4":
        # æ¯ç§å¤±è´¥åŸå› çš„ä»£è¡¨
        for reason, records in reasons.items():
            if len(urls_to_debug) < 10:  # æœ€å¤š10ä¸ª
                urls_to_debug.append(records[0]['url'])
        print(f"\nğŸ¯ è°ƒè¯•å„ç§å¤±è´¥åŸå› çš„ä»£è¡¨æ¡ˆä¾‹ ({len(urls_to_debug)} ä¸ª)")
    
    if not urls_to_debug:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„URL")
        return
    
    # å¼€å§‹è°ƒè¯•
    results = debug_specific_urls(urls_to_debug)
    
    # æ±‡æ€»è°ƒè¯•ç»“æœ
    print(f"\nğŸ“Š è°ƒè¯•ç»“æœæ±‡æ€»:")
    print("=" * 60)
    
    success_count = sum(1 for r in results if r['result'].get('success', False))
    print(f"âœ… æˆåŠŸ: {success_count}/{len(results)}")
    print(f"âŒ å¤±è´¥: {len(results) - success_count}/{len(results)}")
    
    if success_count > 0:
        print(f"\nğŸ‰ æœ‰ {success_count} ä¸ªä¹‹å‰å¤±è´¥çš„URLç°åœ¨æˆåŠŸäº†ï¼")
        print(f"ğŸ’¡ å»ºè®®: è¿è¡Œæ¸…ç†è„šæœ¬ç§»é™¤è¿™äº›å·²ä¿®å¤çš„å¤±è´¥è®°å½•")
        print(f"   python3 scripts/clean_failed_specs.py")

if __name__ == '__main__':
    main()