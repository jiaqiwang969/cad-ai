#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¼”ç¤ºæ¸è¿›å¼ç¼“å­˜ç³»ç»Ÿ
================
å±•ç¤ºä¸‰é˜¶æ®µç¼“å­˜çš„ç»“æ„å’Œæ•°æ®æ ¼å¼
"""

import json
from pathlib import Path
from datetime import datetime


def analyze_cache():
    """åˆ†æç¼“å­˜æ–‡ä»¶å¹¶å±•ç¤ºç»“æ„"""
    
    cache_file = Path('results/cache/classification_tree_full.json')
    
    if not cache_file.exists():
        print("âŒ ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ:")
        print("   python run_cache_manager.py")
        return
    
    # åŠ è½½ç¼“å­˜
    with open(cache_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # å…ƒæ•°æ®
    metadata = data.get('metadata', {})
    
    print("ğŸ“‚ ç¼“å­˜æ–‡ä»¶åˆ†æ")
    print("="*60)
    
    # åŸºæœ¬ä¿¡æ¯
    print(f"\nğŸ“Š ç¼“å­˜å…ƒæ•°æ®:")
    print(f"   â€¢ æ–‡ä»¶è·¯å¾„: {cache_file.resolve()}")
    print(f"   â€¢ æ–‡ä»¶å¤§å°: {cache_file.stat().st_size / 1024 / 1024:.1f} MB")
    print(f"   â€¢ ç¼“å­˜çº§åˆ«: {metadata.get('cache_level_name', 'UNKNOWN')}")
    print(f"   â€¢ ç‰ˆæœ¬: {metadata.get('version', 'unknown')}")
    print(f"   â€¢ ç”Ÿæˆæ—¶é—´: {metadata.get('generated', 'unknown')}")
    
    # è®¡ç®—ç¼“å­˜å¹´é¾„
    if 'generated' in metadata:
        generated_time = datetime.fromisoformat(metadata['generated'])
        age_hours = (datetime.now() - generated_time).total_seconds() / 3600
        print(f"   â€¢ ç¼“å­˜å¹´é¾„: {age_hours:.1f} å°æ—¶")
    
    # æ•°æ®ç»Ÿè®¡
    print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
    print(f"   â€¢ å¶èŠ‚ç‚¹æ•°: {metadata.get('total_leaves', 0):,}")
    print(f"   â€¢ äº§å“æ€»æ•°: {metadata.get('total_products', 0):,}")
    print(f"   â€¢ è§„æ ¼æ€»æ•°: {metadata.get('total_specifications', 0):,}")
    
    # æ ¹æ®ç¼“å­˜çº§åˆ«æ˜¾ç¤ºä¸åŒçš„ä¿¡æ¯
    cache_level = metadata.get('cache_level', 0)
    
    if cache_level >= 1:
        print(f"\nğŸŒ³ åˆ†ç±»æ ‘ç»“æ„ (Level 1):")
        show_classification_tree(data)
    
    if cache_level >= 2:
        print(f"\nğŸ“¦ äº§å“é“¾æ¥ (Level 2):")
        show_product_links(data)
    
    if cache_level >= 3:
        print(f"\nğŸ“‹ äº§å“è§„æ ¼ (Level 3):")
        show_specifications(data)
    
    # ç¼“å­˜ç›®å½•ç»“æ„
    print(f"\nğŸ“ ç¼“å­˜ç›®å½•ç»“æ„:")
    show_cache_directory()


def show_classification_tree(data):
    """å±•ç¤ºåˆ†ç±»æ ‘ä¿¡æ¯"""
    root = data.get('root', {})
    leaves = data.get('leaves', [])
    
    # é€’å½’è®¡ç®—æ ‘çš„æ·±åº¦
    def get_depth(node, current=0):
        if not node.get('children'):
            return current
        return max(get_depth(child, current + 1) for child in node['children'])
    
    tree_depth = get_depth(root)
    
    print(f"   â€¢ æ ¹èŠ‚ç‚¹: {root.get('name', 'Unknown')}")
    print(f"   â€¢ æ ‘æ·±åº¦: {tree_depth} å±‚")
    print(f"   â€¢ å¶èŠ‚ç‚¹æ•°: {len(leaves)}")
    
    # æ˜¾ç¤ºå‰3ä¸ªå¶èŠ‚ç‚¹
    print(f"\n   å‰3ä¸ªå¶èŠ‚ç‚¹ç¤ºä¾‹:")
    for i, leaf in enumerate(leaves[:3], 1):
        print(f"   {i}. {leaf['name']} (code: {leaf['code']})")


def show_product_links(data):
    """å±•ç¤ºäº§å“é“¾æ¥ä¿¡æ¯"""
    leaves = data.get('leaves', [])
    
    # ç»Ÿè®¡æœ‰äº§å“çš„å¶èŠ‚ç‚¹
    leaves_with_products = [l for l in leaves if l.get('product_count', 0) > 0]
    
    print(f"   â€¢ æœ‰äº§å“çš„å¶èŠ‚ç‚¹: {len(leaves_with_products)}/{len(leaves)}")
    
    # æ‰¾å‡ºäº§å“æœ€å¤šçš„å¶èŠ‚ç‚¹
    if leaves_with_products:
        top_leaf = max(leaves_with_products, key=lambda x: x.get('product_count', 0))
        print(f"   â€¢ äº§å“æœ€å¤šçš„å¶èŠ‚ç‚¹: {top_leaf['name']} ({top_leaf.get('product_count', 0)} ä¸ªäº§å“)")
    
    # æ˜¾ç¤ºäº§å“é“¾æ¥ç¤ºä¾‹
    print(f"\n   äº§å“é“¾æ¥ç¤ºä¾‹:")
    count = 0
    for leaf in leaves:
        if count >= 3:
            break
        products = leaf.get('products', [])
        if products:
            count += 1
            print(f"\n   å¶èŠ‚ç‚¹: {leaf['name']}")
            # äº§å“å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸
            for j, product in enumerate(products[:2], 1):
                if isinstance(product, str):
                    print(f"     {j}. {product[:80]}...")
                else:
                    print(f"     {j}. {product.get('product_url', '')[:80]}...")


def show_specifications(data):
    """å±•ç¤ºäº§å“è§„æ ¼ä¿¡æ¯"""
    leaves = data.get('leaves', [])
    
    # ç»Ÿè®¡è§„æ ¼ä¿¡æ¯
    total_specs = 0
    products_with_specs = 0
    
    for leaf in leaves:
        for product in leaf.get('products', []):
            if isinstance(product, dict):
                specs = product.get('specifications', [])
                if specs:
                    products_with_specs += 1
                    total_specs += len(specs)
    
    print(f"   â€¢ æœ‰è§„æ ¼çš„äº§å“æ•°: {products_with_specs}")
    print(f"   â€¢ å¹³å‡æ¯äº§å“è§„æ ¼æ•°: {total_specs/products_with_specs if products_with_specs > 0 else 0:.1f}")
    
    # æ˜¾ç¤ºè§„æ ¼ç¤ºä¾‹
    print(f"\n   äº§å“è§„æ ¼ç¤ºä¾‹:")
    example_count = 0
    for leaf in leaves:
        if example_count >= 2:
            break
        for product in leaf.get('products', []):
            if example_count >= 2:
                break
            if isinstance(product, dict) and product.get('specifications'):
                example_count += 1
                print(f"\n   äº§å“: {product['product_url'][:60]}...")
                print(f"   è§„æ ¼æ•°: {product.get('spec_count', 0)}")
                for spec in product['specifications'][:3]:
                    print(f"     - {spec.get('reference', 'N/A')}: {spec.get('description', 'N/A')[:50]}...")


def show_cache_directory():
    """å±•ç¤ºç¼“å­˜ç›®å½•ç»“æ„"""
    cache_dir = Path('results/cache')
    
    if not cache_dir.exists():
        print("   ç¼“å­˜ç›®å½•ä¸å­˜åœ¨")
        return
    
    # ç»Ÿè®¡æ–‡ä»¶
    product_files = list((cache_dir / 'products').glob('*.json')) if (cache_dir / 'products').exists() else []
    spec_files = list((cache_dir / 'specifications').glob('*.json')) if (cache_dir / 'specifications').exists() else []
    
    print(f"   results/cache/")
    print(f"   â”œâ”€â”€ classification_tree_full.json (ä¸»ç¼“å­˜æ–‡ä»¶)")
    if (cache_dir / 'classification_tree_full.json.bak').exists():
        print(f"   â”œâ”€â”€ classification_tree_full.json.bak (å¤‡ä»½æ–‡ä»¶)")
    print(f"   â”œâ”€â”€ products/ ({len(product_files)} ä¸ªæ–‡ä»¶)")
    print(f"   â””â”€â”€ specifications/ ({len(spec_files)} ä¸ªæ–‡ä»¶)")
    
    # è®¡ç®—æ€»å¤§å°
    total_size = 0
    for file in cache_dir.rglob('*.json'):
        total_size += file.stat().st_size
    
    print(f"\n   ç¼“å­˜æ€»å¤§å°: {total_size / 1024 / 1024:.1f} MB")


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*60)
    print("ğŸš€ TraceParts æ¸è¿›å¼ç¼“å­˜ç³»ç»Ÿæ¼”ç¤º")
    print("="*60)
    
    analyze_cache()
    
    print("\n" + "="*60)
    print("ğŸ’¡ ä½¿ç”¨æç¤º:")
    print("="*60)
    print("\n1. æ„å»ºä¸åŒçº§åˆ«çš„ç¼“å­˜:")
    print("   python run_cache_manager.py --level classification  # ä»…åˆ†ç±»æ ‘")
    print("   python run_cache_manager.py --level products       # åˆ†ç±»æ ‘ + äº§å“é“¾æ¥")
    print("   python run_cache_manager.py --level specifications # å®Œæ•´ç¼“å­˜")
    
    print("\n2. ä½¿ç”¨ä¼˜åŒ–æµæ°´çº¿:")
    print("   python run_pipeline_v2.py                          # ä½¿ç”¨ç¼“å­˜è¿è¡Œ")
    print("   python run_pipeline_v2.py --no-cache               # å¼ºåˆ¶åˆ·æ–°")
    print("   python run_pipeline_v2.py --level products         # åªåˆ°äº§å“çº§åˆ«")
    
    print("\n3. å¯¼å‡ºæ•°æ®:")
    print("   python run_pipeline_v2.py --output export.json     # å¯¼å‡ºåˆ°æ–‡ä»¶")
    
    print("\n4. ç®¡ç†ç¼“å­˜:")
    print("   rm -rf results/cache/products/                     # æ¸…ç†äº§å“ç¼“å­˜")
    print("   rm -rf results/cache/specifications/               # æ¸…ç†è§„æ ¼ç¼“å­˜")
    print("   rm -rf results/cache/                              # æ¸…ç†æ‰€æœ‰ç¼“å­˜")


if __name__ == '__main__':
    main() 