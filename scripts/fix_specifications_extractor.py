#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§„æ ¼æå–å™¨ä¿®å¤è„šæœ¬
ä¸“é—¨è§£å†³æ–‡æœ¬å†…å®¹è·å–å¤±è´¥çš„é—®é¢˜
"""

import sys
sys.path.append('.')

import time
import json
from pathlib import Path
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æµ‹è¯•URL
TEST_URL = "https://www.traceparts.cn/en/product/ntn-europe-usc200t20-cartridge-unit-from-grey-cast-high-temperature?CatalogPath=TRACEPARTS%3ATP01002002006&Product=34-17112021-055894"

def create_enhanced_driver():
    """åˆ›å»ºå¢å¼ºç‰ˆæµè§ˆå™¨é©±åŠ¨"""
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')
    options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
    
    driver = webdriver.Chrome(options=options)
    driver.implicitly_wait(10)
    return driver

def wait_for_content_loaded(driver, timeout=30):
    """ç­‰å¾…é¡µé¢å†…å®¹å®Œå…¨åŠ è½½"""
    logger.info("â³ ç­‰å¾…é¡µé¢å†…å®¹åŠ è½½...")
    
    # ç­‰å¾…è¡¨æ ¼å‡ºç°
    try:
        WebDriverWait(driver, timeout).until(
            EC.presence_of_element_located((By.TAG_NAME, 'table'))
        )
        logger.info("âœ… è¡¨æ ¼å…ƒç´ å·²åŠ è½½")
    except TimeoutException:
        logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°è¡¨æ ¼å…ƒç´ ")
    
    # é¢å¤–ç­‰å¾…åŠ¨æ€å†…å®¹
    time.sleep(5)
    
    # æ»šåŠ¨é¡µé¢ç¡®ä¿å†…å®¹å®Œå…¨å±•ç¤º
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(2)
    driver.execute_script("window.scrollTo(0, 0);")
    time.sleep(2)

def get_cell_text_enhanced(cell_element):
    """å¢å¼ºç‰ˆæ–‡æœ¬è·å–å‡½æ•°"""
    # æ–¹æ³•1: æ ‡å‡† text å±æ€§
    text = cell_element.text.strip()
    if text:
        return text
    
    # æ–¹æ³•2: textContent å±æ€§
    text = cell_element.get_attribute('textContent')
    if text and text.strip():
        return text.strip()
    
    # æ–¹æ³•3: innerText å±æ€§
    text = cell_element.get_attribute('innerText')
    if text and text.strip():
        return text.strip()
    
    # æ–¹æ³•4: innerHTML å¹¶æå–çº¯æ–‡æœ¬
    html = cell_element.get_attribute('innerHTML')
    if html:
        # ç®€å•çš„HTMLæ ‡ç­¾å»é™¤
        import re
        text = re.sub(r'<[^>]+>', '', html).strip()
        if text:
            return text
    
    # æ–¹æ³•5: å­å…ƒç´ æ–‡æœ¬
    try:
        child_elements = cell_element.find_elements(By.XPATH, './/*')
        texts = []
        for child in child_elements:
            child_text = child.text.strip()
            if child_text:
                texts.append(child_text)
        if texts:
            return ' '.join(texts)
    except:
        pass
    
    return ''

def find_all_tables_enhanced(driver):
    """å¢å¼ºç‰ˆè¡¨æ ¼æŸ¥æ‰¾"""
    logger.info("ğŸ” æŸ¥æ‰¾é¡µé¢ä¸­çš„æ‰€æœ‰è¡¨æ ¼...")
    
    tables_info = []
    
    # æŸ¥æ‰¾æ‰€æœ‰è¡¨æ ¼
    tables = driver.find_elements(By.TAG_NAME, 'table')
    logger.info(f"ğŸ“Š æ‰¾åˆ° {len(tables)} ä¸ªè¡¨æ ¼")
    
    for i, table in enumerate(tables):
        try:
            rows = table.find_elements(By.TAG_NAME, 'tr')
            if not rows:
                continue
                
            # åˆ†æè¡¨æ ¼å†…å®¹
            non_empty_rows = 0
            total_cells = 0
            sample_texts = []
            
            for row in rows[:5]:  # åªæ£€æŸ¥å‰5è¡Œ
                cells = row.find_elements(By.CSS_SELECTOR, 'td, th')
                if cells:
                    total_cells += len(cells)
                    row_texts = []
                    for cell in cells:
                        cell_text = get_cell_text_enhanced(cell)
                        if cell_text:
                            row_texts.append(cell_text)
                    
                    if row_texts:
                        non_empty_rows += 1
                        sample_texts.extend(row_texts[:3])  # å–å‰3ä¸ªå•å…ƒæ ¼æ–‡æœ¬
            
            table_info = {
                'index': i,
                'rows_count': len(rows),
                'non_empty_rows': non_empty_rows,
                'total_cells': total_cells,
                'sample_texts': sample_texts[:10],  # æœ€å¤š10ä¸ªæ ·æœ¬
                'element': table
            }
            
            tables_info.append(table_info)
            
            logger.info(f"  è¡¨æ ¼ {i+1}: {len(rows)} è¡Œ, {non_empty_rows} è¡Œæœ‰å†…å®¹, æ ·æœ¬: {sample_texts[:3]}")
            
        except Exception as e:
            logger.warning(f"  è¡¨æ ¼ {i+1} åˆ†æå¤±è´¥: {e}")
    
    return tables_info

def extract_specifications_enhanced(driver):
    """å¢å¼ºç‰ˆè§„æ ¼æå–"""
    logger.info("ğŸš€ å¼€å§‹å¢å¼ºç‰ˆè§„æ ¼æå–...")
    
    # ç­‰å¾…å†…å®¹åŠ è½½
    wait_for_content_loaded(driver)
    
    # æŸ¥æ‰¾æ‰€æœ‰è¡¨æ ¼
    tables_info = find_all_tables_enhanced(driver)
    
    if not tables_info:
        logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•è¡¨æ ¼")
        return []
    
    # é€‰æ‹©æœ€æœ‰å¸Œæœ›çš„è¡¨æ ¼ï¼ˆæœ‰å†…å®¹çš„æœ€å¤§è¡¨æ ¼ï¼‰
    best_table = max(tables_info, key=lambda t: t['non_empty_rows'] * t['rows_count'])
    logger.info(f"ğŸ¯ é€‰æ‹©è¡¨æ ¼ {best_table['index']+1} è¿›è¡Œè¯¦ç»†åˆ†æ")
    
    table_element = best_table['element']
    rows = table_element.find_elements(By.TAG_NAME, 'tr')
    
    logger.info(f"ğŸ“Š è¯¦ç»†åˆ†æè¡¨æ ¼ï¼Œå…± {len(rows)} è¡Œ")
    
    specifications = []
    seen_references = set()
    
    # é€è¡Œåˆ†æ
    for i, row in enumerate(rows):
        try:
            cells = row.find_elements(By.CSS_SELECTOR, 'td, th')
            if not cells:
                continue
            
            # ä½¿ç”¨å¢å¼ºç‰ˆæ–‡æœ¬æå–
            cell_texts = []
            for cell in cells:
                text = get_cell_text_enhanced(cell)
                cell_texts.append(text)
            
            # æ˜¾ç¤ºè¡Œå†…å®¹ï¼ˆè°ƒè¯•ç”¨ï¼‰
            if cell_texts and any(cell_texts):
                logger.info(f"  è¡Œ {i+1}: {cell_texts[:5]}...")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«äº§å“ç¼–å·
                for j, cell_text in enumerate(cell_texts):
                    if (cell_text and len(cell_text) >= 3 and 
                        cell_text not in seen_references and
                        is_likely_product_reference_enhanced(cell_text)):
                        
                        spec_info = {
                            'reference': cell_text,
                            'row_index': i,
                            'column_index': j,
                            'all_cells': cell_texts,
                            'extraction_method': 'enhanced'
                        }
                        
                        specifications.append(spec_info)
                        seen_references.add(cell_text)
                        logger.info(f"  ğŸ“¦ æ‰¾åˆ°è§„æ ¼: {cell_text}")
                        
                        # æ¯è¡Œåªå–ç¬¬ä¸€ä¸ªè§„æ ¼
                        break
            else:
                logger.debug(f"  è¡Œ {i+1}: ç©ºè¡Œæˆ–æ— å†…å®¹")
                
        except Exception as e:
            logger.warning(f"  è¡Œ {i+1} å¤„ç†å¤±è´¥: {e}")
    
    logger.info(f"âœ… æ€»å…±æå–åˆ° {len(specifications)} ä¸ªè§„æ ¼")
    return specifications

def is_likely_product_reference_enhanced(text):
    """å¢å¼ºç‰ˆäº§å“ç¼–å·åˆ¤æ–­"""
    if not text or len(text) < 3:
        return False
    
    # æ’é™¤æ˜æ˜¾çš„éäº§å“ç¼–å·
    exclude_patterns = [
        r'^https?://',  # URL
        r'^www\.',      # ç½‘å€
        r'@',           # é‚®ç®±
        r'^\d{4}-\d{2}-\d{2}',  # æ—¥æœŸ
        r'^\+?\d{10,}$',  # ç”µè¯
        r'^[\s\-_]*$',  # åªæœ‰ç©ºæ ¼å’Œç¬¦å·
    ]
    
    import re
    for pattern in exclude_patterns:
        if re.search(pattern, text, re.IGNORECASE):
            return False
    
    # æ’é™¤å¸¸è§æè¿°è¯
    common_words = [
        'description', 'manufacturer', 'material', 'color', 'size',
        'weight', 'length', 'width', 'height', 'diameter', 'thickness',
        'please', 'select', 'bearing', 'unit', 'assembly', 'component',
        'parts', 'mounted', 'not', 'items', 'per', 'page', 'documentation',
        'contact', 'supplier', 'disclaimer', 'liability'
    ]
    
    text_lower = text.lower()
    if text_lower in common_words:
        return False
    
    # ç§¯ææŒ‡æ ‡
    positive_score = 0
    
    # åŒ…å«æ•°å­—
    if any(c.isdigit() for c in text):
        positive_score += 2
    
    # åŒ…å«è¿å­—ç¬¦
    if '-' in text or '_' in text:
        positive_score += 1
    
    # åŒ…å«å¤§å†™å­—æ¯ï¼ˆé™¤ç¬¬ä¸€ä¸ªï¼‰
    if any(c.isupper() for c in text[1:]):
        positive_score += 1
    
    # é•¿åº¦åˆé€‚
    if 3 <= len(text) <= 50:
        positive_score += 1
    
    # ç‰¹æ®Šæ¨¡å¼
    special_patterns = [
        r'^\w+-\w+-\w+$',  # ABC-123-DEF
        r'^[A-Z]+\d+',     # SLS50
        r'^\d+[A-Z]+',     # 200T20
        r'^[A-Z0-9]+[-_][A-Z0-9]+',  # USC200T20
        r'^[A-Z]{2,}\d{2,}',  # USC200
    ]
    
    for pattern in special_patterns:
        if re.match(pattern, text):
            positive_score += 3
            break
    
    return positive_score >= 3

def test_enhanced_extraction():
    """æµ‹è¯•å¢å¼ºç‰ˆæå–åŠŸèƒ½"""
    logger.info("ğŸ§ª æµ‹è¯•å¢å¼ºç‰ˆè§„æ ¼æå–")
    logger.info(f"ğŸ“ ç›®æ ‡URL: {TEST_URL}")
    
    driver = None
    try:
        driver = create_enhanced_driver()
        
        # è®¿é—®é¡µé¢
        logger.info("ğŸŒ è®¿é—®ç›®æ ‡é¡µé¢...")
        driver.get(TEST_URL)
        
        # æå–è§„æ ¼
        specifications = extract_specifications_enhanced(driver)
        
        # ä¿å­˜ç»“æœ
        if specifications:
            timestamp = int(time.time())
            results = {
                'test_url': TEST_URL,
                'extraction_time': time.strftime('%Y-%m-%d %H:%M:%S'),
                'specifications_count': len(specifications),
                'specifications': specifications
            }
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            results_dir = Path("results/debug")
            results_dir.mkdir(parents=True, exist_ok=True)
            
            results_file = results_dir / f"enhanced_extraction_{timestamp}.json"
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {results_file}")
            
            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            logger.info("\n" + "="*60)
            logger.info("ğŸ“‹ æå–ç»“æœæ‘˜è¦")
            logger.info("="*60)
            logger.info(f"âœ… æˆåŠŸæå– {len(specifications)} ä¸ªè§„æ ¼")
            
            for i, spec in enumerate(specifications[:10], 1):
                logger.info(f"{i:2d}. {spec['reference']}")
            
            if len(specifications) > 10:
                logger.info(f"... è¿˜æœ‰ {len(specifications) - 10} ä¸ªè§„æ ¼")
        else:
            logger.error("âŒ æœªæå–åˆ°ä»»ä½•è§„æ ¼")
            return False
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        if driver:
            driver.quit()

if __name__ == '__main__':
    success = test_enhanced_extraction()
    if success:
        logger.info("âœ… å¢å¼ºç‰ˆæå–æµ‹è¯•æˆåŠŸ")
    else:
        logger.error("âŒ å¢å¼ºç‰ˆæå–æµ‹è¯•å¤±è´¥") 