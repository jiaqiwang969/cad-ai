#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤§é¡µé¢æ€§èƒ½æµ‹è¯•ï¼ˆæ­£ç¡®ç‰ˆæœ¬ï¼‰
========================
æµ‹è¯•ç®—æ³•åœ¨å¤§é¡µé¢ä¸Šçš„è¡¨ç°
"""

import sys
import os
import time
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.crawler.products import ProductLinksCrawler
from src.utils.browser_manager import create_browser_manager


def test_large_page_proper():
    """æµ‹è¯•å¤§é¡µé¢æ€§èƒ½ï¼ˆæ­£ç¡®ç‰ˆæœ¬ï¼‰"""
    # 5099äº§å“çš„å¤§é¡µé¢
    test_url = "https://www.traceparts.cn/en/search/traceparts-classification-electrical-electrical-protection-devices-circuit-breakers-molded-case-circuit-breakers-mccb?CatalogPath=TRACEPARTS%3ATP09004001008"
    
    print("ğŸ¯ å¤§é¡µé¢æ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    print(f"æµ‹è¯•URL: {test_url}")
    print("è¯´æ˜: å°†åŠ è½½äº§å“ç›´åˆ°è¾¾åˆ°500ä¸ªæˆ–æ²¡æœ‰æ›´å¤šäº§å“")
    print("æ¨¡å¼: æ— å¤´æ¨¡å¼ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰\n")
    
    # åˆ›å»ºçˆ¬å–å™¨
    browser_manager = create_browser_manager(pool_size=1)
    crawler = ProductLinksCrawler(browser_manager)
    
    # ä¿å­˜åŸå§‹æ–¹æ³•
    original_load_all = crawler._load_all_results
    
    # åˆ›å»ºä¸€ä¸ªé™åˆ¶ç‰ˆæœ¬
    def limited_load_all_results(driver):
        """ä¿®æ”¹ç‰ˆï¼šåŠ è½½äº§å“ç›´åˆ°500ä¸ª"""
        # åˆå§‹æ»šåŠ¨
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(0.5)
        
        # è®°å½•äº§å“æ•°å˜åŒ–
        last_count = len(driver.find_elements(By.CSS_SELECTOR, "a[href*='&Product=']"))
        no_change_count = 0
        click_count = 0
        
        while True:
            current_count = len(driver.find_elements(By.CSS_SELECTOR, "a[href*='&Product=']"))
            print(f"  å½“å‰äº§å“æ•°: {current_count}")
            
            # è¾¾åˆ°500ä¸ªå°±åœæ­¢
            if current_count >= 500:
                print(f"  âœ“ è¾¾åˆ°500ä¸ªäº§å“ï¼Œåœæ­¢åŠ è½½")
                crawler.logger.info(f"åŠ è½½å®Œæˆï¼Œæœ€ç»ˆäº§å“æ•°: {current_count}")
                break
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
            if current_count == last_count:
                no_change_count += 1
                if no_change_count >= 5:
                    print(f"  âœ“ äº§å“æ•°ä¸å†å˜åŒ–ï¼Œåœæ­¢åŠ è½½")
                    crawler.logger.info(f"åŠ è½½å®Œæˆï¼Œæœ€ç»ˆäº§å“æ•°: {current_count}")
                    break
            else:
                no_change_count = 0
                last_count = current_count
                
            # æ™ºèƒ½ç­‰å¾…å¹¶ç‚¹å‡»æŒ‰é’®ï¼ˆå¤åˆ¶è‡ªä¼˜åŒ–åçš„ä»£ç ï¼‰
            button_clicked = False
            
            # é¦–å…ˆå¿«é€Ÿæ£€æŸ¥æŒ‰é’®æ˜¯å¦å·²å­˜åœ¨
            try:
                button = driver.find_element(By.CSS_SELECTOR, "button.more-results")
                if button.is_displayed() and button.is_enabled():
                    driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", button)
                    time.sleep(0.3)
                    driver.execute_script("arguments[0].click();", button)
                    click_count += 1
                    print(f"  âœ“ ç¬¬ {click_count} æ¬¡ç‚¹å‡» Show More")
                    button_clicked = True
                    time.sleep(1.5)
                    continue
            except:
                pass
                
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œç­‰å¾…æŒ‰é’®å‡ºç°
            if not button_clicked:
                try:
                    from selenium.webdriver.support.ui import WebDriverWait
                    from selenium.webdriver.support import expected_conditions as EC
                    
                    button = WebDriverWait(driver, 2).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, "button.more-results"))
                    )
                    if button.is_displayed() and button.is_enabled():
                        driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", button)
                        time.sleep(0.3)
                        driver.execute_script("arguments[0].click();", button)
                        click_count += 1
                        print(f"  âœ“ ç¬¬ {click_count} æ¬¡ç‚¹å‡» Show Moreï¼ˆç­‰å¾…åï¼‰")
                        button_clicked = True
                        time.sleep(1.5)
                except:
                    pass
                    
            # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°æŒ‰é’®ï¼Œæ»šåŠ¨
            if not button_clicked:
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(0.5)
                
            # é¿å…æ— é™å¾ªç¯
            if click_count > 50:  # 500/40 â‰ˆ 13ï¼Œç»™å……è¶³ä½™é‡
                print(f"  âš ï¸ å·²ç‚¹å‡» {click_count} æ¬¡ï¼Œåœæ­¢åŠ è½½")
                break
    
    # æ›¿æ¢æ–¹æ³•
    crawler._load_all_results = limited_load_all_results
    
    try:
        print("â³ å¼€å§‹çˆ¬å–...")
        start_time = time.time()
        
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        from selenium.webdriver.common.by import By
        
        products = crawler.extract_product_links(test_url)
        
        elapsed = time.time() - start_time
        
        print(f"\n{'='*60}")
        print(f"âœ… å®Œæˆ!")
        print(f"  è·å–äº§å“æ•°: {len(products)}")
        print(f"  ç”¨æ—¶: {elapsed:.1f} ç§’")
        print(f"  é€Ÿåº¦: {len(products)/elapsed:.1f} ä¸ª/ç§’")
        
        # è¯„ä¼°
        if len(products) >= 500:
            print(f"\nğŸ‰ æˆåŠŸè·å–500+ä¸ªäº§å“ï¼")
        elif len(products) >= 400:
            print(f"\nâœ… æ€§èƒ½è‰¯å¥½ï¼")
        else:
            print(f"\nâš ï¸  è·å–äº§å“æ•°è¾ƒå°‘")
            
        # é¢„ä¼°å…¨éƒ¨5099ä¸ªäº§å“çš„æ—¶é—´
        if len(products) > 0:
            # æ›´å‡†ç¡®çš„ä¼°ç®—ï¼šè€ƒè™‘åˆ°åé¢å¯èƒ½ä¼šå˜æ…¢
            avg_speed = len(products) / elapsed
            # å‡è®¾é€Ÿåº¦ä¼šé€æ¸é™ä½
            estimated_time = 5099 / avg_speed * 1.2  # å¢åŠ 20%çš„ç¼“å†²
            print(f"\nğŸ’¡ é¢„ä¼°è·å–å…¨éƒ¨5099ä¸ªäº§å“éœ€è¦: {estimated_time:.1f} ç§’ ({estimated_time/60:.1f} åˆ†é’Ÿ)")
            
            # ä¸test_5099_improved.pyå¯¹æ¯”
            print(f"\nğŸ“Š å‚è€ƒ: test_5099_improved.py è·å–5000ä¸ªäº§å“ç”¨æ—¶243.8ç§’")
            
    finally:
        # æ¢å¤åŸå§‹æ–¹æ³•
        crawler._load_all_results = original_load_all
        browser_manager.shutdown()
        print("\nâœ… æµ‹è¯•å®Œæˆ")


if __name__ == '__main__':
    test_large_page_proper() 