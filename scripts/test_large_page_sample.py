#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤§é¡µé¢é‡‡æ ·æµ‹è¯•
==============
æµ‹è¯•å¤§é¡µé¢ï¼ˆ5099äº§å“ï¼‰çš„éƒ¨åˆ†äº§å“åŠ è½½æ€§èƒ½
"""

import sys
import os
import time
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.crawler.products import ProductLinksCrawler
from src.utils.browser_manager import create_browser_manager


def test_large_page():
    """æµ‹è¯•å¤§é¡µé¢æ€§èƒ½"""
    # 5099äº§å“çš„å¤§é¡µé¢
    test_url = "https://www.traceparts.cn/en/search/traceparts-classification-electrical-electrical-protection-devices-circuit-breakers-molded-case-circuit-breakers-mccb?CatalogPath=TRACEPARTS%3ATP09004001008"
    
    print("ğŸ¯ å¤§é¡µé¢é‡‡æ ·æµ‹è¯•")
    print("=" * 60)
    print(f"æµ‹è¯•URL: {test_url}")
    print("ç›®æ ‡: æµ‹è¯•å‰500ä¸ªäº§å“çš„åŠ è½½é€Ÿåº¦")
    print("æ¨¡å¼: æ— å¤´æ¨¡å¼ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰\n")
    
    # åˆ›å»ºçˆ¬å–å™¨
    browser_manager = create_browser_manager(pool_size=1)
    crawler = ProductLinksCrawler(browser_manager)
    
    # ä¸´æ—¶ä¿®æ”¹çˆ¬å–å™¨ï¼Œåœ¨è¾¾åˆ°500ä¸ªäº§å“æ—¶åœæ­¢
    original_load_all = crawler._load_all_results
    
    def limited_load(driver):
        """é™åˆ¶åŠ è½½åˆ°500ä¸ªäº§å“"""
        # åˆå§‹æ»šåŠ¨
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(0.5)
        
        last_count = len(driver.find_elements(By.CSS_SELECTOR, "a[href*='&Product=']"))
        no_change_count = 0
        click_count = 0
        
        while True:
            current_count = len(driver.find_elements(By.CSS_SELECTOR, "a[href*='&Product=']"))
            
            # è¾¾åˆ°500ä¸ªå°±åœæ­¢
            if current_count >= 500:
                print(f"âœ“ è¾¾åˆ°500ä¸ªäº§å“ï¼Œåœæ­¢åŠ è½½")
                break
                
            if current_count == last_count:
                no_change_count += 1
                if no_change_count >= 5:
                    print(f"âœ“ äº§å“æ•°ä¸å†å˜åŒ–ï¼Œåœæ­¢åŠ è½½ï¼ˆå½“å‰: {current_count}ï¼‰")
                    break
            else:
                no_change_count = 0
                last_count = current_count
                
            # è°ƒç”¨åŸå§‹çš„ç‚¹å‡»é€»è¾‘
            original_load_all(driver)
            break
    
    # ä¸´æ—¶æ›¿æ¢æ–¹æ³•
    crawler._load_all_results = limited_load
    
    try:
        print("â³ å¼€å§‹çˆ¬å–ï¼ˆé™åˆ¶500ä¸ªäº§å“ï¼‰...")
        start_time = time.time()
        
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        from selenium.webdriver.common.by import By
        
        products = crawler.extract_product_links(test_url)
        
        elapsed = time.time() - start_time
        
        print(f"\n{'='*60}")
        print(f"âœ… å®Œæˆ!")
        print(f"  è·å–äº§å“æ•°: {len(products)}")
        print(f"  ç”¨æ—¶: {elapsed:.1f} ç§’")
        print(f"  é€Ÿåº¦: {len(products)/elapsed:.1f} ä¸ª/ç§’")
        
        # è¯„ä¼°
        if len(products) >= 400:
            print(f"\nâœ… æ€§èƒ½è‰¯å¥½ï¼")
        else:
            print(f"\nâš ï¸  è·å–äº§å“æ•°è¾ƒå°‘")
            
        # é¢„ä¼°å…¨éƒ¨5099ä¸ªäº§å“çš„æ—¶é—´
        if len(products) > 0:
            estimated_time = (5099 / len(products)) * elapsed
            print(f"\nğŸ’¡ é¢„ä¼°è·å–å…¨éƒ¨5099ä¸ªäº§å“éœ€è¦: {estimated_time:.1f} ç§’ ({estimated_time/60:.1f} åˆ†é’Ÿ)")
            
    finally:
        # æ¢å¤åŸå§‹æ–¹æ³•
        crawler._load_all_results = original_load_all
        browser_manager.shutdown()
        print("\nâœ… æµ‹è¯•å®Œæˆ")


if __name__ == '__main__':
    test_large_page() 