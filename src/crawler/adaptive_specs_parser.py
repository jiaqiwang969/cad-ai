#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªé€‚åº”è§„æ ¼è§£æå™¨ - å®Œå…¨é›†æˆtest-09-1é€»è¾‘
==============
åŸºäºtest-09-1çš„å®Œæ•´é€»è¾‘ï¼Œå®ç°äº§å“è§„æ ¼çš„æ™ºèƒ½æå–
"""

import re
import time
import logging
from typing import List, Dict, Any, Optional, Tuple
from urllib.parse import urlparse, parse_qs, urlencode
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException


class AdaptiveSpecsParser:
    """è‡ªé€‚åº”è§„æ ¼è§£æå™¨ - é›†æˆtest-09-1å®Œæ•´é€»è¾‘"""
    
    def __init__(self, logger=None):
        self.logger = logger or logging.getLogger(__name__)
        
        # äº§å“ç¼–å·è¯†åˆ«å…³é”®è¯ï¼ˆå¤šè¯­è¨€æ”¯æŒï¼‰
        self.reference_keywords = [
            'part number', 'part no', 'part#', 'p/n',
            'product number', 'product code', 'product id',
            'model', 'model number', 'model no',
            'reference', 'ref', 'item number', 'item no',
            'catalog number', 'cat no', 'sku',
            'bestellnummer', 'artikelnummer', 'teilenummer',  # å¾·è¯­
            'numÃ©ro', 'rÃ©fÃ©rence',  # æ³•è¯­
            'nÃºmero', 'codigo',  # è¥¿ç­ç‰™è¯­
            'å‹å·', 'ç¼–å·', 'æ–™å·'  # ä¸­æ–‡
        ]
    
    def parse_specifications(self, driver, url: str) -> List[Dict[str, Any]]:
        """
        ä¸»è¦è§„æ ¼è§£æå…¥å£ - å®Œå…¨å¤åˆ¶test-09-1é€»è¾‘
        è¿”å›æ ¼å¼ä¸ç°æœ‰pipelineå…¼å®¹çš„è§„æ ¼åˆ—è¡¨
        """
        try:
            self.logger.info(f"ğŸ¯ å¼€å§‹è§£æäº§å“è§„æ ¼: {url}")
            
            # Step 1: æå–åŸºç¡€äº§å“ä¿¡æ¯
            base_product_info = self.extract_base_product_info(url)
            
            # Step 2: æ‰§è¡Œå®Œæ•´çš„äº§å“è§„æ ¼æå–ï¼ˆtest-09-1æ ¸å¿ƒé€»è¾‘ï¼‰
            specifications, all_headers = self.extract_all_product_specifications(driver)
            
            # Step 3: ä¸ºæ¯ä¸ªè§„æ ¼ç”Ÿæˆè¯¦ç»†URL
            enhanced_specifications = []
            for spec in specifications:
                spec_urls = self.generate_specification_urls(
                    base_product_info, spec.get('reference', '')
                )
                
                # è½¬æ¢ä¸ºpipelineå…¼å®¹æ ¼å¼
                enhanced_spec = {
                    'reference': spec.get('reference', ''),
                    'dimensions': spec.get('dimensions', ''),
                    'weight': spec.get('weight', ''),
                    'parameters': spec.get('parameters', {}),
                    'specification_urls': spec_urls,
                    'base_product_name': base_product_info['base_product_name'],
                    'product_id': base_product_info['product_id'],
                    'table_type': spec.get('table_type', 'unknown'),
                    'row_index': spec.get('row_index', 0),
                    'headers': spec.get('headers', all_headers),
                    'all_cells': spec.get('all_cells', [])
                }
                enhanced_specifications.append(enhanced_spec)
            
            self.logger.info(f"âœ… æˆåŠŸè§£æ {len(enhanced_specifications)} ä¸ªäº§å“è§„æ ¼")
            return enhanced_specifications
            
        except Exception as e:
            self.logger.error(f"âŒ è§„æ ¼è§£æå¤±è´¥: {e}")
            return []
    
    def extract_base_product_info(self, product_url: str) -> Dict[str, Any]:
        """æå–åŸºç¡€äº§å“ä¿¡æ¯ - å¤åˆ¶test-09-1é€»è¾‘"""
        try:
            parsed_url = urlparse(product_url)
            path_parts = parsed_url.path.split('/')
            query_params = parse_qs(parsed_url.query)
            
            # æå–äº§å“åç§°ï¼ˆURLè·¯å¾„æœ€åä¸€éƒ¨åˆ†ï¼‰
            base_product_name = path_parts[-1] if path_parts else 'unknown-product'
            
            # æå–äº§å“IDï¼ˆæŸ¥è¯¢å‚æ•°ä¸­çš„Productå­—æ®µï¼‰
            product_id = query_params.get('Product', ['unknown-id'])[0]
            
            result = {
                'base_product_name': base_product_name,
                'product_id': product_id,
                'query_params': query_params
            }
            
            self.logger.debug(f"ğŸ“‹ åŸºç¡€äº§å“ä¿¡æ¯: {result}")
            return result
            
        except Exception as e:
            self.logger.error(f"åŸºç¡€äº§å“ä¿¡æ¯æå–å¤±è´¥: {e}")
            return {
                'base_product_name': 'unknown-product',
                'product_id': 'unknown-id',
                'query_params': {}
            }
    
    def extract_all_product_specifications(self, driver) -> Tuple[List[Dict[str, Any]], List[str]]:
        """
        å®Œæ•´çš„äº§å“è§„æ ¼æå– - å®Œå…¨å¤åˆ¶test-09-1çš„extract_all_product_specificationsé€»è¾‘
        """
        specifications = []
        all_headers = []
        
        try:
            # ========== Step 1: é¡µé¢é¢„å¤„ç†å’Œç¨³å®šç­‰å¾… ==========
            self.logger.debug("ğŸ”„ Step 1: é¡µé¢é¢„å¤„ç†å’Œç¨³å®šç­‰å¾…")
            
            # ç­‰å¾…é¡µé¢åŸºæœ¬ç»“æ„åŠ è½½
            try:
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                )
            except TimeoutException:
                self.logger.warning("é¡µé¢bodyåŠ è½½è¶…æ—¶ï¼Œç»§ç»­å¤„ç†")
            
            # åŸºç¡€ç­‰å¾…
            time.sleep(2)
            
            # ========== Step 2: æ£€æµ‹åŠ¨æ€å†…å®¹å¹¶å¤„ç† ==========
            self.logger.debug("ğŸ”„ Step 2: æ£€æµ‹åŠ¨æ€å†…å®¹")
            
            # æŸ¥æ‰¾åˆ†é¡µä¿¡æ¯ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦ç­‰å¾…åŠ¨æ€åŠ è½½
            pagination_indicators = [
                "items per page", "out of", "total", "results", "showing",
                "é¡µé¢", "å…±", "æ€»è®¡", "æ˜¾ç¤º"
            ]
            
            has_pagination_text = False
            for indicator in pagination_indicators:
                try:
                    elements = driver.find_elements(By.XPATH, 
                        f"//*[contains(translate(text(), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{indicator}')]")
                    for elem in elements:
                        if elem.is_displayed() and elem.text.strip():
                            has_pagination_text = True
                            self.logger.debug(f"å‘ç°åˆ†é¡µä¿¡æ¯: '{elem.text.strip()}'")
                            break
                    if has_pagination_text:
                        break
                except Exception:
                    continue
            
            # ========== Step 3: 6ç§åŠ¨æ€åŠ è½½ç­–ç•¥ ==========
            if has_pagination_text:
                self.logger.debug("ğŸ”„ Step 3: æ‰§è¡ŒåŠ¨æ€åŠ è½½ç­–ç•¥")
                success_strategy = self.apply_dynamic_loading_strategies(driver)
                self.logger.debug(f"åŠ¨æ€åŠ è½½ç­–ç•¥ç»“æœ: {success_strategy}")
            
            # ========== Step 4: æœ€ç»ˆé¡µé¢ç¨³å®šç­‰å¾… ==========
            self.logger.debug("ğŸ”„ Step 4: æœ€ç»ˆé¡µé¢ç¨³å®šç­‰å¾…")
            time.sleep(1)
            
            # ç¡®ä¿é¡µé¢å®Œå…¨æ¸²æŸ“
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(0.5)
            driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(0.5)
            
            # ========== Step 5: æ™ºèƒ½è¡¨æ ¼é€‰æ‹©å’Œæ•°æ®æå– ==========
            self.logger.debug("ğŸ”„ Step 5: æ™ºèƒ½è¡¨æ ¼é€‰æ‹©")
            
            selected_table = self.intelligent_table_selection(driver)
            
            if selected_table:
                self.logger.debug("âœ… æ‰¾åˆ°åˆé€‚çš„è¡¨æ ¼ï¼Œå¼€å§‹æå–æ•°æ®")
                table_specs, table_headers = self.extract_table_specifications(selected_table)
                specifications.extend(table_specs)
                all_headers = table_headers
            else:
                self.logger.warning("âŒ æœªæ‰¾åˆ°åˆé€‚çš„äº§å“è¡¨æ ¼")
            
            return specifications, all_headers
            
        except Exception as e:
            self.logger.error(f"âŒ äº§å“è§„æ ¼æå–å¤±è´¥: {e}")
            return [], []
    
    def apply_dynamic_loading_strategies(self, driver) -> str:
        """åº”ç”¨6ç§åŠ¨æ€åŠ è½½ç­–ç•¥ - å¤åˆ¶test-09-1é€»è¾‘"""
        strategies = [
            ("å»¶é•¿ç­‰å¾…ç­–ç•¥", self.strategy_extended_wait),
            ("å¼ºåˆ¶åˆ·æ–°ç­–ç•¥", self.strategy_force_refresh),
            ("å¤šæ¬¡æ»šåŠ¨ç­–ç•¥", self.strategy_multiple_scroll),
            ("ç‚¹å‡»è§¦å‘å™¨ç­–ç•¥", self.strategy_click_triggers),
            ("ç­‰å¾…å…ƒç´ ç­–ç•¥", self.strategy_wait_elements),
            ("æœ€ç»ˆæ»šåŠ¨ç­–ç•¥", self.strategy_final_scroll)
        ]
        
        for strategy_name, strategy_func in strategies:
            try:
                self.logger.debug(f"ğŸ”„ å°è¯•: {strategy_name}")
                result = strategy_func(driver)
                if result:
                    self.logger.debug(f"âœ… {strategy_name} æˆåŠŸ")
                    return strategy_name
                else:
                    self.logger.debug(f"âŒ {strategy_name} æ— æ•ˆæœ")
            except Exception as e:
                self.logger.debug(f"âŒ {strategy_name} å¼‚å¸¸: {e}")
                continue
        
        return "æ— ç­–ç•¥æˆåŠŸ"
    
    def strategy_extended_wait(self, driver) -> bool:
        """ç­–ç•¥1: å»¶é•¿ç­‰å¾…ç­–ç•¥"""
        try:
            # ç­‰å¾…å¯èƒ½çš„AJAXå†…å®¹åŠ è½½
            WebDriverWait(driver, 15).until(
                lambda d: len(d.find_elements(By.TAG_NAME, 'table')) > 0 or
                         len(d.find_elements(By.XPATH, "//div[contains(@class, 'spec')]")) > 0
            )
            time.sleep(3)
            return True
        except TimeoutException:
            return False
    
    def strategy_force_refresh(self, driver) -> bool:
        """ç­–ç•¥2: å¼ºåˆ¶åˆ·æ–°ç­–ç•¥"""
        try:
            current_url = driver.current_url
            driver.refresh()
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            time.sleep(2)
            return True
        except Exception:
            return False
    
    def strategy_multiple_scroll(self, driver) -> bool:
        """ç­–ç•¥3: å¤šæ¬¡æ»šåŠ¨ç­–ç•¥"""
        try:
            for i in range(3):
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(1)
                driver.execute_script("window.scrollTo(0, 0);")
                time.sleep(1)
            return True
        except Exception:
            return False
    
    def strategy_click_triggers(self, driver) -> bool:
        """ç­–ç•¥4: ç‚¹å‡»è§¦å‘å™¨ç­–ç•¥"""
        try:
            # å°è¯•ç‚¹å‡»"Show All"æˆ–"All"é€‰é¡¹
            all_selectors = [
                "//li[normalize-space(.)='All']",
                "//div[normalize-space(.)='All']",
                "//option[normalize-space(.)='All']",
                "//span[normalize-space(.)='All']",
                "//button[normalize-space(.)='All']",
                "//a[normalize-space(.)='All']",
                "//*[@role='option'][normalize-space(.)='All']",
                "//*[contains(@class,'option')][normalize-space(.)='All']",
                "//*[contains(@class,'menu-item')][normalize-space(.)='All']"
            ]
            
            clicked = False
            for selector in all_selectors:
                try:
                    elements = driver.find_elements(By.XPATH, selector)
                    for element in elements:
                        if element.is_displayed() and element.is_enabled():
                            self.logger.debug(f"æ‰¾åˆ°Allé€‰é¡¹: {element.text}")
                            element.click()
                            time.sleep(3)
                            clicked = True
                            break
                    if clicked:
                        break
                except Exception:
                    continue
            
            return clicked
        except Exception:
            return False
    
    def strategy_wait_elements(self, driver) -> bool:
        """ç­–ç•¥5: ç­‰å¾…å…ƒç´ ç­–ç•¥"""
        try:
            # ç­‰å¾…ç‰¹å®šå…ƒç´ å‡ºç°
            wait_selectors = [
                "//table[@class]",
                "//div[@class='specifications']",
                "//div[@class='product-details']",
                "//tr[td]"
            ]
            
            for selector in wait_selectors:
                try:
                    WebDriverWait(driver, 5).until(
                        EC.presence_of_element_located((By.XPATH, selector))
                    )
                    return True
                except TimeoutException:
                    continue
            
            return False
        except Exception:
            return False
    
    def strategy_final_scroll(self, driver) -> bool:
        """ç­–ç•¥6: æœ€ç»ˆæ»šåŠ¨ç­–ç•¥"""
        try:
            # æ‰§è¡Œå…¨é¢çš„é¡µé¢æ»šåŠ¨
            driver.execute_script("""
                var scrollHeight = Math.max(
                    document.body.scrollHeight,
                    document.body.offsetHeight,
                    document.documentElement.clientHeight,
                    document.documentElement.scrollHeight,
                    document.documentElement.offsetHeight
                );
                window.scrollTo(0, scrollHeight);
            """)
            time.sleep(2)
            
            driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(1)
            
            return True
        except Exception:
            return False
    
    def intelligent_table_selection(self, driver) -> Optional[Any]:
        """æ™ºèƒ½è¡¨æ ¼é€‰æ‹© - å®Œå…¨å¤åˆ¶test-09-1é€»è¾‘"""
        
        # ========== æ–¹å¼A: é€šè¿‡æ ‡é¢˜æŸ¥æ‰¾è¡¨æ ¼ ==========
        self.logger.debug("ğŸ” æ–¹å¼A: é€šè¿‡æ ‡é¢˜æŸ¥æ‰¾è¡¨æ ¼")
        
        title_selectors = [
            "//h1[contains(translate(text(), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'spec')]",
            "//h2[contains(translate(text(), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'spec')]",
            "//h3[contains(translate(text(), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'spec')]",
            "//h1[contains(translate(text(), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'product')]",
            "//h2[contains(translate(text(), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'product')]",
            "//div[contains(translate(text(), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'spec')]",
        ]
        
        for selector_idx, selector in enumerate(title_selectors):
            try:
                elements = driver.find_elements(By.XPATH, selector)
                self.logger.debug(f"é€‰æ‹©å™¨ {selector_idx+1}: æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
                
                for elem in elements:
                    if elem.is_displayed() and elem.text.strip():
                        # æŸ¥æ‰¾è¯¥å…ƒç´ é™„è¿‘çš„è¡¨æ ¼
                        try:
                            # å…ˆå°è¯•åœ¨åŒä¸€çˆ¶å®¹å™¨å†…æŸ¥æ‰¾
                            parent = elem.find_element(By.XPATH, "./..")
                            tables_in_parent = parent.find_elements(By.TAG_NAME, 'table')
                            
                            if not tables_in_parent:
                                # å°è¯•åœ¨åç»­å…„å¼Ÿå…ƒç´ ä¸­æŸ¥æ‰¾
                                tables_in_parent = elem.find_elements(By.XPATH, "./following-sibling::*//table")
                            
                            if not tables_in_parent:
                                # å°è¯•åœ¨æ•´ä¸ªæ–‡æ¡£ä¸­æŸ¥æ‰¾è¯¥å…ƒç´ ä¹‹åçš„è¡¨æ ¼
                                tables_in_parent = elem.find_elements(By.XPATH, "./following::table")
                            
                            if tables_in_parent:
                                candidate_table = tables_in_parent[0]
                                
                                # æ£€æŸ¥è¡¨æ ¼æ˜¯å¦çœŸçš„åŒ…å«äº§å“æ•°æ®
                                if self.validate_table_content(candidate_table):
                                    self.logger.debug("âœ… é€šè¿‡æ ‡é¢˜æ‰¾åˆ°åˆé€‚çš„è¡¨æ ¼")
                                    return candidate_table
                                    
                        except Exception as e:
                            self.logger.debug(f"åˆ†æå…ƒç´ é™„è¿‘è¡¨æ ¼æ—¶å‡ºé”™: {e}")
                            
            except Exception as e:
                self.logger.debug(f"é€‰æ‹©å™¨ {selector_idx+1} å‡ºé”™: {e}")
        
        # ========== æ–¹å¼B: è¡¨æ ¼è¯„åˆ†æœºåˆ¶ ==========
        self.logger.debug("ğŸ” æ–¹å¼B: è¡¨æ ¼è¯„åˆ†æœºåˆ¶")
        
        tables = driver.find_elements(By.TAG_NAME, 'table')
        
        if not tables:
            self.logger.warning("é¡µé¢ä¸­æœªæ‰¾åˆ°ä»»ä½•è¡¨æ ¼")
            return None
        
        best_table = None
        best_score = 0
        
        self.logger.debug(f"å‘ç° {len(tables)} ä¸ªè¡¨æ ¼ï¼Œå¼€å§‹è¯„åˆ†...")
        
        for i, table in enumerate(tables):
            if not table.is_displayed():
                continue
            
            score = self.score_table_for_product_specs(table)
            self.logger.debug(f"è¡¨æ ¼ {i+1} è¯„åˆ†: {score}")
            
            if score > best_score:
                best_score = score
                best_table = table
                self.logger.debug(f"âœ… è¡¨æ ¼ {i+1} æˆä¸ºæœ€ä½³å€™é€‰ (è¯„åˆ†: {score})")
        
        if best_table and best_score > 0:
            self.logger.debug(f"æœ€ç»ˆé€‰æ‹©è¡¨æ ¼ï¼Œè¯„åˆ†: {best_score}")
            return best_table
        else:
            self.logger.warning("æ‰€æœ‰è¡¨æ ¼è¯„åˆ†å‡ä¸º0ï¼Œæœªæ‰¾åˆ°åˆé€‚çš„è¡¨æ ¼")
            return None
    
    def validate_table_content(self, table) -> bool:
        """éªŒè¯è¡¨æ ¼æ˜¯å¦åŒ…å«æœ‰æ„ä¹‰çš„äº§å“æ•°æ®"""
        try:
            rows = table.find_elements(By.TAG_NAME, 'tr')
            if len(rows) < 2:
                return False
            
            # æ£€æŸ¥å‰å‡ è¡Œæ˜¯å¦æœ‰éç©ºä¸”æœ‰æ„ä¹‰çš„å†…å®¹
            meaningful_rows = 0
            for row in rows[:5]:
                cells = row.find_elements(By.CSS_SELECTOR, 'td, th')
                cell_texts = [cell.text.strip() for cell in cells]
                non_empty_cells = [text for text in cell_texts if text and len(text) > 1]
                
                if len(non_empty_cells) >= 2:
                    meaningful_rows += 1
            
            return meaningful_rows >= 2
        except:
            return False
    
    def score_table_for_product_specs(self, table) -> int:
        """ä¸ºè¡¨æ ¼è¯„åˆ† - å®Œå…¨å¤åˆ¶test-09-1çš„è¯„åˆ†é€»è¾‘"""
        score = 0
        
        try:
            rows = table.find_elements(By.TAG_NAME, 'tr')
            if len(rows) < 2:
                return 0
            
            for row in rows[:10]:  # åªæ£€æŸ¥å‰10è¡Œ
                cells = row.find_elements(By.CSS_SELECTOR, 'td, th')
                cell_texts = [cell.text.strip() for cell in cells]
                non_empty_cells = [text for text in cell_texts if text and len(text) > 1]
                
                if len(non_empty_cells) >= 2:
                    score += len(non_empty_cells)
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«äº§å“ç¼–å·ç›¸å…³è¯æ±‡
                    for text in cell_texts:
                        text_lower = text.lower()
                        if any(keyword in text_lower for keyword in self.reference_keywords):
                            score += 10
                        # æ£€æŸ¥æ˜¯å¦çœ‹èµ·æ¥åƒäº§å“ç¼–å·
                        if self.is_likely_product_reference(text):
                            score += 5
            
            return score
        except:
            return 0
    
    def extract_table_specifications(self, table) -> Tuple[List[Dict[str, Any]], List[str]]:
        """
        ä»è¡¨æ ¼æå–è§„æ ¼ - å®Œå…¨å¤åˆ¶test-09-1çš„è¡¨æ ¼å¤„ç†é€»è¾‘
        """
        specifications = []
        all_headers = []
        seen_references = set()
        
        try:
            rows = table.find_elements(By.TAG_NAME, 'tr')
            if len(rows) < 1:
                return [], []
            
            # ========== æ£€æµ‹è¡¨æ ¼ç±»å‹ï¼ˆçºµå‘ vs æ¨ªå‘ï¼‰==========
            is_vertical_table = False
            
            # æ£€æŸ¥å‰å‡ è¡Œæ˜¯å¦éƒ½æ˜¯2åˆ—æ ¼å¼
            two_col_count = 0
            for i, row in enumerate(rows[:5]):  # æ£€æŸ¥å‰5è¡Œ
                cells = row.find_elements(By.CSS_SELECTOR, 'td, th')
                if len(cells) == 2:
                    two_col_count += 1
            
            if two_col_count >= 3:  # å¦‚æœè‡³å°‘3è¡Œéƒ½æ˜¯2åˆ—ï¼Œå¯èƒ½æ˜¯çºµå‘è¡¨æ ¼
                is_vertical_table = True
                self.logger.debug("æ£€æµ‹åˆ°çºµå‘è¡¨æ ¼æ ¼å¼ï¼ˆå±æ€§-å€¼å¯¹ï¼‰")
            
            # ========== çºµå‘è¡¨æ ¼å¤„ç† ==========
            if is_vertical_table:
                self.logger.debug("ä»çºµå‘è¡¨æ ¼æå–æ•°æ®...")
                for i, row in enumerate(rows):
                    cells = row.find_elements(By.CSS_SELECTOR, 'td, th')
                    if len(cells) != 2:
                        continue
                    
                    prop_name = cells[0].text.strip()
                    prop_value = cells[1].text.strip()
                    
                    if prop_value and len(prop_value) >= 2 and prop_value not in seen_references:
                        # æ™ºèƒ½åˆ¤æ–­ï¼šå¦‚æœçœ‹èµ·æ¥åƒç¼–å·ï¼ˆåŒ…å«æ•°å­—æˆ–ç‰¹æ®Šæ ¼å¼ï¼‰
                        if self.is_likely_product_reference(prop_value):
                            spec_info = {
                                'reference': prop_value,
                                'row_index': i,
                                'dimensions': '',
                                'weight': '',
                                'property_name': prop_name,
                                'table_type': 'vertical',
                                'parameters': {prop_name: prop_value}
                            }
                            
                            specifications.append(spec_info)
                            seen_references.add(prop_value)
                            all_headers.append(prop_name)
                            self.logger.debug(f"æå–è§„æ ¼: {prop_value} (æ¥è‡ª: {prop_name})")
            
            # ========== æ¨ªå‘è¡¨æ ¼å¤„ç† ==========
            else:
                self.logger.debug("æ£€æµ‹åˆ°æ¨ªå‘è¡¨æ ¼æ ¼å¼")
                
                # æŸ¥æ‰¾è¡¨å¤´è¡Œ
                header_row_index = -1
                header_cells = []
                
                for i, row in enumerate(rows):
                    cells = row.find_elements(By.CSS_SELECTOR, 'td, th')
                    if not cells:
                        continue
                    
                    # å¦‚æœæ˜¯thå…ƒç´ ï¼Œå¾ˆå¯èƒ½æ˜¯è¡¨å¤´
                    th_cells = row.find_elements(By.TAG_NAME, 'th')
                    is_header_row = len(th_cells) == len(cells) and len(th_cells) > 0
                    
                    if is_header_row:
                        header_row_index = i
                        header_cells = [cell.text.strip() for cell in cells]
                        all_headers = header_cells
                        self.logger.debug(f"è¯†åˆ«è¡¨å¤´è¡Œ {i+1}: {header_cells[:5]}...")
                        break
                
                # ç¡®å®šäº§å“ç¼–å·åˆ—ï¼ˆæ ¹æ®åˆ—åï¼‰
                product_columns = []
                if header_cells:
                    for j, header in enumerate(header_cells):
                        header_lower = header.lower()
                        
                        # åŒ¹é…å„ç§è¯­è¨€çš„äº§å“ç¼–å·åˆ—å
                        for keyword in self.reference_keywords:
                            if keyword in header_lower:
                                product_columns.append(j)
                                self.logger.debug(f"è¯†åˆ«äº§å“ç¼–å·åˆ— {j+1}: '{header}'")
                                break
                        
                    # ä½¿ç”¨ç¬¬ä¸€ä¸ªäº§å“ç¼–å·åˆ—
                    if len(product_columns) > 1:
                        product_columns = product_columns[:1]
                
                # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°äº§å“ç¼–å·åˆ—ï¼Œä½¿ç”¨æ™ºèƒ½åˆ¤æ–­
                use_smart_detection = not product_columns
                
                # æå–æ•°æ®è¡Œ
                for i, row in enumerate(rows):
                    if i <= header_row_index:  # è·³è¿‡è¡¨å¤´åŠä¹‹å‰çš„è¡Œ
                        continue
                        
                    cells = row.find_elements(By.CSS_SELECTOR, 'td, th')
                    if not cells:
                        continue
                    
                    cell_texts = [cell.text.strip() for cell in cells]
                    
                    # æ„å»ºå‚æ•°å­—å…¸
                    parameters = {}
                    for j, cell_text in enumerate(cell_texts):
                        if j < len(header_cells) and header_cells[j] and cell_text:
                            parameters[header_cells[j]] = cell_text
                    
                    # æŸ¥æ‰¾å¯èƒ½çš„äº§å“ç¼–å·
                    found_reference = None
                    if use_smart_detection:
                        # æ™ºèƒ½æ£€æµ‹æ¨¡å¼ï¼šæ‰«ææ‰€æœ‰å•å…ƒæ ¼
                        for j, cell_text in enumerate(cell_texts):
                            if self.is_likely_product_reference(cell_text) and cell_text not in seen_references:
                                found_reference = cell_text
                                break
                    else:
                        # åˆ—ç´¢å¼•æ¨¡å¼ï¼šåªæ£€æŸ¥äº§å“ç¼–å·åˆ—
                        for col_idx in product_columns:
                            if col_idx < len(cell_texts):
                                cell_text = cell_texts[col_idx]
                                if cell_text and len(cell_text) >= 2 and cell_text not in seen_references:
                                    found_reference = cell_text
                                    break
                    
                    if found_reference:
                        spec_info = {
                            'reference': found_reference,
                            'row_index': i,
                            'dimensions': self.extract_dimensions_from_cells(cell_texts),
                            'weight': self.extract_weight_from_cells(cell_texts),
                            'table_type': 'horizontal',
                            'all_cells': cell_texts,
                            'headers': header_cells,
                            'parameters': parameters
                        }
                        
                        specifications.append(spec_info)
                        seen_references.add(found_reference)
                        self.logger.debug(f"æå–è§„æ ¼: {found_reference}")
            
            return specifications, all_headers
            
        except Exception as e:
            self.logger.error(f"è¡¨æ ¼è§„æ ¼æå–å¤±è´¥: {e}")
            return [], []
    
    def is_likely_product_reference(self, text: str, debug_enabled: bool = False) -> bool:
        """æ™ºèƒ½åˆ¤æ–­æ–‡æœ¬æ˜¯å¦å¯èƒ½æ˜¯äº§å“ç¼–å· - å®Œå…¨å¤åˆ¶test-09-1é€»è¾‘"""
        if debug_enabled:
            self.logger.debug(f"åˆ†ææ–‡æœ¬: '{text}'")
        
        # æ”¾å®½é•¿åº¦é™åˆ¶åˆ°2ä¸ªå­—ç¬¦ï¼Œæ”¯æŒåƒ'SD'è¿™æ ·çš„çŸ­äº§å“ç¼–å·
        if not text or len(text) < 2:
            if debug_enabled:
                self.logger.debug(f"âŒ æ–‡æœ¬ä¸ºç©ºæˆ–é•¿åº¦ä¸è¶³2: {len(text) if text else 0}")
            return False
        
        # æ˜æ˜¾çš„æ’é™¤é¡¹
        exclude_patterns = [
            r'^https?://',  # URL
            r'^www\.',      # ç½‘å€
            r'@',           # é‚®ç®±
            r'^\d{4}-\d{2}-\d{2}',  # æ—¥æœŸæ ¼å¼
            r'^\+?\d{10,}$',  # ç”µè¯å·ç 
        ]
        
        for pattern in exclude_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                if debug_enabled:
                    self.logger.debug(f"âŒ åŒ¹é…æ’é™¤æ¨¡å¼: {pattern}")
                return False
        
        # æ’é™¤çº¯æè¿°æ€§æ–‡æœ¬ï¼ˆå…¨æ˜¯å¸¸è§è‹±æ–‡å•è¯ï¼‰ï¼Œä½†ä¿ç•™'N/A'ç­‰å¯èƒ½çš„äº§å“ç¼–å·
        common_words = [
            'description', 'manufacturer', 'material', 'color', 'size',
            'weight', 'length', 'width', 'height', 'diameter', 'thickness'
        ]
        
        text_lower = text.lower()
        # ä¿ç•™ 'N/A', 'TBD', 'TBA' ç­‰å¯èƒ½æ˜¯äº§å“ç¼–å·çš„å€¼
        special_codes = ['n/a', 'na', 'tbd', 'tba', 'pending', 'standard', 'default']
        
        if text_lower in special_codes:
            if debug_enabled:
                self.logger.debug(f"âœ… ä¿ç•™ç‰¹æ®Šç¼–å·: {text_lower}")
            return True  # ä¿ç•™è¿™äº›ç‰¹æ®Šç¼–å·
        
        if any(text_lower == word for word in common_words):
            if debug_enabled:
                self.logger.debug(f"âŒ æ˜¯å¸¸è§æè¿°è¯: {text_lower}")
            return False
        
        # ç§¯æçš„æŒ‡æ ‡ï¼šåŒ…å«è¿™äº›ç‰¹å¾çš„æ›´å¯èƒ½æ˜¯äº§å“ç¼–å·
        positive_indicators = 0
        indicators_found = []
        
        # 1. åŒ…å«æ•°å­— (+2åˆ†)
        if any(c.isdigit() for c in text):
            positive_indicators += 2
            indicators_found.append("åŒ…å«æ•°å­—(+2)")
        
        # 2. åŒ…å«è¿å­—ç¬¦æˆ–ä¸‹åˆ’çº¿ (+1åˆ†)
        if '-' in text or '_' in text:
            positive_indicators += 1
            indicators_found.append("åŒ…å«è¿å­—ç¬¦/ä¸‹åˆ’çº¿(+1)")
        
        # 3. åŒ…å«å¤§å†™å­—æ¯ï¼ˆä¸æ˜¯å¥å­å¼€å¤´ï¼‰(+1åˆ†)
        if any(c.isupper() for c in text[1:]):
            positive_indicators += 1
            indicators_found.append("åŒ…å«å¤§å†™å­—æ¯(+1)")
        
        # 4. é•¿åº¦é€‚ä¸­ï¼ˆ2-50ä¸ªå­—ç¬¦ï¼‰(+1åˆ†)
        if 2 <= len(text) <= 50:
            positive_indicators += 1
            indicators_found.append("é•¿åº¦é€‚ä¸­(+1)")
        
        # 5. ç‰¹æ®Šæ ¼å¼æ¨¡å¼ (+2åˆ†)
        special_patterns = [
            r'^\d+-\d+-\d+$',  # 5-14230-00
            r'^[A-Z]+\d+',     # SLS50, DIN787
            r'^\d+[A-Z]+',     # 14W, 230V
            r'^[A-Z0-9]+[-_][A-Z0-9]+',  # QAAMC10A050S
            r'^[A-Z]{2,}\d{2,}',  # DIN787, EN561
            r'^USC\d+T\d+$',   # USC201T20, USC202T20ç­‰NTNäº§å“ç¼–å·
        ]
        
        for pattern in special_patterns:
            if re.match(pattern, text):
                positive_indicators += 2
                indicators_found.append(f"ç‰¹æ®Šæ ¼å¼æ¨¡å¼(+2): {pattern}")
                break
        
        result = positive_indicators >= 3
        
        if debug_enabled:
            self.logger.debug(f"æŒ‡æ ‡æ€»åˆ†: {positive_indicators}")
            self.logger.debug(f"æ‰¾åˆ°æŒ‡æ ‡: {indicators_found}")
            self.logger.debug(f"æœ€ç»ˆåˆ¤æ–­: {'âœ… æ˜¯äº§å“ç¼–å·' if result else 'âŒ ä¸æ˜¯äº§å“ç¼–å·'}")
        
        return result
    
    def extract_dimensions_from_cells(self, cells: List[str]) -> str:
        """ä»å•å…ƒæ ¼ä¸­æå–å°ºå¯¸ä¿¡æ¯"""
        for cell_text in cells:
            dimension_match = re.search(r'\d+x\d+x?\d*', cell_text)
            if dimension_match:
                return dimension_match.group()
        return ''
    
    def extract_weight_from_cells(self, cells: List[str]) -> str:
        """ä»å•å…ƒæ ¼ä¸­æå–é‡é‡æˆ–é•¿åº¦ä¿¡æ¯"""
        for cell_text in cells:
            measure_match = re.search(r'(\d+[,\.]\d+|\d+)\s*(mm|kg|m|cm)', cell_text.lower())
            if measure_match:
                return measure_match.group()
        return ''
    
    def generate_specification_urls(self, base_product_info: Dict[str, Any], part_number: str) -> List[str]:
        """ç”Ÿæˆè§„æ ¼URL - å¤åˆ¶test-09-1é€»è¾‘"""
        try:
            if not part_number or part_number == 'unknown':
                return []
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            query_params = base_product_info.get('query_params', {}).copy()
            
            # æ·»åŠ PartNumberå‚æ•°
            query_params['PartNumber'] = [part_number]
            
            # ç”ŸæˆURLåˆ—è¡¨
            urls = []
            
            # åŸºç¡€URL
            base_url = f"https://www.traceparts.cn/en/product/{base_product_info['base_product_name']}"
            
            # æ„å»ºå®Œæ•´çš„æŸ¥è¯¢å­—ç¬¦ä¸²
            query_string = urlencode(query_params, doseq=True)
            full_url = f"{base_url}?{query_string}"
            
            urls.append(full_url)
            
            return urls
            
        except Exception as e:
            self.logger.error(f"URLç”Ÿæˆå¤±è´¥: {e}")
            return []

    # ========== å…¼å®¹æ€§æ–¹æ³•ï¼ˆä¿æŒä¸ç°æœ‰pipelineçš„æ¥å£ä¸€è‡´ï¼‰==========
    
    def detect_page_type(self, url: str, driver) -> str:
        """ä¿ç•™åŸæœ‰çš„é¡µé¢ç±»å‹æ£€æµ‹æ–¹æ³•ï¼Œä½†ç°åœ¨ç»Ÿä¸€ä½¿ç”¨æ–°é€»è¾‘"""
        return "test-09-1-unified"
    
    def _parse_standard_table(self, driver, url: str) -> List[Dict[str, Any]]:
        """ä¿ç•™åŸæœ‰æ–¹æ³•åï¼Œä½†ä½¿ç”¨æ–°é€»è¾‘"""
        return self.parse_specifications(driver, url)