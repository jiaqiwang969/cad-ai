#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆäº§å“è§„æ ¼çˆ¬å–å™¨
=================
æ•´åˆæ‰€æœ‰è§£å†³æ–¹æ¡ˆçš„æœ€ç»ˆç‰ˆæœ¬
"""

import time
import logging
from typing import List, Dict, Any, Optional
from selenium import webdriver
from selenium.webdriver.common.by import By
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from src.crawler.adaptive_specs_parser import AdaptiveSpecsParser
from src.utils.smart_waiter import SmartWaiter
from src.utils.anti_detection import AntiDetectionManager
from src.utils.smart_thread_pool import SmartThreadPool, Task, TaskPriority


class EnhancedSpecificationsCrawler:
    """å¢å¼ºç‰ˆè§„æ ¼çˆ¬å–å™¨"""
    
    def __init__(self, max_workers: int = 12, log_level: int = logging.INFO):
        self.max_workers = max_workers
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(log_level)
        
        # æ ¸å¿ƒç»„ä»¶
        self.adaptive_parser = AdaptiveSpecsParser(self.logger)
        self.anti_detection = AntiDetectionManager(self.logger)
        self.thread_pool = SmartThreadPool(max_workers, self.logger)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_processed': 0,
            'successful_extractions': 0,
            'failed_extractions': 0,
            'vendor_breakdown': {},
            'error_categories': {}
        }
    
    def extract_batch_specifications(self, product_urls: List[str]) -> Dict[str, Any]:
        """æ‰¹é‡æå–äº§å“è§„æ ¼ - å¢å¼ºç‰ˆ"""
        if not product_urls:
            return {'results': [], 'summary': {}}
        
        self.logger.info(f"ğŸš€ å¼€å§‹å¢å¼ºç‰ˆæ‰¹é‡è§„æ ¼æå–")
        self.logger.info(f"   ğŸ“¦ äº§å“æ•°é‡: {len(product_urls)}")
        self.logger.info(f"   ğŸ§µ æœ€å¤§å¹¶å‘: {self.max_workers}")
        
        start_time = time.time()
        results = []
        futures = []
        
        # åˆ›å»ºä»»åŠ¡å¹¶æäº¤
        for i, url in enumerate(product_urls):
            vendor = self.anti_detection.detect_vendor_from_url(url)
            
            # æ ¹æ®ä¾›åº”å•†è®¾ç½®ä¼˜å…ˆçº§
            if vendor == 'apostoli':
                priority = TaskPriority.HIGH  # apostoliæˆåŠŸç‡é«˜ï¼Œä¼˜å…ˆå¤„ç†
            elif vendor == 'industrietechnik':
                priority = TaskPriority.NORMAL  # industrietechnikéœ€è¦ç‰¹æ®Šå¤„ç†
            else:
                priority = TaskPriority.NORMAL
            
            task = Task(
                id=f"spec_{i}",
                url=url,
                vendor=vendor,
                priority=priority
            )
            
            # æäº¤ä»»åŠ¡
            future = self.thread_pool.submit_task(task, self._process_single_product)
            futures.append(future)
        
        # æ”¶é›†ç»“æœ
        for future in futures:
            try:
                result = future.result(timeout=60)  # æ¯ä¸ªä»»åŠ¡æœ€å¤šç­‰å¾…60ç§’
                results.append(result['result'] if result['success'] else {
                    'product_url': result.get('task_id', 'unknown'),
                    'specifications': [],
                    'count': 0,
                    'success': False,
                    'error': result.get('error', 'Unknown error')
                })
            except Exception as e:
                self.logger.error(f"âŒ ä»»åŠ¡ç»“æœè·å–å¤±è´¥: {e}")
                results.append({
                    'product_url': 'unknown',
                    'specifications': [],
                    'count': 0,
                    'success': False,
                    'error': str(e)
                })
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        self.thread_pool.wait_for_completion(timeout=300)
        
        # ç»Ÿè®¡ç»“æœ
        total_time = time.time() - start_time
        success_count = sum(1 for r in results if r.get('success', False))
        total_specs = sum(r.get('count', 0) for r in results)
        
        # è·å–æ€§èƒ½ç»Ÿè®¡
        pool_stats = self.thread_pool.get_performance_stats()
        
        self.logger.info(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ:")
        self.logger.info(f"   â±ï¸  æ€»è€—æ—¶: {total_time:.1f}s")
        self.logger.info(f"   ğŸ“Š æˆåŠŸç‡: {success_count}/{len(product_urls)} ({success_count/len(product_urls)*100:.1f}%)")
        self.logger.info(f"   ğŸ“‹ æ€»è§„æ ¼æ•°: {total_specs}")
        self.logger.info(f"   ğŸ§µ çº¿ç¨‹æ± ç»Ÿè®¡: {pool_stats}")
        
        return {
            'results': results,
            'summary': {
                'total_products': len(product_urls),
                'successful_products': success_count,
                'failed_products': len(product_urls) - success_count,
                'total_specifications': total_specs,
                'processing_time': total_time,
                'success_rate': success_count / len(product_urls) if product_urls else 0,
                'avg_time_per_product': total_time / len(product_urls) if product_urls else 0,
                'thread_pool_stats': pool_stats
            }
        }
    
    def _process_single_product(self, task: Task, thread_resources: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªäº§å“ - ä½¿ç”¨çº¿ç¨‹èµ„æº"""
        try:
            driver = thread_resources['driver']
            waiter = thread_resources['waiter']
            anti_detection = thread_resources['anti_detection']
            
            self.logger.debug(f"ğŸ” å¤„ç†äº§å“: {task.url}")
            
            # åº”ç”¨è¯·æ±‚é™æµ
            anti_detection.apply_request_throttling(task.vendor)
            
            # è®¿é—®é¡µé¢
            driver.get(task.url)
            
            # æ™ºèƒ½ç­‰å¾…é¡µé¢å°±ç»ª
            page_ready = waiter.wait_for_page_ready(task.vendor)
            if not page_ready:
                self.logger.warning(f"âš ï¸ é¡µé¢æœªå°±ç»ª: {task.url}")
            
            # æ¨¡æ‹Ÿäººç±»è¡Œä¸º
            anti_detection.simulate_human_behavior(driver)
            
            # ç­‰å¾…è§„æ ¼æ•°æ®
            specs_ready = waiter.adaptive_wait_for_specs(task.vendor)
            if not specs_ready:
                self.logger.warning(f"âš ï¸ è§„æ ¼æ•°æ®æœªå°±ç»ª: {task.url}")
            
            # ä½¿ç”¨è‡ªé€‚åº”è§£æå™¨æå–è§„æ ¼
            specifications = self.adaptive_parser.parse_specifications(driver, task.url)
            
            # è®°å½•ç»“æœ
            success = len(specifications) > 0
            
            if success:
                self.logger.info(f"âœ… è§„æ ¼æå–æˆåŠŸ: {task.url} -> {len(specifications)} è§„æ ¼")
            else:
                self.logger.warning(f"âŒ è§„æ ¼æå–å¤±è´¥: {task.url} -> 0 è§„æ ¼")
            
            # ç›´æ¥è¿”å›adaptive_parseræå–çš„è§„æ ¼æ•°æ®ï¼ˆå·²ç»æ˜¯test-09-1å…¼å®¹æ ¼å¼ï¼‰
            return {
                'product_url': task.url,
                'specifications': specifications,  # ç›´æ¥ä½¿ç”¨adaptive_parserçš„ç»“æœ
                'count': len(specifications),
                'success': success,
                'vendor': task.vendor,
                'page_type': self.adaptive_parser.detect_page_type(task.url, driver),
                'extraction_method': 'enhanced_adaptive'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ äº§å“å¤„ç†å¼‚å¸¸: {task.url} - {e}")
            return {
                'product_url': task.url,
                'specifications': [],
                'count': 0,
                'success': False,
                'error': str(e),
                'vendor': task.vendor
            }
    
    def extract_specifications(self, product_url: str) -> Dict[str, Any]:
        """å•äº§å“æå–æ¥å£ - ç›´æ¥åŒæ­¥å¤„ç†ï¼Œé¿å…åŒå±‚å¹¶å‘å†²çª"""
        try:
            self.logger.debug(f"ğŸ” å¼€å§‹å¤„ç†å•ä¸ªäº§å“: {product_url}")
            
            # æ£€æµ‹ä¾›åº”å•†
            vendor = self.anti_detection.detect_vendor_from_url(product_url)
            
            # åº”ç”¨è¯·æ±‚é™æµï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
            self.anti_detection.apply_request_throttling(vendor)
            
            # åˆ›å»ºä¸´æ—¶driverï¼ˆç®€å•åŒæ­¥æ¨¡å¼ï¼‰
            from selenium.webdriver.chrome.options import Options
            options = Options()
            options.add_argument('--headless')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            options.add_argument('--window-size=1920,1080')
            options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
            
            driver = webdriver.Chrome(options=options)
            
            try:
                # è®¿é—®é¡µé¢
                driver.get(product_url)
                
                # åˆ›å»ºä¸´æ—¶waiter
                waiter = SmartWaiter(driver, self.logger)
                
                # æ™ºèƒ½ç­‰å¾…é¡µé¢å°±ç»ª
                page_ready = waiter.wait_for_page_ready(vendor)
                if not page_ready:
                    self.logger.warning(f"âš ï¸ é¡µé¢æœªå°±ç»ª: {product_url}")
                
                # æ¨¡æ‹Ÿäººç±»è¡Œä¸º
                self.anti_detection.simulate_human_behavior(driver)
                
                # ç­‰å¾…è§„æ ¼æ•°æ®
                specs_ready = waiter.adaptive_wait_for_specs(vendor)
                if not specs_ready:
                    self.logger.warning(f"âš ï¸ è§„æ ¼æ•°æ®æœªå°±ç»ª: {product_url}")
                
                # ä½¿ç”¨è‡ªé€‚åº”è§£æå™¨æå–è§„æ ¼ï¼ˆtest-09-1é€»è¾‘ï¼‰
                specifications = self.adaptive_parser.parse_specifications(driver, product_url)
                
                # è®°å½•ç»“æœ
                success = len(specifications) > 0
                
                if success:
                    self.logger.debug(f"âœ… è§„æ ¼æå–æˆåŠŸ: {product_url} -> {len(specifications)} è§„æ ¼")
                else:
                    self.logger.debug(f"âŒ è§„æ ¼æå–å¤±è´¥: {product_url} -> 0 è§„æ ¼")
                
                # è¿”å›ä¸test-09-1å…¼å®¹çš„æ ¼å¼
                return {
                    'product_url': product_url,
                    'specifications': specifications,  # AdaptiveSpecsParserå·²è¿”å›test-09-1æ ¼å¼
                    'count': len(specifications),
                    'success': success,
                    'vendor': vendor,
                    'page_type': self.adaptive_parser.detect_page_type(product_url, driver),
                    'extraction_method': 'enhanced_adaptive_sync'
                }
                
            finally:
                driver.quit()
                
        except Exception as e:
            self.logger.error(f"âŒ å•äº§å“å¤„ç†å¼‚å¸¸: {product_url} - {e}")
            return {
                'product_url': product_url,
                'specifications': [],
                'count': 0,
                'success': False,
                'error': str(e),
                'vendor': self.anti_detection.detect_vendor_from_url(product_url)
            }
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        pool_stats = self.thread_pool.get_performance_stats()
        
        return {
            'crawler_stats': self.stats,
            'thread_pool_stats': pool_stats,
            'timestamp': time.time()
        }
    
    def close(self):
        """å…³é—­çˆ¬å–å™¨"""
        self.logger.info("ğŸ›‘ å…³é—­å¢å¼ºç‰ˆè§„æ ¼çˆ¬å–å™¨...")
        self.thread_pool.shutdown()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


def main():
    """æµ‹è¯•å…¥å£"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(name)s: %(message)s'
    )
    
    # æµ‹è¯•URL
    test_urls = [
        'https://www.traceparts.cn/en/product/item-industrietechnik-gmbh-stairway-assembly-set-pp-30deg?CatalogPath=TRACEPARTS%3ATP12002018002&Product=30-12112020-084493',
        'https://www.traceparts.cn/en/product/apostoli-f30?CatalogPath=TRACEPARTS%3ATP12002018003004&Product=90-23112023-059945'
    ]
    
    with EnhancedSpecificationsCrawler(max_workers=4) as crawler:
        results = crawler.extract_batch_specifications(test_urls)
        
        print("\n" + "="*60)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ‘˜è¦")
        print("="*60)
        
        summary = results['summary']
        print(f"æ€»äº§å“æ•°: {summary['total_products']}")
        print(f"æˆåŠŸ: {summary['successful_products']}")
        print(f"å¤±è´¥: {summary['failed_products']}")
        print(f"æˆåŠŸç‡: {summary['success_rate']:.1%}")
        print(f"æ€»è§„æ ¼æ•°: {summary['total_specifications']}")
        print(f"å¤„ç†æ—¶é—´: {summary['processing_time']:.1f}s")


if __name__ == '__main__':
    main()