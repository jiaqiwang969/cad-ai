#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ ¸ä¼˜åŒ–ç‰ˆäº§å“è§„æ ¼çˆ¬å–æ¨¡å—
=========================
é’ˆå¯¹å¤šæ ¸CPUä¼˜åŒ–ï¼Œæä¾›æ›´å¥½çš„å¹¶å‘æ€§èƒ½
ä¿æŒæ•°æ®å®Œæ•´æ€§ï¼Œä¸ä¸¢å¤±ä»»ä½•è§„æ ¼ä¿¡æ¯
"""

import re
import time
import threading
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from queue import Queue
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException

from config.settings import Settings
from config.logging_config import LoggerMixin
from src.utils.browser_manager import create_browser_manager
from src.utils.net_guard import register_success, register_fail


class MultiCoreSpecificationsCrawler(LoggerMixin):
    """å¤šæ ¸ä¼˜åŒ–çš„äº§å“è§„æ ¼çˆ¬å–å™¨"""
    
    def __init__(self, max_workers: int = None, browser_pool_size: int = None):
        """
        åˆå§‹åŒ–å¤šæ ¸è§„æ ¼çˆ¬å–å™¨
        
        Args:
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°ï¼ˆé»˜è®¤ä½¿ç”¨CPUæ ¸å¿ƒæ•°ï¼‰
            browser_pool_size: æµè§ˆå™¨æ± å¤§å°ï¼ˆé»˜è®¤ä¸º max_workers * 1.5ï¼‰
        """
        import os
        self.max_workers = max_workers or min(32, (os.cpu_count() or 1) * 2)
        self.browser_pool_size = browser_pool_size or int(self.max_workers * 1.5)
        
        # åˆ›å»ºæ›´å¤§çš„æµè§ˆå™¨æ± 
        self.browser_manager = create_browser_manager(
            browser_type='selenium',
            pool_size=self.browser_pool_size
        )
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'total_processed': 0,
            'success_count': 0,
            'fail_count': 0,
            'total_specs': 0,
            'start_time': None,
            'lock': threading.Lock()
        }
        
        # åŠ¨æ€è¶…æ—¶ç®¡ç†
        self.timeout_manager = DynamicTimeoutManager()
        
        self.logger.info(f"å¤šæ ¸çˆ¬è™«åˆå§‹åŒ–: workers={self.max_workers}, pool={self.browser_pool_size}")
    
    def _is_valid_product_reference(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„äº§å“å‚è€ƒå·ï¼ˆä¸åŸç‰ˆç›¸åŒï¼‰"""
        if not text or len(text) < 3:
            return False
        
        exclude_keywords = [
            'aluminum', 'description', 'links', 
            'manufacturer', 'product page', 'material',
            'weight', 'dimension', 'color'
        ]
        
        text_lower = text.lower()
        if any(keyword in text_lower for keyword in exclude_keywords):
            return False
        
        has_letter = bool(re.search(r'[A-Za-z]', text))
        has_number = bool(re.search(r'\d', text))
        
        if len(text) > 60:
            return False
        
        return has_letter and has_number
    
    def _smart_wait_for_content(self, driver, timeout: int = None) -> bool:
        """æ™ºèƒ½ç­‰å¾…é¡µé¢å†…å®¹åŠ è½½"""
        timeout = timeout or self.timeout_manager.get_timeout()
        
        try:
            # ç­‰å¾…ä¸»è¦å†…å®¹å®¹å™¨
            wait = WebDriverWait(driver, timeout)
            
            # ç­–ç•¥1ï¼šç­‰å¾…è¡¨æ ¼å‡ºç°
            try:
                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'table, .table')))
                return True
            except TimeoutException:
                pass
            
            # ç­–ç•¥2ï¼šç­‰å¾…äº§å“ä¿¡æ¯å®¹å™¨
            try:
                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '[class*="product"], [class*="spec"]')))
                return True
            except TimeoutException:
                pass
            
            # ç­–ç•¥3ï¼šç­‰å¾…ä»»ä½•è¡¨æ ¼è¡Œ
            try:
                wait.until(EC.presence_of_element_located((By.TAG_NAME, 'tr')))
                return True
            except TimeoutException:
                pass
            
            return False
            
        except Exception as e:
            self.logger.debug(f"æ™ºèƒ½ç­‰å¾…å¤±è´¥: {e}")
            return False
    
    def _optimized_scroll(self, driver):
        """ä¼˜åŒ–çš„æ»šåŠ¨ç­–ç•¥"""
        # ä½¿ç”¨æ›´å¿«çš„æ»šåŠ¨æ–¹å¼
        driver.execute_script("""
            // å¿«é€Ÿæ»šåŠ¨åˆ°åº•éƒ¨
            window.scrollTo(0, document.body.scrollHeight);
            
            // è§¦å‘æ‡’åŠ è½½
            var event = new Event('scroll');
            window.dispatchEvent(event);
        """)
        
        # åªç­‰å¾…å¿…è¦çš„æ—¶é—´
        time.sleep(0.5)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°å†…å®¹åŠ è½½
        new_height = driver.execute_script("return document.body.scrollHeight")
        return new_height
    
    def _parallel_extract_specifications(self, product_url: str) -> Dict[str, Any]:
        """å¹¶è¡Œæå–å•ä¸ªäº§å“çš„è§„æ ¼"""
        start_time = time.time()
        
        with self.browser_manager.get_browser() as driver:
            try:
                # è®¿é—®é¡µé¢
                driver.get(product_url)
                
                # æ™ºèƒ½ç­‰å¾…å†…å®¹åŠ è½½
                if not self._smart_wait_for_content(driver):
                    self.logger.warning(f"é¡µé¢å†…å®¹åŠ è½½å¤±è´¥: {product_url}")
                    return self._create_result(product_url, [], False, "content_load_failed")
                
                # å°è¯•ç‚¹å‡»"æ˜¾ç¤ºå…¨éƒ¨"ï¼ˆä½¿ç”¨æ›´å¿«çš„æ–¹æ³•ï¼‰
                self._quick_click_show_all(driver)
                
                # ä¼˜åŒ–æ»šåŠ¨
                self._optimized_scroll(driver)
                
                # æå–è§„æ ¼
                specifications = self._extract_specifications_from_page(driver)
                
                # æ›´æ–°ç»Ÿè®¡
                self._update_stats(True, len(specifications))
                
                # è®°å½•å“åº”æ—¶é—´ä¾›åŠ¨æ€è¶…æ—¶ä½¿ç”¨
                response_time = time.time() - start_time
                self.timeout_manager.record_response_time(response_time)
                
                self.logger.info(f"âœ… æå–æˆåŠŸ: {len(specifications)} ä¸ªè§„æ ¼ ({response_time:.1f}ç§’) - {product_url}")
                register_success()
                
                return self._create_result(product_url, specifications, True)
                
            except Exception as e:
                self._update_stats(False, 0)
                self.logger.error(f"âŒ æå–å¤±è´¥: {e} - {product_url}")
                register_fail('extraction_error')
                return self._create_result(product_url, [], False, str(e))
    
    def _quick_click_show_all(self, driver):
        """å¿«é€Ÿç‚¹å‡»æ˜¾ç¤ºå…¨éƒ¨æŒ‰é’®"""
        try:
            # ä½¿ç”¨ JavaScript ç›´æ¥ç‚¹å‡»ï¼Œé¿å…æ»šåŠ¨å’Œç­‰å¾…
            driver.execute_script("""
                var buttons = document.querySelectorAll('*');
                for (var i = 0; i < buttons.length; i++) {
                    var btn = buttons[i];
                    if (btn.textContent.trim() === 'All' && 
                        (btn.tagName === 'BUTTON' || btn.tagName === 'LI' || 
                         btn.tagName === 'OPTION' || btn.tagName === 'DIV' || 
                         btn.tagName === 'SPAN')) {
                        btn.click();
                        return true;
                    }
                }
                return false;
            """)
            time.sleep(0.5)  # çŸ­æš‚ç­‰å¾…é¡µé¢æ›´æ–°
        except:
            pass
    
    def _extract_specifications_from_page(self, driver) -> List[Dict[str, Any]]:
        """ä»é¡µé¢æå–è§„æ ¼ä¿¡æ¯"""
        specifications = []
        seen_references = set()
        
        # æ‰¹é‡è·å–æ‰€æœ‰è¡Œï¼Œå‡å°‘ DOM è®¿é—®æ¬¡æ•°
        rows = driver.find_elements(By.CSS_SELECTOR, 'tr')
        
        for row in rows:
            try:
                # æ‰¹é‡è·å–å•å…ƒæ ¼æ–‡æœ¬
                cell_texts = driver.execute_script("""
                    var cells = arguments[0].querySelectorAll('td, th');
                    return Array.from(cells).map(cell => cell.textContent.trim());
                """, row)
                
                # æŸ¥æ‰¾äº§å“å‚è€ƒå·
                for i, text in enumerate(cell_texts[:5]):
                    if self._is_valid_product_reference(text) and text not in seen_references:
                        seen_references.add(text)
                        
                        spec = {
                            'reference': text,
                            'row_index': i,
                            'all_cells': cell_texts,
                            'cell_count': len(cell_texts)
                        }
                        
                        if len(cell_texts) > 1:
                            spec['description'] = cell_texts[1] if len(cell_texts) > 1 else ''
                            spec['details'] = cell_texts[2:] if len(cell_texts) > 2 else []
                        
                        specifications.append(spec)
                        break
                        
            except Exception as e:
                self.logger.debug(f"å¤„ç†è¡¨æ ¼è¡Œæ—¶å‡ºé”™: {e}")
                continue
        
        return specifications
    
    def _create_result(self, product_url: str, specifications: List[Dict], 
                      success: bool, error: str = None) -> Dict[str, Any]:
        """åˆ›å»ºç»Ÿä¸€çš„ç»“æœæ ¼å¼"""
        return {
            'product_url': product_url,
            'specifications': specifications,
            'count': len(specifications),
            'success': success,
            'error': error
        }
    
    def _update_stats(self, success: bool, spec_count: int):
        """çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        with self.stats['lock']:
            self.stats['total_processed'] += 1
            if success:
                self.stats['success_count'] += 1
                self.stats['total_specs'] += spec_count
            else:
                self.stats['fail_count'] += 1
    
    def extract_specifications(self, product_url: str) -> Dict[str, Any]:
        """æå–å•ä¸ªäº§å“è§„æ ¼ï¼ˆå…¼å®¹æ¥å£ï¼‰"""
        return self._parallel_extract_specifications(product_url)
    
    def extract_batch_specifications(self, product_urls: List[str], 
                                   max_workers: int = None) -> List[Dict[str, Any]]:
        """æ‰¹é‡æå–äº§å“è§„æ ¼ï¼ˆå¤šæ ¸ä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        max_workers = max_workers or self.max_workers
        results = []
        total_urls = len(product_urls)
        
        self.logger.info(f"ğŸš€ å¼€å§‹å¤šæ ¸æ‰¹é‡æå–: {total_urls} ä¸ªäº§å“, {max_workers} ä¸ªå·¥ä½œçº¿ç¨‹")
        self.stats['start_time'] = time.time()
        
        # é¢„çƒ­æµè§ˆå™¨æ± 
        self._preheat_browser_pool(min(max_workers, self.browser_pool_size))
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_url = {
                executor.submit(self._parallel_extract_specifications, url): url
                for url in product_urls
            }
            
            # å®æ—¶å¤„ç†ç»“æœ
            for future in as_completed(future_to_url):
                url = future_to_url[future]
                try:
                    result = future.result()
                    results.append(result)
                    
                    # å®æ—¶è¿›åº¦æŠ¥å‘Š
                    with self.stats['lock']:
                        processed = self.stats['total_processed']
                        if processed % 100 == 0:
                            self._report_progress(processed, total_urls)
                            
                except Exception as e:
                    self.logger.error(f"ä»»åŠ¡å¼‚å¸¸: {e}")
                    results.append(self._create_result(url, [], False, str(e)))
        
        # æœ€ç»ˆç»Ÿè®¡
        self._report_final_stats(total_urls)
        
        return results
    
    def _preheat_browser_pool(self, count: int):
        """é¢„çƒ­æµè§ˆå™¨æ± ï¼Œå‡å°‘å¯åŠ¨å»¶è¿Ÿ"""
        self.logger.info(f"é¢„çƒ­æµè§ˆå™¨æ± : {count} ä¸ªå®ä¾‹")
        
        def create_browser():
            with self.browser_manager.get_browser() as browser:
                # è®¿é—®ç©ºç™½é¡µè¿›è¡Œé¢„çƒ­
                browser.get("about:blank")
                time.sleep(0.1)
        
        # å¹¶è¡Œåˆ›å»ºæµè§ˆå™¨å®ä¾‹
        with ThreadPoolExecutor(max_workers=count) as executor:
            futures = [executor.submit(create_browser) for _ in range(count)]
            for future in as_completed(futures):
                try:
                    future.result()
                except:
                    pass
    
    def _report_progress(self, processed: int, total: int):
        """æŠ¥å‘Šè¿›åº¦"""
        elapsed = time.time() - self.stats['start_time']
        rate = processed / elapsed if elapsed > 0 else 0
        eta = (total - processed) / rate if rate > 0 else 0
        
        self.logger.info(
            f"ğŸ“Š è¿›åº¦: {processed}/{total} ({processed*100/total:.1f}%) | "
            f"é€Ÿåº¦: {rate:.1f} ä¸ª/ç§’ | "
            f"é¢„è®¡å‰©ä½™: {eta/60:.1f} åˆ†é’Ÿ"
        )
    
    def _report_final_stats(self, total_urls: int):
        """æŠ¥å‘Šæœ€ç»ˆç»Ÿè®¡"""
        elapsed = time.time() - self.stats['start_time']
        
        self.logger.info(f"\n{'='*60}")
        self.logger.info(f"âœ… å¤šæ ¸æ‰¹é‡æå–å®Œæˆ")
        self.logger.info(f"{'='*60}")
        self.logger.info(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        self.logger.info(f"   â€¢ æ€»äº§å“æ•°: {total_urls}")
        self.logger.info(f"   â€¢ æˆåŠŸ: {self.stats['success_count']} ({self.stats['success_count']*100/total_urls:.1f}%)")
        self.logger.info(f"   â€¢ å¤±è´¥: {self.stats['fail_count']}")
        self.logger.info(f"   â€¢ æ€»è§„æ ¼æ•°: {self.stats['total_specs']}")
        self.logger.info(f"   â€¢ æ€»è€—æ—¶: {elapsed:.1f} ç§’ ({elapsed/60:.1f} åˆ†é’Ÿ)")
        self.logger.info(f"   â€¢ å¹³å‡é€Ÿåº¦: {total_urls/elapsed:.2f} ä¸ª/ç§’")
        self.logger.info(f"   â€¢ å¹³å‡æ¯ä¸ªäº§å“: {elapsed/total_urls:.1f} ç§’")
        self.logger.info(f"{'='*60}")


class DynamicTimeoutManager:
    """åŠ¨æ€è¶…æ—¶ç®¡ç†å™¨"""
    
    def __init__(self, base_timeout: int = 30):
        self.base_timeout = base_timeout
        self.response_times = []
        self.lock = threading.Lock()
        self.max_samples = 100
    
    def record_response_time(self, time_seconds: float):
        """è®°å½•å“åº”æ—¶é—´"""
        with self.lock:
            self.response_times.append(time_seconds)
            if len(self.response_times) > self.max_samples:
                self.response_times.pop(0)
    
    def get_timeout(self) -> int:
        """è·å–åŠ¨æ€è¶…æ—¶æ—¶é—´"""
        with self.lock:
            if not self.response_times:
                return self.base_timeout
            
            # ä½¿ç”¨95åˆ†ä½æ•°ä½œä¸ºè¶…æ—¶æ—¶é—´
            sorted_times = sorted(self.response_times)
            p95_index = int(len(sorted_times) * 0.95)
            p95_time = sorted_times[p95_index] if p95_index < len(sorted_times) else sorted_times[-1]
            
            # è¶…æ—¶æ—¶é—´ä¸º P95 çš„ 1.5 å€ï¼Œä½†ä¸ä½äºåŸºç¡€è¶…æ—¶
            dynamic_timeout = max(self.base_timeout, int(p95_time * 1.5))
            
            return min(dynamic_timeout, 90)  # æœ€å¤§90ç§’ 