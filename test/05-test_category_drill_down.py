#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç±»ç›®æ·±åº¦çˆ¬å–æµ‹è¯• - TraceParts å­ç±»ç›®ä¿¡æ¯æŠ“å–
æµ‹è¯•è¿›å…¥å…·ä½“ç±»ç›®é¡µé¢ï¼Œæå–å­ç±»ç›®å’Œé“¾æ¥
"""

import os
import json
import re
import time
import asyncio
import aiofiles
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor
import random

from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.prompts import ChatPromptTemplate

# å¯¼å…¥seleniumç›¸å…³æ¨¡å—
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, WebDriverException
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False

import requests
from bs4 import BeautifulSoup

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
LOG = logging.getLogger("category-drill-down")

# å¹¶å‘æ§åˆ¶å¸¸é‡
MAX_SUBCATEGORY_CONCURRENCY = 2  # å­ç±»ç›®é¡µé¢çš„å¹¶å‘æ•°é‡
MAX_RETRIES = 3
SUBCATEGORY_TIMEOUT = 60
BACKOFF_BASE = 2.0
BACKOFF_JITTER = 0.25

@dataclass
class CategoryDrillConfig:
    """ç±»ç›®æ·±åº¦çˆ¬å–é…ç½®"""
    api_key: str = "sk-YgL2cnnuifh9AloZFa6d63111aC64e4898Ba0769077521Ac"
    base_url: str = "https://ai.pumpkinai.online"
    model: str = "gpt-4o-mini"
    temperature: float = 0.2
    max_tokens: int = 3000
    subcategory_concurrency: int = MAX_SUBCATEGORY_CONCURRENCY
    max_retries: int = MAX_RETRIES
    subcategory_timeout: int = SUBCATEGORY_TIMEOUT

@dataclass
class CategoryInfo:
    """ç±»ç›®ä¿¡æ¯æ•°æ®ç»“æ„"""
    name: str
    description: str
    url: str
    parent_category: str = ""
    level: int = 1  # 1=ä¸»ç±»ç›®, 2=å­ç±»ç›®, 3=å­å­ç±»ç›®

class CategoryDrillDownExtractor:
    """ç±»ç›®æ·±åº¦çˆ¬å–å™¨"""
    
    def __init__(self, config: CategoryDrillConfig):
        self.config = config
        self.subcategory_sem = asyncio.Semaphore(config.subcategory_concurrency)
        
        # é…ç½®LLM
        self.llm = ChatOpenAI(
            model=config.model,
            openai_api_key=config.api_key,
            openai_api_base=config.base_url + "/v1",
            temperature=config.temperature,
            max_tokens=config.max_tokens
        )
        
        # å­ç±»ç›®æå–çš„AIæç¤ºæ¨¡æ¿
        self.subcategory_prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯TracePartsç½‘ç«™çš„ä¸“ä¸šåˆ†æå¸ˆã€‚è¯·ä»äº§å“ç±»ç›®é¡µé¢ä¸­æå–å®Œæ•´çš„å¤šå±‚çº§å­ç±»ç›®ä¿¡æ¯ã€‚

ä½ æ­£åœ¨åˆ†æä¸€ä¸ªå…·ä½“çš„äº§å“ç±»ç›®é¡µé¢ï¼ˆå¦‚MECHANICAL COMPONENTSï¼‰ï¼Œéœ€è¦æå–å…¶ä¸‹çš„æ‰€æœ‰å±‚çº§å­ç±»ç›®ã€‚

**é‡è¦ä»»åŠ¡ï¼š**
1. è¯†åˆ«é¡µé¢ä¸­çš„æ‰€æœ‰å­ç±»ç›®åç§°ï¼ˆäºŒçº§ã€ä¸‰çº§ã€å››çº§ç­‰ï¼‰
2. æå–æ¯ä¸ªå­ç±»ç›®å¯¹åº”çš„å®Œæ•´é“¾æ¥
3. åˆ†æå­ç±»ç›®çš„å±‚çº§å…³ç³»
4. è¯†åˆ«å­ç±»ç›®çš„æè¿°ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰

**ç‰¹åˆ«æ³¨æ„å¤šå±‚çº§å†…å®¹æ ¼å¼ï¼š**
- å¯èƒ½åŒ…å«æ ¼å¼å¦‚ï¼šğŸ”— L2 ç±»ç›®: XXX, ğŸ”— L3 ç±»ç›®: XXX, ğŸ”— L4 ç±»ç›®: XXX
- å¯èƒ½åŒ…å«è·¯å¾„ä¿¡æ¯ï¼šğŸ—‚ï¸ è·¯å¾„: fasteners > washers
- å±‚çº§ç¼©è¿›æ˜¾ç¤ºï¼šäºŒçº§ç±»ç›®æ— ç¼©è¿›ï¼Œä¸‰çº§ç±»ç›®ä¸¤ä¸ªç©ºæ ¼ç¼©è¿›

**æå–è§„åˆ™ï¼š**
- å­ç±»ç›®é€šå¸¸ä»¥é“¾æ¥å½¢å¼å‡ºç°
- å­ç±»ç›®åç§°å¯èƒ½æ˜¯è‹±æ–‡æˆ–ä¸­æ–‡
- ä¼˜å…ˆæå–åŒ…å«ä»¥ä¸‹æ¨¡å¼çš„é“¾æ¥ï¼š
  - /search/traceparts-classification-
  - CatalogPath=TRACEPARTS%3A
  - äº§å“ç›¸å…³çš„åˆ†ç±»é“¾æ¥

**è¿”å›æ ¼å¼ï¼š**
è¯·è¿”å›ä¸¥æ ¼çš„JSONæ ¼å¼ï¼ŒåŒ…å«å®Œæ•´çš„å±‚çº§ä¿¡æ¯ï¼š

{{
    "subcategories": [
        {{
            "name": "Fasteners",
            "description": "ç´§å›ºä»¶ç›¸å…³äº§å“",
            "url": "https://www.traceparts.cn/en/search/traceparts-classification-mechanical-components-fasteners?CatalogPath=TRACEPARTS%3ATP01001",
            "level": 2,
            "parent_path": "MECHANICAL COMPONENTS"
        }},
        {{
            "name": "Screws and bolts",
            "description": "èºä¸å’Œèºæ “",
            "url": "https://www.traceparts.cn/en/search/traceparts-classification-mechanical-components-fasteners-screws?CatalogPath=TRACEPARTS%3ATP01001001",
            "level": 3,
            "parent_path": "MECHANICAL COMPONENTS > Fasteners"
        }},
        {{
            "name": "Spherical seat washers",
            "description": "çƒé¢å«åœˆ",
            "url": "https://www.traceparts.cn/en/search/traceparts-classification-mechanical-components-fasteners-washers-spherical?CatalogPath=TRACEPARTS%3ATP01001003001",
            "level": 4,
            "parent_path": "MECHANICAL COMPONENTS > Fasteners > Washers"
        }}
    ],
    "parent_info": {{
        "name": "çˆ¶ç±»ç›®åç§°",
        "total_subcategories": "å­ç±»ç›®æ€»æ•°",
        "level_distribution": {{
            "level_2": "äºŒçº§ç±»ç›®æ•°é‡",
            "level_3": "ä¸‰çº§ç±»ç›®æ•°é‡", 
            "level_4": "å››çº§ç±»ç›®æ•°é‡"
        }}
    }}
}}

**ä¸¥æ ¼è¦æ±‚ï¼š**
- åªæå–çœŸå®å­˜åœ¨çš„é“¾æ¥ï¼Œä¸è¦ç¼–é€ ä»»ä½•URL
- URLå¿…é¡»å®Œæ•´ï¼Œä»¥https://å¼€å¤´
- levelå­—æ®µå¿…é¡»æ˜¯æ•°å­—(2, 3, 4ç­‰)
- parent_pathè¦ä½“ç°å®Œæ•´çš„å±‚çº§è·¯å¾„
- å¦‚æœæ²¡æœ‰æ‰¾åˆ°å­ç±»ç›®ï¼Œsubcategoriesæ•°ç»„ä¸ºç©º
- å­ç±»ç›®åç§°è¦å‡†ç¡®ï¼Œä¸è¦ç¿»è¯‘æˆ–ä¿®æ”¹
- ä¼˜å…ˆä»å†…å®¹ä¸­æ ‡è®°ä¸º"L2 ç±»ç›®"ã€"L3 ç±»ç›®"ç­‰æ ¼å¼çš„ä¿¡æ¯ä¸­æå–"""),
            ("human", "è¯·åˆ†æä»¥ä¸‹TracePartsäº§å“ç±»ç›®é¡µé¢ï¼Œæå–æ‰€æœ‰å¤šå±‚çº§å­ç±»ç›®ä¿¡æ¯ã€‚ç‰¹åˆ«æ³¨æ„å±‚çº§æ ‡è®°(L2ã€L3ã€L4)å’Œè·¯å¾„ä¿¡æ¯ã€‚é¡µé¢å†…å®¹ï¼š\n\n{content}")
        ])

    def load_category_page_selenium(self, category_url: str, category_name: str) -> str:
        """ä½¿ç”¨SeleniumåŠ è½½å…·ä½“ç±»ç›®é¡µé¢å¹¶æ·±åº¦æŒ–æ˜æ ‘çŠ¶ç»“æ„"""
        LOG.info(f"ğŸŒ åŠ è½½ {category_name} ç±»ç›®é¡µé¢: {category_url}")
        
        if not SELENIUM_AVAILABLE:
            raise Exception("Seleniumæœªå®‰è£…ï¼Œè¯·è¿è¡Œï¼špip install selenium")
        
        try:
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            driver = webdriver.Chrome(options=chrome_options)
            driver.set_page_load_timeout(30)
            driver.get(category_url)
            
            LOG.info("â³ ç­‰å¾…ç±»ç›®é¡µé¢åŠ è½½...")
            time.sleep(10)  # å¢åŠ åˆå§‹ç­‰å¾…æ—¶é—´
            
            try:
                WebDriverWait(driver, 30).until(
                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                )
            except TimeoutException:
                LOG.warning("âš ï¸  é¡µé¢åŠ è½½è¶…æ—¶ï¼Œç»§ç»­å°è¯•è·å–å†…å®¹...")
            
            # æ·±åº¦æŒ–æ˜ç­–ç•¥å¼€å§‹
            LOG.info("ğŸ” å¼€å§‹æ·±åº¦æŒ–æ˜æ ‘çŠ¶å¯¼èˆªç»“æ„...")
            
            # 1. å°è¯•å±•å¼€æ‰€æœ‰å¯èƒ½çš„æ ‘èŠ‚ç‚¹
            self.expand_all_tree_nodes(driver)
            
            # 2. æ»šåŠ¨é¡µé¢ç¡®ä¿åŠ¨æ€å†…å®¹åŠ è½½
            self.scroll_to_load_dynamic_content(driver)
            
            # 3. å†æ¬¡ç­‰å¾…åŠ¨æ€å†…å®¹åŠ è½½
            time.sleep(5)
            
            content = driver.page_source
            
            # 4. æ·±åº¦æå–å¤šå±‚çº§ç±»ç›®ç»“æ„
            all_subcategories = self.deep_extract_tree_structure(driver, category_name)
            
            if all_subcategories:
                # æ„å»ºè¯¦ç»†çš„å¤šå±‚çº§å­ç±»ç›®ä¿¡æ¯
                detailed_subcategory_info = f"\n\n=== {category_name} å®Œæ•´æ ‘çŠ¶ç»“æ„ ===\n"
                detailed_subcategory_info += f"çˆ¶ç±»ç›®: {category_name}\n"
                detailed_subcategory_info += f"æ€»å­ç±»ç›®æ•°é‡: {len(all_subcategories)}\n\n"
                
                # æŒ‰å±‚çº§ç»„ç»‡ä¿¡æ¯
                level_2_categories = [sub for sub in all_subcategories if sub.get('level', 2) == 2]
                level_3_categories = [sub for sub in all_subcategories if sub.get('level', 2) == 3]
                level_4_categories = [sub for sub in all_subcategories if sub.get('level', 2) == 4]
                
                detailed_subcategory_info += f"äºŒçº§ç±»ç›®: {len(level_2_categories)} ä¸ª\n"
                detailed_subcategory_info += f"ä¸‰çº§ç±»ç›®: {len(level_3_categories)} ä¸ª\n"
                detailed_subcategory_info += f"å››çº§ç±»ç›®: {len(level_4_categories)} ä¸ª\n\n"
                
                for item in all_subcategories:
                    level_prefix = "  " * (item.get('level', 2) - 2)
                    detailed_subcategory_info += f"{level_prefix}ğŸ”— L{item.get('level', 2)} ç±»ç›®: {item['name']}\n"
                    detailed_subcategory_info += f"{level_prefix}ğŸŒ é“¾æ¥: {item['url']}\n"
                    detailed_subcategory_info += f"{level_prefix}ğŸ“‚ çˆ¶ç±»ç›®: {item['parent_category']}\n"
                    if 'parent_path' in item:
                        detailed_subcategory_info += f"{level_prefix}ğŸ—‚ï¸  è·¯å¾„: {item['parent_path']}\n"
                    detailed_subcategory_info += f"{level_prefix}" + "=" * 50 + "\n"
                
                content += detailed_subcategory_info
                LOG.info(f"âœ… æ·±åº¦æŒ–æ˜æˆåŠŸæå–äº† {len(all_subcategories)} ä¸ªå¤šå±‚çº§å­ç±»ç›®")
                
                # æ˜¾ç¤ºå±‚çº§ç»Ÿè®¡
                LOG.info("ğŸ“Š å±‚çº§åˆ†å¸ƒç»Ÿè®¡:")
                LOG.info(f"  äºŒçº§ç±»ç›®: {len(level_2_categories)} ä¸ª")
                LOG.info(f"  ä¸‰çº§ç±»ç›®: {len(level_3_categories)} ä¸ª") 
                LOG.info(f"  å››çº§ç±»ç›®: {len(level_4_categories)} ä¸ª")
                
            else:
                LOG.warning(f"âš ï¸  æ·±åº¦æŒ–æ˜æœªæ‰¾åˆ° {category_name} çš„å­ç±»ç›®")
            
            driver.quit()
            
            LOG.info(f"âœ… {category_name} é¡µé¢æ·±åº¦åˆ†æå®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            return content
            
        except Exception as e:
            LOG.error(f"âŒ {category_name} é¡µé¢åŠ è½½å¤±è´¥: {str(e)}")
            raise

    def expand_all_tree_nodes(self, driver):
        """å±•å¼€æ‰€æœ‰å¯èƒ½çš„æ ‘èŠ‚ç‚¹"""
        LOG.info("ğŸŒ³ å°è¯•å±•å¼€æ‰€æœ‰æ ‘çŠ¶å¯¼èˆªèŠ‚ç‚¹...")
        
        # å¯èƒ½çš„å±•å¼€æŒ‰é’®é€‰æ‹©å™¨
        expand_selectors = [
            "button[aria-expanded='false']",     # ARIAå±•å¼€æŒ‰é’®
            ".tree-toggle",                      # æ ‘çŠ¶åˆ‡æ¢æŒ‰é’®
            ".expand-button",                    # å±•å¼€æŒ‰é’®
            ".collapse-toggle",                  # æŠ˜å åˆ‡æ¢
            "[role='button'][aria-expanded='false']",  # ARIAæŒ‰é’®
            ".fa-plus",                         # Font Awesome pluså›¾æ ‡
            ".fa-chevron-right",                # Font Awesomeå³ç®­å¤´
            "span.toggle",                      # åˆ‡æ¢span
            ".jstree-closed > .jstree-icon",    # jsTreeå…³é—­èŠ‚ç‚¹
            ".fancytree-closed .fancytree-expander",  # fancyTreeå…³é—­èŠ‚ç‚¹
        ]
        
        expanded_count = 0
        for selector in expand_selectors:
            try:
                elements = driver.find_elements(By.CSS_SELECTOR, selector)
                LOG.info(f"  æ‰¾åˆ° {len(elements)} ä¸ª '{selector}' å±•å¼€å…ƒç´ ")
                
                for element in elements[:50]:  # é™åˆ¶æ•°é‡é¿å…æ— é™å¾ªç¯
                    try:
                        if element.is_displayed() and element.is_enabled():
                            driver.execute_script("arguments[0].click();", element)
                            expanded_count += 1
                            time.sleep(0.5)  # ç­‰å¾…å±•å¼€åŠ¨ç”»
                    except:
                        continue
                        
            except Exception as e:
                LOG.debug(f"  å±•å¼€é€‰æ‹©å™¨ '{selector}' å¤±è´¥: {str(e)}")
        
        LOG.info(f"âœ… æ€»å…±å±•å¼€äº† {expanded_count} ä¸ªæ ‘èŠ‚ç‚¹")

    def scroll_to_load_dynamic_content(self, driver):
        """æ»šåŠ¨é¡µé¢ä»¥åŠ è½½åŠ¨æ€å†…å®¹"""
        LOG.info("ğŸ“œ æ»šåŠ¨é¡µé¢åŠ è½½åŠ¨æ€å†…å®¹...")
        
        try:
            # è·å–é¡µé¢æ€»é«˜åº¦
            total_height = driver.execute_script("return document.body.scrollHeight")
            current_position = 0
            
            # åˆ†æ®µæ»šåŠ¨
            while current_position < total_height:
                # å‘ä¸‹æ»šåŠ¨
                driver.execute_script(f"window.scrollTo(0, {current_position});")
                time.sleep(1)
                current_position += 500
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°å†…å®¹åŠ è½½
                new_height = driver.execute_script("return document.body.scrollHeight")
                if new_height > total_height:
                    total_height = new_height
                    LOG.info(f"ğŸ“ˆ æ£€æµ‹åˆ°æ–°å†…å®¹ï¼Œé¡µé¢é«˜åº¦å¢åŠ åˆ° {total_height}px")
            
            # æ»šåŠ¨åˆ°é¡¶éƒ¨
            driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(2)
            
            LOG.info("âœ… é¡µé¢æ»šåŠ¨å®Œæˆ")
            
        except Exception as e:
            LOG.warning(f"âš ï¸  é¡µé¢æ»šåŠ¨å¤±è´¥: {str(e)}")

    def deep_extract_tree_structure(self, driver, category_name: str) -> List[Dict[str, Any]]:
        """æ·±åº¦æå–å®Œæ•´çš„æ ‘çŠ¶ç»“æ„"""
        LOG.info("ğŸ¯ æ·±åº¦æå–å®Œæ•´æ ‘çŠ¶ç»“æ„...")
        
        all_subcategories = []
        
        # é«˜ç²¾åº¦é€‰æ‹©å™¨ç­–ç•¥
        high_precision_selectors = [
            # ç›´æ¥åŒ¹é…æ‰€æœ‰TracePartsåˆ†ç±»é“¾æ¥
            "a[href*='traceparts-classification-']",              # æ‰€æœ‰åˆ†ç±»é“¾æ¥
            "a[href*='CatalogPath=TRACEPARTS%3A']",               # æ‰€æœ‰ç›®å½•è·¯å¾„é“¾æ¥
            # æ ‘çŠ¶ç»“æ„é€‰æ‹©å™¨
            "li a[href*='classification']",                       # åˆ—è¡¨ä¸­çš„åˆ†ç±»é“¾æ¥
            "ul li a[href*='traceparts']",                        # æ— åºåˆ—è¡¨ä¸­çš„TracePartsé“¾æ¥
            # ä¾§è¾¹æ å¯¼èˆª
            ".sidebar a[href*='classification']",                 # ä¾§è¾¹æ åˆ†ç±»é“¾æ¥
            "nav a[href*='classification']",                      # å¯¼èˆªåŒºåˆ†ç±»é“¾æ¥
            "aside a[href*='classification']",                    # asideåŒºåŸŸåˆ†ç±»é“¾æ¥
            # ç‰¹å®šçš„å¯¼èˆªç»“æ„
            "[role='tree'] a",                                    # ARIAæ ‘ç»“æ„
            "[role='treeitem'] a",                                # ARIAæ ‘é¡¹
            ".tree a",                                            # æ ‘çŠ¶ç»„ä»¶
            ".nav-tree a",                                        # å¯¼èˆªæ ‘
            # é€šç”¨ä½†æœ‰æ•ˆçš„é€‰æ‹©å™¨
            "a[href*='search/traceparts-classification']",        # æœç´¢åˆ†ç±»é“¾æ¥
            "a[title*='classification']",                         # æ ‡é¢˜åŒ…å«classification
            ".classification a",                                  # åˆ†ç±»classä¸‹çš„é“¾æ¥
        ]
        
        seen_urls = set()
        seen_texts = set()
        
        for selector in high_precision_selectors:
            try:
                elements = driver.find_elements(By.CSS_SELECTOR, selector)
                LOG.info(f"  é«˜ç²¾åº¦é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
                
                for element in elements:
                    try:
                        text = element.text.strip()
                        href = element.get_attribute('href') or ""
                        
                        if not text or len(text) < 2 or len(text) > 200:
                            continue
                        
                        # æ›´ç²¾ç¡®çš„æœºæ¢°ç»„ä»¶å­ç±»ç›®åˆ¤æ–­
                        if not self.is_valid_mechanical_subcategory(text, href):
                            continue
                        
                        # æ„å»ºå®Œæ•´URL
                        if href and not href.startswith('http'):
                            if href.startswith('/'):
                                href = f"https://www.traceparts.cn{href}"
                        
                        # å»é‡
                        if href in seen_urls or text.upper() in seen_texts:
                            continue
                        
                        seen_urls.add(href)
                        seen_texts.add(text.upper())
                        
                        # åˆ†æå±‚çº§
                        level, parent_path = self.analyze_category_level(text, href, element)
                        
                        subcategory = {
                            "name": text,
                            "url": href,
                            "level": level,
                            "parent_category": category_name,
                            "parent_path": parent_path,
                            "element_tag": element.tag_name,
                            "extraction_method": "deep_tree_analysis"
                        }
                        
                        all_subcategories.append(subcategory)
                        LOG.debug(f"    æ·±åº¦æå–: L{level} '{text}' -> {href[:80]}...")
                        
                    except Exception as e:
                        continue
                        
            except Exception as e:
                LOG.debug(f"  é«˜ç²¾åº¦é€‰æ‹©å™¨ '{selector}' å¤±è´¥: {str(e)}")
        
        # æŒ‰å±‚çº§å’Œåç§°æ’åº
        all_subcategories.sort(key=lambda x: (x['level'], x['name']))
        
        LOG.info(f"ğŸ¯ æ·±åº¦æå–å®Œæˆï¼Œå…±è·å¾— {len(all_subcategories)} ä¸ªå¤šå±‚çº§å­ç±»ç›®")
        return all_subcategories

    def is_valid_mechanical_subcategory(self, text: str, href: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆçš„TracePartsåˆ†ç±»å­ç±»ç›®ï¼ˆæ‰©å±•åˆ°æ‰€æœ‰ç±»ç›®ï¼‰"""
        text_lower = text.lower()
        href_lower = href.lower()
        
        # æ’é™¤æ¨¡å¼
        exclude_patterns = [
            'sign-in', 'sign-up', 'login', 'register', 'news', 'blog',
            'help', 'support', 'contact', 'about', 'home', 'search?q=',
            'cookie', 'privacy', 'terms', 'javascript:', 'mailto:'
        ]
        
        if any(pattern in text_lower or pattern in href_lower for pattern in exclude_patterns):
            return False
        
        # æ‰©å±•çš„TracePartsæ‰€æœ‰ç±»ç›®å…³é”®è¯
        all_category_keywords = [
            # æœºæ¢°ç»„ä»¶
            'mechanical', 'fastener', 'screw', 'bolt', 'nut', 'washer', 'rivet', 'pin',
            'anchor', 'stud', 'thread', 'insert', 'lock', 'retaining', 'bearing', 'seal',
            'gasket', 'o-ring', 'ring', 'spring', 'damper', 'shock', 'vibration',
            'gear', 'pulley', 'belt', 'chain', 'coupling', 'joint', 'transmission',
            'drive', 'clutch', 'brake', 'linear', 'slide', 'guide', 'rail', 'actuator',
            'cylinder', 'piston', 'rod', 'shaft', 'spindle',
            
            # ç”µæ°”ç»„ä»¶
            'electrical', 'electronic', 'connector', 'cable', 'wire', 'switch',
            'relay', 'sensor', 'circuit', 'breaker', 'fuse', 'terminal', 'plug',
            'socket', 'junction', 'panel', 'meter', 'transformer', 'capacitor',
            'resistor', 'inductor', 'diode', 'transistor',
            
            # ææ–™
            'material', 'steel', 'stainless', 'aluminum', 'brass', 'copper', 'plastic',
            'rubber', 'ceramic', 'composite', 'bar', 'beam', 'tube', 'pipe', 'sheet',
            'plate', 'profile', 'angle', 'channel', 'round', 'square', 'flat',
            
            # æ¶²å‹æ°”åŠ¨
            'hydraulic', 'pneumatic', 'valve', 'pump', 'filter', 'regulator',
            'accumulator', 'reservoir', 'manifold', 'fitting', 'hose', 'cylinder',
            'motor', 'compressor', 'air', 'oil', 'fluid',
            
            # å…‰å­¦
            'optic', 'optical', 'lens', 'mirror', 'prism', 'fiber', 'laser',
            'camera', 'detector', 'filter', 'window', 'dome',
            
            # çœŸç©ºè®¾å¤‡
            'vacuum', 'pump', 'chamber', 'valve', 'gauge', 'fitting',
            
            # çƒ­ä¼ å¯¼
            'heat', 'thermal', 'cooler', 'heater', 'exchanger', 'radiator',
            'insulation', 'thermostat', 'temperature',
            
            # å»ºç­‘æ–½å·¥
            'building', 'construction', 'concrete', 'brick', 'mortar', 'cement',
            'aggregate', 'reinforcement', 'formwork', 'scaffold',
            
            # åœŸæœ¨å·¥ç¨‹
            'civil', 'engineering', 'infrastructure', 'road', 'bridge', 'tunnel',
            'foundation', 'drainage', 'pavement',
            
            # æ ‡å‡†å’Œè§„æ ¼
            'din', 'iso', 'ansi', 'astm', 'jis', 'gb', 'metric', 'imperial',
            'standard', 'specification', 'grade', 'class'
        ]
        
        # URLåŒ…å«åˆ†ç±»ç‰¹å¾ï¼ˆæœ€é‡è¦ï¼‰
        if 'traceparts-classification-' in href_lower or 'catalogpath=traceparts' in href_lower:
            return True
        
        # æ–‡æœ¬åŒ…å«ä»»ä½•ç±»ç›®å…³é”®è¯
        if any(keyword in text_lower for keyword in all_category_keywords):
            return True
        
        # æ ¼å¼åƒç±»ç›®åç§°
        if (len(text.split()) <= 6 and 
            len(text) >= 3 and 
            text[0].isupper() and
            not any(skip in text_lower for skip in ['view', 'show', 'more', 'see all', 'browse', 'click'])):
            return True
        
        return False

    def analyze_category_level(self, text: str, href: str, element) -> tuple:
        """åˆ†æç±»ç›®å±‚çº§å’Œè·¯å¾„"""
        try:
            # é€šè¿‡URLè·¯å¾„åˆ†æå±‚çº§
            if 'traceparts-classification-' in href:
                # åˆ†æå®Œæ•´çš„åˆ†ç±»è·¯å¾„
                classification_part = href.split('traceparts-classification-')[1].split('?')[0]
                
                if classification_part == '':
                    # æ ¹åˆ†ç±»
                    level = 1
                    parent_path = "TraceParts Classification"
                else:
                    # è®¡ç®—å±‚çº§æ·±åº¦
                    parts = classification_part.split('-')
                    level = min(len(parts) + 1, 6)  # é™åˆ¶æœ€å¤§å±‚çº§ä¸º6
                    
                    # æ„å»ºçˆ¶è·¯å¾„
                    if level == 2:
                        parent_path = "TraceParts Classification"
                    else:
                        parent_path = "TraceParts Classification > " + ' > '.join(parts[:-1])
            else:
                level = 2
                parent_path = "TraceParts Classification"
            
            # é€šè¿‡DOMç»“æ„åˆ†æå±‚çº§ï¼ˆå¦‚æœå¯èƒ½ï¼‰
            try:
                parent_li = element.find_element(By.XPATH, "./..")
                nested_level = 0
                current = parent_li
                
                # å‘ä¸ŠæŸ¥æ‰¾åµŒå¥—çš„ul/liç»“æ„
                for _ in range(5):  # æœ€å¤šæŸ¥æ‰¾5å±‚
                    try:
                        current = current.find_element(By.XPATH, "../..")
                        if current.tag_name.lower() in ['ul', 'ol']:
                            nested_level += 1
                    except:
                        break
                
                if nested_level > 0:
                    level = max(level, nested_level + 1)
                    
            except:
                pass  # DOMåˆ†æå¤±è´¥ä¸å½±å“URLåˆ†æ
            
            return level, parent_path
            
        except:
            return 2, "TraceParts Classification"

    async def extract_subcategories(self, category_info: CategoryInfo) -> Dict[str, Any]:
        """å¼‚æ­¥æå–å­ç±»ç›®ä¿¡æ¯"""
        LOG.info(f"ğŸ” å¼€å§‹åˆ†æ {category_info.name} çš„å­ç±»ç›®...")
        
        selenium_subcategories = []  # å­˜å‚¨Seleniumç›´æ¥æå–çš„ç»“æœ
        
        async with self.subcategory_sem:
            try:
                # åœ¨çº¿ç¨‹æ± ä¸­åŠ è½½é¡µé¢å†…å®¹
                loop = asyncio.get_event_loop()
                with ThreadPoolExecutor() as executor:
                    content = await loop.run_in_executor(
                        executor,
                        self.load_category_page_selenium,
                        category_info.url,
                        category_info.name
                    )
                
                # ä»SeleniumåŠ è½½è¿‡ç¨‹ä¸­æå–å­ç±»ç›®æ•°æ®ï¼ˆç›´æ¥ä»æ—¥å¿—è®°å½•ä¸­è·å–ï¼‰
                # æ£€æŸ¥contentä¸­æ˜¯å¦åŒ…å«æˆ‘ä»¬æ·»åŠ çš„å­ç±»ç›®ä¿¡æ¯
                content_markers = [
                    f"=== {category_info.name} å®Œæ•´æ ‘çŠ¶ç»“æ„ ===",  # æ–°æ ¼å¼
                    f"=== {category_info.name} å­ç±»ç›®ä¿¡æ¯ ==="      # æ—§æ ¼å¼å…¼å®¹
                ]
                
                found_content_marker = any(marker in content for marker in content_markers)
                
                if found_content_marker:
                    LOG.info("ğŸ“¦ å‘ç°Seleniumæå–çš„å­ç±»ç›®ä¿¡æ¯ï¼Œå°è¯•è§£æ...")
                    selenium_subcategories = self.extract_selenium_subcategories_from_content(content, category_info.name)
                    LOG.info(f"ğŸ“¦ ä»Seleniumå†…å®¹ä¸­è§£æåˆ° {len(selenium_subcategories)} ä¸ªå­ç±»ç›®")
                
                # åˆ†å‰²å†…å®¹è¿›è¡ŒAIåˆ†æ
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=4000,
                    chunk_overlap=300,
                    separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""],
                    length_function=len,
                )
                chunks = text_splitter.split_text(content)
                LOG.info(f"ğŸ“„ {category_info.name} å†…å®¹åˆ†å‰²ä¸º {len(chunks)} ä¸ªå—")
                
                # AIåˆ†æå‰å‡ ä¸ªæœ‰æ•ˆå—
                ai_subcategories = []
                for chunk in chunks[:3]:  # åˆ†æå‰3ä¸ªå—
                    if len(chunk) > 1000:  # åªåˆ†ææœ‰è¶³å¤Ÿå†…å®¹çš„å—
                        try:
                            with ThreadPoolExecutor() as executor:
                                chain = self.subcategory_prompt | self.llm
                                
                                future = executor.submit(
                                    chain.invoke,
                                    {"content": chunk}
                                )
                                
                                response = await asyncio.wait_for(
                                    asyncio.wrap_future(future),
                                    timeout=self.config.subcategory_timeout
                                )
                            
                            # è§£æAIå“åº”
                            chunk_subcategories = self.parse_subcategory_response(response.content, category_info.name)
                            if chunk_subcategories:
                                ai_subcategories.extend(chunk_subcategories)
                                LOG.info(f"âœ… AIåˆ†æå— {len(ai_subcategories)} æå–åˆ°å­ç±»ç›®")
                                break  # æ‰¾åˆ°ä¸€ä¸ªæœ‰æ•ˆçš„å°±é€€å‡º
                        except Exception as e:
                            LOG.warning(f"âš ï¸  AIåˆ†æå—å¤±è´¥: {str(e)}")
                            continue
                
                # å†³å®šä½¿ç”¨å“ªä¸ªç»“æœï¼šä¼˜å…ˆAIç»“æœï¼Œfallbackåˆ°Seleniumç»“æœ
                final_subcategories = []
                extraction_method = ""
                
                if ai_subcategories:
                    final_subcategories = ai_subcategories
                    extraction_method = "AI_analysis"
                    LOG.info(f"âœ… ä½¿ç”¨AIåˆ†æç»“æœ: {len(final_subcategories)} ä¸ªå­ç±»ç›®")
                elif selenium_subcategories:
                    final_subcategories = selenium_subcategories
                    extraction_method = "selenium_direct"
                    LOG.info(f"âœ… ä½¿ç”¨Seleniumç›´æ¥æå–ç»“æœ: {len(final_subcategories)} ä¸ªå­ç±»ç›®")
                else:
                    LOG.warning(f"âš ï¸  AIå’ŒSeleniuméƒ½æœªèƒ½æå–åˆ° {category_info.name} çš„å­ç±»ç›®")
                
                if final_subcategories:
                    return {
                        "parent_category": category_info.name,
                        "parent_url": category_info.url,
                        "subcategories": final_subcategories,
                        "extraction_method": extraction_method,
                        "extraction_time": datetime.now().isoformat()
                    }
                else:
                    return {
                        "parent_category": category_info.name,
                        "parent_url": category_info.url,
                        "subcategories": [],
                        "extraction_method": "failed",
                        "extraction_time": datetime.now().isoformat()
                    }
                
            except Exception as e:
                LOG.error(f"âŒ {category_info.name} å­ç±»ç›®æå–å¤±è´¥: {str(e)}")
                # å³ä½¿å‡ºé”™ï¼Œä¹Ÿå°è¯•è¿”å›Seleniumç»“æœ
                if selenium_subcategories:
                    LOG.info(f"ğŸ”„ ä½¿ç”¨Seleniumå¤‡ä»½ç»“æœ: {len(selenium_subcategories)} ä¸ªå­ç±»ç›®")
                    return {
                        "parent_category": category_info.name,
                        "parent_url": category_info.url,
                        "subcategories": selenium_subcategories,
                        "extraction_method": "selenium_backup",
                        "error": str(e),
                        "extraction_time": datetime.now().isoformat()
                    }
                
                return {
                    "parent_category": category_info.name,
                    "parent_url": category_info.url,
                    "subcategories": [],
                    "error": str(e),
                    "extraction_method": "failed",
                    "extraction_time": datetime.now().isoformat()
                }

    def extract_selenium_subcategories_from_content(self, content: str, parent_name: str) -> List[Dict[str, Any]]:
        """ä»Seleniumæ·»åŠ åˆ°contentä¸­çš„å­ç±»ç›®ä¿¡æ¯è§£æå‡ºå­ç±»ç›®åˆ—è¡¨"""
        subcategories = []
        
        try:
            # æŸ¥æ‰¾å¤šå±‚çº§å­ç±»ç›®ä¿¡æ¯æ®µè½ - æ›´æ–°æ ‡è®°
            start_markers = [
                f"=== {parent_name} å®Œæ•´æ ‘çŠ¶ç»“æ„ ===",  # æ–°æ ¼å¼
                f"=== {parent_name} å­ç±»ç›®ä¿¡æ¯ ==="      # æ—§æ ¼å¼å…¼å®¹
            ]
            
            found_marker = None
            for marker in start_markers:
                if marker in content:
                    found_marker = marker
                    break
            
            if found_marker:
                LOG.info(f"ğŸ“¦ æ‰¾åˆ°æ ‡è®°: {found_marker}")
                start_idx = content.find(found_marker)
                remaining_content = content[start_idx:]
                
                # æ›´æ–°æ­£åˆ™è¡¨è¾¾å¼æ”¯æŒå¤šå±‚çº§æ ¼å¼
                patterns = [
                    # æ–°çš„å¤šå±‚çº§æ ¼å¼ï¼šğŸ”— L2 ç±»ç›®: XXX
                    r'ğŸ”— L(\d+) ç±»ç›®: (.+?)\n.*?ğŸŒ é“¾æ¥: (.+?)\n.*?ğŸ“‚ çˆ¶ç±»ç›®: (.+?)\n',
                    # æ—§æ ¼å¼å…¼å®¹ï¼šğŸ”— å­ç±»ç›®: XXX  
                    r'ğŸ”— å­ç±»ç›®: (.+?)\nğŸŒ é“¾æ¥: (.+?)\nğŸ“‚ çˆ¶ç±»ç›®: (.+?)\n'
                ]
                
                for pattern in patterns:
                    matches = re.findall(pattern, remaining_content, re.DOTALL)
                    LOG.info(f"ğŸ“¦ æ­£åˆ™æ¨¡å¼åŒ¹é…åˆ° {len(matches)} ä¸ªç»“æœ")
                    
                    if matches:
                        for match in matches:
                            if len(match) == 4:  # æ–°æ ¼å¼ï¼š(level, name, url, parent)
                                level, name, url, parent = match
                                level = int(level)
                            else:  # æ—§æ ¼å¼ï¼š(name, url, parent)
                                name, url, parent = match
                                level = 2
                            
                            if name.strip() and url.strip():
                                subcategory = {
                                    "name": name.strip(),
                                    "description": f"{name.strip()}å­ç±»ç›®",
                                    "url": url.strip(),
                                    "level": level,
                                    "parent_category": parent.strip(),
                                    "extraction_method": "selenium_parsed"
                                }
                                subcategories.append(subcategory)
                                LOG.debug(f"ğŸ“¦ è§£æå­ç±»ç›®: L{level} {name.strip()}")
                        
                        break  # æ‰¾åˆ°åŒ¹é…å°±åœæ­¢
                
                LOG.info(f"ğŸ“¦ ä»å†…å®¹ä¸­è§£æå‡º {len(subcategories)} ä¸ªå­ç±»ç›®")
                return subcategories
            else:
                LOG.warning("ğŸ“¦ æœªæ‰¾åˆ°ä»»ä½•æ ‡è®°")
            
        except Exception as e:
            LOG.warning(f"âš ï¸  è§£æSeleniumå†…å®¹å¤±è´¥: {str(e)}")
        
        return []

    def parse_subcategory_response(self, response_content: str, parent_name: str) -> List[Dict[str, Any]]:
        """è§£æAIçš„å­ç±»ç›®å“åº”"""
        subcategories = []
        
        try:
            # æ¸…ç†å“åº”å†…å®¹
            cleaned_content = response_content.strip()
            if cleaned_content.startswith('```json'):
                cleaned_content = re.sub(r'^```json\s*', '', cleaned_content)
            if cleaned_content.endswith('```'):
                cleaned_content = re.sub(r'\s*```$', '', cleaned_content)
            
            result = json.loads(cleaned_content)
            
            if "subcategories" in result and isinstance(result["subcategories"], list):
                for sub in result["subcategories"]:
                    if isinstance(sub, dict) and "name" in sub:
                        clean_name = sub["name"].strip()
                        if clean_name:
                            subcategories.append({
                                "name": clean_name,
                                "description": sub.get("description", "").strip(),
                                "url": sub.get("url", ""),
                                "level": sub.get("level", 2),
                                "parent_category": parent_name
                            })
                
                LOG.debug(f"{parent_name} JSONè§£ææˆåŠŸï¼Œæå–åˆ° {len(subcategories)} ä¸ªå­ç±»ç›®")
                return subcategories
                
        except json.JSONDecodeError as e:
            LOG.debug(f"{parent_name} JSONè§£æå¤±è´¥: {str(e)}")
        
        # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
        return []

async def test_category_drill_down():
    """æµ‹è¯•ç±»ç›®æ·±åº¦çˆ¬å–"""
    LOG.info("=" * 80)
    LOG.info("ğŸ”§ TraceParts å®Œæ•´åˆ†ç±»æ ‘æå–æµ‹è¯• - æ ¹åˆ†ç±»é¡µé¢æ·±åº¦åˆ†æ")
    LOG.info("=" * 80)
    
    # ç›®æ ‡ï¼šTracePartsæ ¹åˆ†ç±»é¡µé¢ï¼ˆåŒ…å«å®Œæ•´æ ‘çŠ¶ç»“æ„ï¼‰
    root_classification = CategoryInfo(
        name="TraceParts Classification",
        description="TracePartså®Œæ•´åˆ†ç±»æ ‘",
        url="https://www.traceparts.cn/en/search/traceparts-classification?CatalogPath=TRACEPARTS%3ATRACEPARTS",
        level=1
    )
    
    config = CategoryDrillConfig()
    
    try:
        # åˆå§‹åŒ–æå–å™¨
        LOG.info("ğŸ”§ åˆå§‹åŒ–å®Œæ•´åˆ†ç±»æ ‘æå–å™¨...")
        extractor = CategoryDrillDownExtractor(config)
        LOG.info("âœ… æå–å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # æå–å®Œæ•´åˆ†ç±»æ ‘
        start_time = time.time()
        result = await extractor.extract_subcategories(root_classification)
        extraction_time = time.time() - start_time
        
        # æ„å»ºæœ€ç»ˆç»“æœ
        final_result = {
            "drill_down_result": result,
            "metadata": {
                "target_category": root_classification.name,
                "target_url": root_classification.url,
                "extraction_date": datetime.now().isoformat(),
                "extraction_time_seconds": round(extraction_time, 2),
                "selenium_available": SELENIUM_AVAILABLE,
                "extraction_scope": "complete_classification_tree",
                "config": {
                    "subcategory_concurrency": config.subcategory_concurrency,
                    "max_retries": config.max_retries,
                    "subcategory_timeout": config.subcategory_timeout
                }
            }
        }
        
        # ä¿å­˜ç»“æœ
        LOG.info("ğŸ’¾ æ­£åœ¨ä¿å­˜å®Œæ•´åˆ†ç±»æ ‘æå–ç»“æœ...")
        os.makedirs("results", exist_ok=True)
        filepath = "results/traceparts_complete_classification_tree.json"
        
        async with aiofiles.open(filepath, 'w', encoding='utf-8') as f:
            await f.write(json.dumps(final_result, ensure_ascii=False, indent=2))
        
        LOG.info(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {filepath}")
        
        LOG.info("\n" + "=" * 80)
        LOG.info("ğŸ“‹ å®Œæ•´åˆ†ç±»æ ‘æå–ç»“æœæ‘˜è¦:")
        LOG.info("=" * 80)
        
        subcategories = result.get("subcategories", [])
        subcategory_count = len(subcategories)
        
        LOG.info(f"ğŸ¯ æ ¹åˆ†ç±»: {root_classification.name}")
        LOG.info(f"ğŸ”— æ ¹åˆ†ç±»é“¾æ¥: {root_classification.url}")
        LOG.info(f"ğŸ“Š æå–åˆ°çš„æ€»ç±»ç›®æ•°é‡: {subcategory_count} ä¸ª")
        LOG.info(f"â±ï¸  æå–æ—¶é—´: {extraction_time:.2f} ç§’")
        LOG.info(f"ğŸ“ ç»“æœæ–‡ä»¶: {filepath}")
        
        if subcategory_count > 0:
            # ç»Ÿè®¡å„ä¸»ç±»ç›®ä¸‹çš„å­ç±»ç›®æ•°é‡
            main_categories = {}
            for sub in subcategories:
                # åˆ†æä¸»ç±»ç›®
                if sub.get('level', 2) == 2:  # ä¸»ç±»ç›®
                    main_category = sub['name']
                    if main_category not in main_categories:
                        main_categories[main_category] = {'count': 0, 'subcats': []}
                    main_categories[main_category]['count'] += 1
                elif sub.get('level', 2) > 2:  # å­ç±»ç›®
                    parent_path = sub.get('parent_path', '')
                    if '>' in parent_path:
                        main_category = parent_path.split('>')[0].strip()
                    else:
                        main_category = "å…¶ä»–"
                    if main_category not in main_categories:
                        main_categories[main_category] = {'count': 0, 'subcats': []}
                    main_categories[main_category]['count'] += 1
                    main_categories[main_category]['subcats'].append(sub['name'])
            
            LOG.info(f"\nğŸ—‚ï¸  ä¸»ç±»ç›®åˆ†å¸ƒç»Ÿè®¡:")
            for main_cat, info in main_categories.items():
                LOG.info(f"  ğŸ“ {main_cat}: {info['count']} ä¸ªå­ç±»ç›®")
                if info['subcats']:
                    sample_subcats = info['subcats'][:3]
                    LOG.info(f"      ç¤ºä¾‹: {', '.join(sample_subcats)}{'...' if len(info['subcats']) > 3 else ''}")
            
            LOG.info("\nğŸ”– æå–åˆ°çš„æ‰€æœ‰ç±»ç›®:")
            for i, sub in enumerate(subcategories[:20]):  # æ˜¾ç¤ºå‰20ä¸ª
                name = sub.get('name', 'N/A')
                level = sub.get('level', 2)
                url = sub.get('url', '')
                indent = "  " * (level - 2)
                LOG.info(f"  {i+1}. {indent}L{level} {name}")
                if url and i < 10:  # åªæ˜¾ç¤ºå‰10ä¸ªçš„URL
                    LOG.info(f"      {indent}-> {url[:100]}{'...' if len(url) > 100 else ''}")
                    
            if subcategory_count > 20:
                LOG.info(f"  ... è¿˜æœ‰ {subcategory_count - 20} ä¸ªç±»ç›®")
        else:
            LOG.warning("\nâš ï¸  æœªæå–åˆ°ç±»ç›®ï¼Œå¯èƒ½åŸå› :")
            LOG.warning("  1. é¡µé¢ç»“æ„ä¸é¢„æœŸä¸åŒ")
            LOG.warning("  2. éœ€è¦è°ƒæ•´é€‰æ‹©å™¨ç­–ç•¥")
            LOG.warning("  3. é¡µé¢éœ€è¦æ›´å¤šåŠ è½½æ—¶é—´")
            LOG.warning("  4. æ ¹åˆ†ç±»é¡µé¢å¯èƒ½éœ€è¦ç‰¹æ®Šå¤„ç†")
        
        LOG.info("=" * 80)
        LOG.info("ğŸ‰ å®Œæ•´åˆ†ç±»æ ‘æå–æµ‹è¯•å®Œæˆï¼")
        
        return subcategory_count > 0
        
    except Exception as e:
        LOG.error(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        LOG.info("=" * 80)
        return False

def test_drill_down():
    """åŒæ­¥åŒ…è£…å‡½æ•°"""
    return asyncio.run(test_category_drill_down())

if __name__ == "__main__":
    success = test_drill_down()
    
    if success:
        print("âœ… TraceParts ç±»ç›®æ·±åº¦çˆ¬å–æµ‹è¯•æˆåŠŸå®Œæˆï¼")
    else:
        print("âŒ TraceParts ç±»ç›®æ·±åº¦çˆ¬å–æµ‹è¯•å¤±è´¥ï¼")
        print("ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒSeleniumé…ç½®")
        
    exit(0 if success else 1)