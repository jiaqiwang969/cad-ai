#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯• 06-1  â€”â€” æµ‹è¯•å•ä¸ªåˆ†ç±»ç›®å½•çš„é“¾æ¥æå–
ä¸“é—¨æµ‹è¯•ç‰¹å®šURLçš„åˆ†ç±»é“¾æ¥æŠ“å–èƒ½åŠ›
"""

import os
import json
import time
import logging
from datetime import datetime
from collections import defaultdict
from typing import Dict, List
from bs4 import BeautifulSoup

# Selenium
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, WebDriverException
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
LOG = logging.getLogger("test-06-1")

# æµ‹è¯•URL - ä¿®æ­£ä¸º.cnåŸŸå
TEST_URL = "https://www.traceparts.cn/en/search/traceparts-classification-mechanical-components-bearings-bearing-blocks-flanged-block-bearings?CatalogPath=TRACEPARTS%3ATP01002002002"

EXCLUDE_PATTERNS = [
    "sign-in", "sign-up", "login", "register", "javascript:", "mailto:", "#"
]


def prepare_driver() -> webdriver.Chrome:
    """å‡†å¤‡Chromeé©±åŠ¨"""
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--window-size=1920,1080')
    chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
    driver = webdriver.Chrome(options=chrome_options)
    driver.set_page_load_timeout(40)
    return driver


def scroll_full(driver):
    """æ»šåŠ¨é¡µé¢åˆ°åº•éƒ¨ï¼Œç¡®ä¿æ‰€æœ‰å†…å®¹åŠ è½½"""
    LOG.info("ğŸ”„ å¼€å§‹æ»šåŠ¨é¡µé¢...")
    last_height = driver.execute_script("return document.body.scrollHeight")
    scroll_count = 0
    
    while True:
        # æ»šåŠ¨åˆ°åº•éƒ¨
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)
        
        # è®¡ç®—æ–°çš„æ»šåŠ¨é«˜åº¦å¹¶ä¸ä¹‹å‰çš„é«˜åº¦è¿›è¡Œæ¯”è¾ƒ
        new_height = driver.execute_script("return document.body.scrollHeight")
        scroll_count += 1
        
        LOG.info(f"   æ»šåŠ¨ç¬¬ {scroll_count} æ¬¡: {last_height} -> {new_height}")
        
        if new_height == last_height:
            break
        last_height = new_height
        
        # é˜²æ­¢æ— é™å¾ªç¯
        if scroll_count > 10:
            LOG.warning("   æ»šåŠ¨æ¬¡æ•°è¿‡å¤šï¼Œåœæ­¢æ»šåŠ¨")
            break
    
    # æ»šåŠ¨å›é¡¶éƒ¨
    driver.execute_script("window.scrollTo(0, 0);")
    time.sleep(1)
    LOG.info("âœ… é¡µé¢æ»šåŠ¨å®Œæˆ")


def extract_all_links(driver) -> List[Dict]:
    """æå–é¡µé¢ä¸­çš„æ‰€æœ‰é“¾æ¥"""
    LOG.info("ğŸ”— å¼€å§‹æå–é¡µé¢ä¸­çš„æ‰€æœ‰é“¾æ¥...")
    
    # å¤šç§CSSé€‰æ‹©å™¨
    selectors = [
        "a[href*='traceparts-classification-']",  # test-06ä½¿ç”¨çš„é€‰æ‹©å™¨
        "a[href*='classification']",              # æ›´å®½æ³›çš„åˆ†ç±»é“¾æ¥
        "a[href*='CatalogPath']",                 # åŒ…å«CatalogPathçš„é“¾æ¥
        "a",                                      # æ‰€æœ‰é“¾æ¥
    ]
    
    all_links = {}
    
    for selector in selectors:
        elements = driver.find_elements(By.CSS_SELECTOR, selector)
        LOG.info(f"   é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
        
        for el in elements:
            href = el.get_attribute('href') or ""
            text = el.text.strip()
            
            if not href or any(pat in href.lower() for pat in EXCLUDE_PATTERNS):
                continue
                
            # å­˜å‚¨é“¾æ¥ä¿¡æ¯
            if href not in all_links:
                all_links[href] = {
                    'url': href,
                    'text': text,
                    'selector': selector,
                    'is_classification': 'traceparts-classification-' in href,
                    'has_catalog_path': 'CatalogPath=' in href
                }
    
    LOG.info(f"âœ… æ€»å…±æ‰¾åˆ° {len(all_links)} ä¸ªå”¯ä¸€é“¾æ¥")
    return list(all_links.values())


def analyze_url(url: str) -> Dict:
    """åˆ†æURLçš„ç»“æ„"""
    analysis = {
        'url': url,
        'domain': '',
        'path': '',
        'catalog_path': '',
        'code': '',
        'level': 0,
        'is_classification': False
    }
    
    try:
        # æå–åŸŸå
        if '://' in url:
            analysis['domain'] = url.split('://')[1].split('/')[0]
        
        # æå–è·¯å¾„
        if '/search/' in url:
            analysis['path'] = url.split('/search/')[1].split('?')[0]
        
        # æå–CatalogPath
        if 'CatalogPath=TRACEPARTS%3A' in url:
            analysis['catalog_path'] = url.split('CatalogPath=TRACEPARTS%3A')[1].split('&')[0]
            analysis['code'] = analysis['catalog_path']
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºåˆ†ç±»é“¾æ¥
        analysis['is_classification'] = 'traceparts-classification-' in url
        
        # åˆ†æå±‚çº§
        if analysis['code']:
            if analysis['code'] == 'TRACEPARTS':
                analysis['level'] = 1
            elif analysis['code'].startswith('TP'):
                code = analysis['code'][2:]  # å»æ‰'TP'
                if len(code) <= 2:
                    analysis['level'] = 2
                else:
                    # æ¯3ä½ä¸€ä¸ªå±‚çº§
                    analysis['level'] = 2 + len(code) // 3
        
    except Exception as e:
        LOG.warning(f"åˆ†æURLå¤±è´¥: {e}")
    
    return analysis


def test_specific_url():
    """æµ‹è¯•ç‰¹å®šURL"""
    if not SELENIUM_AVAILABLE:
        LOG.error("âŒ Selenium æœªå®‰è£…ï¼Œæ— æ³•è¿è¡Œæµ‹è¯•ï¼")
        return False
    
    driver = None
    try:
        driver = prepare_driver()
        
        LOG.info(f"ğŸŒ æµ‹è¯•URL: {TEST_URL}")
        LOG.info("=" * 80)
        
        # è®¿é—®é¡µé¢
        LOG.info("ğŸ”„ æ­£åœ¨åŠ è½½é¡µé¢...")
        driver.get(TEST_URL)
        
        # ç­‰å¾…é¡µé¢åŠ è½½
        WebDriverWait(driver, 30).until(
            EC.presence_of_element_located((By.TAG_NAME, 'body'))
        )
        time.sleep(3)
        
        # æ£€æŸ¥é¡µé¢åŸºæœ¬ä¿¡æ¯
        title = driver.title
        current_url = driver.current_url
        LOG.info(f"ğŸ“„ é¡µé¢æ ‡é¢˜: {title}")
        LOG.info(f"ğŸ”— å½“å‰URL: {current_url}")
        
        # æ£€æŸ¥æ˜¯å¦è¢«é‡å®šå‘
        if current_url != TEST_URL:
            LOG.warning(f"âš ï¸  é¡µé¢è¢«é‡å®šå‘: {TEST_URL} -> {current_url}")
        
        # æ»šåŠ¨é¡µé¢
        scroll_full(driver)
        
        # æå–æ‰€æœ‰é“¾æ¥
        links = extract_all_links(driver)
        
        # åˆ†æé“¾æ¥
        LOG.info("\nğŸ“Š é“¾æ¥åˆ†æç»“æœ:")
        LOG.info("=" * 50)
        
        classification_links = []
        catalog_links = []
        other_links = []
        
        for link in links:
            analysis = analyze_url(link['url'])
            link.update(analysis)
            
            if link['is_classification']:
                classification_links.append(link)
            elif link['has_catalog_path']:
                catalog_links.append(link)
            else:
                other_links.append(link)
        
        LOG.info(f"ğŸ“‹ åˆ†ç±»é“¾æ¥ (traceparts-classification-): {len(classification_links)}")
        LOG.info(f"ğŸ“‹ ç›®å½•é“¾æ¥ (CatalogPath): {len(catalog_links)}")
        LOG.info(f"ğŸ“‹ å…¶ä»–é“¾æ¥: {len(other_links)}")
        
        # è¯¦ç»†æ˜¾ç¤ºåˆ†ç±»é“¾æ¥
        if classification_links:
            LOG.info(f"\nğŸ” åˆ†ç±»é“¾æ¥è¯¦æƒ… (å‰10ä¸ª):")
            for i, link in enumerate(classification_links[:10]):
                LOG.info(f"  {i+1}. {link['text'][:50]}...")
                LOG.info(f"      Code: {link['code']}, Level: {link['level']}")
                LOG.info(f"      URL: {link['url']}")
        
        # è¯¦ç»†æ˜¾ç¤ºç›®å½•é“¾æ¥
        if catalog_links:
            LOG.info(f"\nğŸ” ç›®å½•é“¾æ¥è¯¦æƒ… (å‰10ä¸ª):")
            for i, link in enumerate(catalog_links[:10]):
                LOG.info(f"  {i+1}. {link['text'][:50]}...")
                LOG.info(f"      Code: {link['code']}, Level: {link['level']}")
                LOG.info(f"      URL: {link['url']}")
        
        # æŒ‰å±‚çº§ç»Ÿè®¡
        level_stats = defaultdict(int)
        for link in classification_links + catalog_links:
            if link['level'] > 0:
                level_stats[link['level']] += 1
        
        if level_stats:
            LOG.info(f"\nğŸ“Š å±‚çº§ç»Ÿè®¡:")
            for level in sorted(level_stats.keys()):
                LOG.info(f"   Level {level}: {level_stats[level]} ä¸ªé“¾æ¥")
        
        # ä¿å­˜ç»“æœ
        result = {
            'test_url': TEST_URL,
            'current_url': current_url,
            'title': title,
            'timestamp': datetime.now().isoformat(),
            'total_links': len(links),
            'classification_links': len(classification_links),
            'catalog_links': len(catalog_links),
            'level_stats': dict(level_stats),
            'links': links[:50]  # åªä¿å­˜å‰50ä¸ªé“¾æ¥é¿å…æ–‡ä»¶è¿‡å¤§
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        result_file = "results/test_06_1_single_classification.json"
        os.makedirs("results", exist_ok=True)
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        LOG.info(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
        
        # æ€»ç»“
        LOG.info(f"\nâœ… æµ‹è¯•å®Œæˆ!")
        LOG.info(f"   æ€»é“¾æ¥æ•°: {len(links)}")
        LOG.info(f"   åˆ†ç±»é“¾æ¥: {len(classification_links)}")
        LOG.info(f"   ç›®å½•é“¾æ¥: {len(catalog_links)}")
        
        return True
        
    except Exception as e:
        LOG.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False
        
    finally:
        if driver:
            driver.quit()


def main():
    """ä¸»å‡½æ•°"""
    LOG.info("ğŸš€ å¼€å§‹æµ‹è¯•å•ä¸ªåˆ†ç±»ç›®å½•...")
    LOG.info("=" * 80)
    
    success = test_specific_url()
    
    if success:
        LOG.info("âœ… æµ‹è¯•æˆåŠŸå®Œæˆ!")
    else:
        LOG.error("âŒ æµ‹è¯•å¤±è´¥!")
    
    return success


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)