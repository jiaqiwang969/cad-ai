#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯• 08  â€”â€” é’ˆå¯¹ TraceParts æŸä¸ªæœ€æœ«å±‚ï¼ˆleafï¼‰åˆ†ç±»é¡µé¢ï¼Œæ”¶é›†è¯¥åˆ†ç±»ä¸‹æ‰€æœ‰äº§å“è¯¦æƒ…é¡µé“¾æ¥ã€‚
ä½¿ç”¨ Playwright + stealth ç™»å½•ï¼Œå®Œå…¨ç±»ä¼¼ test-10 çš„å®ç°æ–¹å¼ã€‚

ç¤ºä¾‹å…¥å£ï¼ˆleafï¼‰URLï¼š
https://www.traceparts.cn/en/search/traceparts-classification-mechanical-components-bearings-bearing-blocks-cartridge-blocks?CatalogPath=TRACEPARTS%3ATP01002002006

ç›®æ ‡ï¼šè·å–æ‰€æœ‰å½¢å¦‚
https://www.traceparts.cn/en/product/...?...&Product=90-31032023-039178
çš„é“¾æ¥ï¼Œå¹¶ä¿å­˜åˆ° results/product_links_<TP code>.json

ä½¿ç”¨æ–¹æ³•ï¼š
$ python test/08-test_leaf_product_links.py <leaf_url>
è‹¥ä¸æä¾›å‚æ•°ï¼Œåˆ™è„šæœ¬é»˜è®¤ä½¿ç”¨ä¸Šé¢ç¤ºä¾‹ã€‚
"""

import os
import re
import sys
import json
import time
import random
import logging
from urllib.parse import urlparse, parse_qs
from pathlib import Path
import importlib.util

# Playwright
from playwright.sync_api import sync_playwright

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
LOG = logging.getLogger("test-08")

# è°ƒè¯•å¼€å…³
DEBUG_MODE = True
# å¯é€šè¿‡ç¯å¢ƒå˜é‡ TRACEPARTS_SKIP_LOGIN=1 æ¥è·³è¿‡ç™»å½•
SKIP_LOGIN = os.getenv("TRACEPARTS_SKIP_LOGIN", "0") == "1"  # True è·³è¿‡ç™»å½•
HEADLESS_MODE = True  # è®¾ç½®ä¸ºFalseä½¿ç”¨æœ‰å¤´æ¨¡å¼è°ƒè¯•

# ç™»å½•è´¦å·
EMAIL = os.getenv("TRACEPARTS_EMAIL", "SearcherKerry36154@hotmail.com")
PASSWORD = os.getenv("TRACEPARTS_PASSWORD", "Vsn220mh@")

# --------- åŠ¨æ€åŠ è½½ stealth11i æ¨¡å— ---------
BASE_DIR = Path(__file__).parent
path_to_11i = BASE_DIR / "legacy" / "11i-stealth_cad_downloader.py"
if not path_to_11i.exists():
    LOG.error(f"âŒ Critical: 11i-stealth_cad_downloader.py not found at expected location: {path_to_11i}")
    sys.exit(1)

MOD11 = importlib.util.spec_from_file_location("stealth11i", path_to_11i)
stealth11i = importlib.util.module_from_spec(MOD11)  # type: ignore
MOD11.loader.exec_module(stealth11i)  # type: ignore


PRODUCT_LINK_PATTERN = re.compile(r"[?&]Product=([0-9\-]+)")

def human_like_delay(min_delay=0.5, max_delay=2.0):
    """äººç±»è¡Œä¸ºå»¶è¿Ÿ"""
    delay = random.uniform(min_delay, max_delay)
    time.sleep(delay)

def scroll_full(page, current_products: int = 0, target_count: int = 0):
    """é€æ­¥æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨ï¼Œå¸¦éšæœºäººç±»è¡Œä¸º"""
    if DEBUG_MODE:
        LOG.info("ğŸ“œ å¼€å§‹éšæœºåŒ–æ»šåŠ¨...")
    
    # è·å–åˆå§‹æ»šåŠ¨é«˜åº¦
    last_height = page.evaluate("document.body.scrollHeight")
    
    # éšæœºé€‰æ‹©æ»šåŠ¨æ­¥æ•° (4-7æ­¥)
    scroll_steps = random.randint(4, 7)
    if DEBUG_MODE:
        LOG.info(f"  ğŸ“œ éšæœºé€‰æ‹© {scroll_steps} æ­¥æ»šåŠ¨")
    
    # åˆ†æ­¥æ»šåŠ¨ï¼Œæ¯æ¬¡æ»šåŠ¨ä¸€å®šæ¯”ä¾‹
    for step in range(scroll_steps):
        # æ»šåŠ¨åˆ°å½“å‰çš„ (step+1)/scroll_steps ä½ç½®
        position = last_height * (step + 1) / scroll_steps
        page.evaluate(f"window.scrollTo(0, {position});")
        if DEBUG_MODE:
            LOG.info(f"  ğŸ“œ æ»šåŠ¨æ­¥éª¤ {step + 1}/{scroll_steps}")
        
        # æ ¹æ®è¿›åº¦è°ƒæ•´ç­‰å¾…æ—¶é—´ - å‰æœŸæ›´å¿«
        current_progress = (current_products / target_count * 100) if target_count > 0 else 50
        if current_progress < 80:
            wait_time = random.uniform(0.3, 0.8)  # 80%å‰æ›´å¿«
        else:
            wait_time = random.uniform(0.5, 1.2)  # 80%åæ­£å¸¸é€Ÿåº¦
        time.sleep(wait_time)
        
        # éšæœºæ·»åŠ äººç±»è¡Œä¸ºï¼šæœ‰30%æ¦‚ç‡ç¨å¾®å¾€å›æ»š
        if random.random() < 0.3:
            back_scroll = random.randint(20, 100)
            page.evaluate(f"window.scrollBy(0, -{back_scroll});")
            if DEBUG_MODE:
                LOG.info(f"  ğŸ”™ éšæœºå›æ»š {back_scroll}px")
            time.sleep(random.uniform(0.3, 0.8))
            page.evaluate(f"window.scrollBy(0, {back_scroll + 20});")
    
    # æœ€åç¡®ä¿æ»šåŠ¨åˆ°ç»å¯¹åº•éƒ¨
    page.evaluate("window.scrollTo(0, document.body.scrollHeight);")
    final_wait = random.uniform(0.8, 1.5)  # å‡å°‘æœ€ç»ˆç­‰å¾…
    time.sleep(final_wait)
    if DEBUG_MODE:
        LOG.info(f"ğŸ“œ æ»šåŠ¨å®Œæˆï¼Œæœ€ç»ˆç­‰å¾… {final_wait:.1f}s")


def detect_leaf_node_and_target_count(page) -> tuple:
    """æ£€æµ‹æ˜¯å¦ä¸ºå¶èŠ‚ç‚¹å¹¶è·å–ç›®æ ‡äº§å“æ€»æ•°"""
    try:
        # è·å–é¡µé¢æ–‡æœ¬å†…å®¹
        page_text = page.text_content("body")
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ£€æµ‹"æ•°å­—+results"æ¨¡å¼
        # æ”¯æŒé€—å·åˆ†éš”çš„æ•°å­—å’Œä¸é—´æ–­ç©ºæ ¼(\u00a0)
        import re
        results_pattern = r'\b[\d,]+(?:\s|\u00a0)+results?\b'
        
        has_number_results = bool(re.search(results_pattern, page_text, re.IGNORECASE))
        
        LOG.info(f"ğŸ” å¶èŠ‚ç‚¹æ£€æµ‹: æ•°å­—+resultsæ¨¡å¼={'âœ…' if has_number_results else 'âŒ'}")
        
        if has_number_results:
            LOG.info("âœ… ç¡®è®¤è¿™æ˜¯ä¸€ä¸ªå¶èŠ‚ç‚¹é¡µé¢ï¼ˆåŸºäºæ•°å­—+resultsæ¨¡å¼ï¼‰")
            
            # å°è¯•æå–ç›®æ ‡äº§å“æ€»æ•°
            target_count = extract_target_product_count(page)
            return True, target_count
        else:
            LOG.warning("âš ï¸ è¿™å¯èƒ½ä¸æ˜¯å¶èŠ‚ç‚¹é¡µé¢ï¼ˆæœªæ£€æµ‹åˆ°æ•°å­—+resultsæ¨¡å¼ï¼‰")
            return False, 0
            
    except Exception as e:
        LOG.warning(f"âš ï¸ å¶èŠ‚ç‚¹æ£€æµ‹å¤±è´¥: {e}")
        return False, 0


def extract_target_product_count(page) -> int:
    """ä»é¡µé¢æå–ç›®æ ‡äº§å“æ€»æ•°"""
    try:
        # å¸¸è§çš„äº§å“æ•°é‡æ˜¾ç¤ºæ¨¡å¼ï¼Œæ”¯æŒé€—å·åˆ†éš”ç¬¦
        count_patterns = [
            r"([\d,]+)\s*results?",
            r"([\d,]+)\s*products?", 
            r"([\d,]+)\s*items?",
            r"showing\s*[\d,]+\s*[-â€“]\s*[\d,]+\s*of\s*([\d,]+)",
            r"([\d,]+)\s*total",
            r"found\s*([\d,]+)"
        ]
        
        # è·å–é¡µé¢å…¨éƒ¨æ–‡æœ¬å†…å®¹
        page_text = page.text_content("body").lower()
        
        LOG.info(f"ğŸ” æœç´¢äº§å“æ•°é‡æ¨¡å¼...")
        
        # å°è¯•åŒ¹é…å„ç§æ¨¡å¼
        for pattern in count_patterns:
            if DEBUG_MODE:
                LOG.info(f"  ğŸ“„ å°è¯•æ¨¡å¼: {pattern}")
            matches = re.findall(pattern, page_text, re.IGNORECASE)
            if matches:
                if DEBUG_MODE:
                    LOG.info(f"    ğŸ‰ æ¨¡å¼ {pattern} åŒ¹é…åˆ°: {matches}")
                for match_item in matches:
                    try:
                        # re.findall è¿”å›çš„æ˜¯å…ƒç»„åˆ—è¡¨ï¼Œå³ä½¿åªæœ‰ä¸€ä¸ªæ•è·ç»„
                        # å¦‚æœæ˜¯å…ƒç»„ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼›å¦åˆ™ï¼Œç›´æ¥ä½¿ç”¨
                        actual_match_str = match_item if isinstance(match_item, str) else match_item[0]
                        
                        # ç§»é™¤é€—å·åè½¬æ¢ä¸ºæ•´æ•°
                        count_str = actual_match_str.replace(',', '')
                        if not count_str.isdigit(): # ç¡®ä¿æ˜¯çº¯æ•°å­—
                            LOG.warning(f"      âš ï¸ éæ•°å­—å†…å®¹: '{count_str}' (æ¥è‡ª: '{actual_match_str}')")
                            continue
                        count = int(count_str)
                        
                        # æ›´æ–°äº§å“æ•°é‡èŒƒå›´çš„ä¸‹é™ä¸º1ï¼Œå› ä¸ºæˆ‘ä»¬å…³å¿ƒçš„æ˜¯>0
                        if 1 <= count <= 50000:  # åˆç†çš„äº§å“æ•°é‡èŒƒå›´
                            LOG.info(f"ğŸ¯ å‘ç°ç›®æ ‡äº§å“æ€»æ•°: {count} (æ¥è‡ªæ¨¡å¼: '{pattern}', åŸæ–‡: '{actual_match_str}')")
                            return count
                        else:
                            if DEBUG_MODE:
                                LOG.info(f"      ğŸ”¶ æ•°é‡ {count} ä¸åœ¨æœ‰æ•ˆèŒƒå›´ [1, 50000] (æ¥è‡ª: '{actual_match_str}')")
                    except (ValueError, IndexError) as e_inner:
                        LOG.warning(f"      âš ï¸ å¤„ç†åŒ¹é…é¡¹ '{match_item}' æ—¶å‡ºé”™: {e_inner}")
                        continue
            else:
                if DEBUG_MODE:
                    LOG.info(f"    âŒ æ¨¡å¼ {pattern} æœªåŒ¹é…åˆ°ä»»ä½•å†…å®¹")
        
        LOG.info("âš ï¸ æœªèƒ½æå–åˆ°ç›®æ ‡äº§å“æ€»æ•°")
        return 0
        
    except Exception as e:
        LOG.warning(f"âš ï¸ æå–ç›®æ ‡äº§å“æ€»æ•°å¤±è´¥: {e}")
        return 0


def monitor_progress(current_count: int, target_count: int, round_name: str = ""):
    """ç›‘æ§æŠ“å–è¿›åº¦"""
    if target_count > 0:
        progress = (current_count / target_count) * 100
        remaining = target_count - current_count
        LOG.info(f"ğŸ“ˆ {round_name}è¿›åº¦: {current_count}/{target_count} ({progress:.1f}%), è¿˜éœ€æŠ“å–: {remaining}")
    else:
        LOG.info(f"ğŸ“Š {round_name}å½“å‰æ•°é‡: {current_count}")


def extract_products_on_page(page, seen: set) -> list:
    """æå–å½“å‰é¡µé¢æ‰€æœ‰å« &Product= çš„ a æ ‡ç­¾é“¾æ¥ï¼Œå»é‡"""
    elements = page.query_selector_all("a[href*='&Product=']")
    links = []
    for el in elements:
        href = el.get_attribute('href') or ""
        if not href or href in seen:
            continue
        if '&Product=' not in href:
            continue
        parsed = urlparse(href)
        if '/product/' not in parsed.path:
            continue  # è¿‡æ»¤å¹¿å‘Šæˆ–å…¶ä»–é“¾æ¥
        seen.add(href)
        links.append(href)
    return links


def append_page_size(url: str, size: int = 500) -> str:
    """è‹¥ URL ä¸­æœªåŒ…å« PageSize å‚æ•°ï¼Œåˆ™è¡¥å……ä¸€ä¸ªè¾ƒå¤§çš„å€¼ï¼Œå‡å°‘åˆ†é¡µæ¬¡æ•°ã€‚"""
    if 'PageSize=' in url:
        return url
    # å°è¯•æ›´å¤§çš„PageSizeå’Œå…¶ä»–å¯èƒ½çš„å‚æ•°
    params = f"PageSize={size}&ShowAll=true&IncludeVariants=true"
    if '?' in url:
        return f"{url}&{params}"
    else:
        return f"{url}?{params}"


def click_show_more_if_any(page, target_count: int = 0) -> bool:
    """è‹¥é¡µé¢å­˜åœ¨ 'Show more results' æŒ‰é’®ï¼Œåˆ™ç‚¹å‡»å¹¶è¿”å› Trueï¼›å¦åˆ™ Falseã€‚"""
    try:
        # å…ˆæ£€æŸ¥é¡µé¢ä¸Šæ‰€æœ‰çš„æŒ‰é’®
        all_buttons = page.query_selector_all("button")
        if DEBUG_MODE:
            LOG.info(f"ğŸ” é¡µé¢å…±æœ‰ {len(all_buttons)} ä¸ªæŒ‰é’®")
        
        # æŸ¥æ‰¾åŒ…å«show moreçš„æŒ‰é’®
        show_more_buttons = []
        for i, btn in enumerate(all_buttons):
            try:
                btn_text = (btn.text_content() or "").lower()
                if DEBUG_MODE and btn_text:  # åªåœ¨è°ƒè¯•æ¨¡å¼æ˜¾ç¤ºæ‰€æœ‰æŒ‰é’®æ–‡æœ¬
                    pass  # Add pass to make the if statement syntactically correct
                if 'show' in btn_text and 'more' in btn_text:
                    show_more_buttons.append((i, btn, btn_text))
                    LOG.info(f"ğŸ¯ æ‰¾åˆ°Show MoreæŒ‰é’® {i}: '{btn_text}' (visible: {btn.is_visible()}, enabled: {btn.is_enabled()})")
            except Exception:
                continue
        
        LOG.info(f"ğŸ¯ æ€»å…±æ‰¾åˆ° {len(show_more_buttons)} ä¸ªShow MoreæŒ‰é’®")
        
        # å°è¯•å¤šç§Show MoreæŒ‰é’®æŸ¥æ‰¾ç­–ç•¥
        btn = None
        selectors = [
            "button:has-text('Show more')",
            "button:has-text('Show More')", 
            "button:has-text('Load more')",
            "button:has-text('More results')",
            "a:has-text('Show more')",
            ".show-more, .load-more",
            "button[class*='show-more'], button[class*='load-more']"
        ]
        
        for selector in selectors:
            try:
                btn = page.query_selector(selector)
                if btn and btn.is_visible() and btn.is_enabled():
                    LOG.info(f"âœ… ä½¿ç”¨é€‰æ‹©å™¨æ‰¾åˆ°æŒ‰é’®: {selector}")
                    break
            except Exception:
                continue
        
        if not btn:
            LOG.info("âŒ æ‰€æœ‰é€‰æ‹©å™¨éƒ½æœªæ‰¾åˆ°Show MoreæŒ‰é’®")
            return False
        if btn and btn.is_visible() and btn.is_enabled():
            LOG.info(f"ğŸ‘† æ‰¾åˆ°å¯ç‚¹å‡»çš„Show MoreæŒ‰é’®: '{btn.text_content()}'")
            btn.scroll_into_view_if_needed()
            time.sleep(1)
            
            try:
                # å…ˆå°è¯•æ™®é€šç‚¹å‡»
                btn.click()
                LOG.info("âœ… æ™®é€šç‚¹å‡»æˆåŠŸ")
            except Exception:
                LOG.info("âš ï¸ æ™®é€šç‚¹å‡»å¤±è´¥ï¼Œå°è¯•JavaScriptç‚¹å‡»")
                # ä½¿ç”¨JavaScriptç‚¹å‡»
                page.evaluate("arguments[0].click();", btn)
                LOG.info("âœ… JavaScriptç‚¹å‡»æˆåŠŸ")
            
            # æ ¹æ®è¿›åº¦è°ƒæ•´ç‚¹å‡»åçš„ç­‰å¾…æ—¶é—´
            current_after_click = len(page.query_selector_all("a[href*='&Product=']"))
            progress_after_click = (current_after_click / target_count * 100) if target_count > 0 else 50
            
            if progress_after_click < 80:
                post_click_wait = random.uniform(0.2, 0.5)  # 80%å‰æ›´å¿«
                up_scroll_prob = 0.3  # é™ä½æ¦‚ç‡
                final_wait = random.uniform(0.4, 0.8)
            else:
                post_click_wait = random.uniform(0.4, 0.8)  # 80%åæ­£å¸¸
                up_scroll_prob = 0.5
                final_wait = random.uniform(0.8, 1.5)
                
            time.sleep(post_click_wait)
            
            # ç‚¹å‡»åäººç±»é€šå¸¸ä¼šéšæœºæŸ¥çœ‹æ–°å†…å®¹
            if random.random() < up_scroll_prob:
                up_scroll = random.randint(80, 150)
                page.evaluate(f"window.scrollBy(0, -{up_scroll});")
                if DEBUG_MODE:
                    LOG.info(f"  ğŸ‘€ éšæœºä¸Šæ»šæŸ¥çœ‹ {up_scroll}px")
                time.sleep(random.uniform(0.1, 0.3))
            
            # å†æ»šåˆ°åº•éƒ¨ï¼Œéšæœºç­‰å¾…
            page.evaluate("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(final_wait)
            return True
        else:
            LOG.info("âŒ Show MoreæŒ‰é’®ä¸å¯ç‚¹å‡»")
    except Exception as e:
        LOG.warning(f"âš ï¸ ç‚¹å‡»Show MoreæŒ‰é’®å‡ºé”™: {e}")
        time.sleep(1)
    return False


def load_all_results(page, target_count: int = 0):
    """æŒç»­æ»šåŠ¨å¹¶ç‚¹å‡» 'Show more results'ï¼Œç›´åˆ°å…¨éƒ¨äº§å“éƒ½åŠ è½½å®Œã€‚"""
    # click_count is the general iteration counter for the main loop
    click_count = 0 
    # max_clicks is the overall safety limit for iterations of the main loop
    max_clicks = 100 
    
    # Counts consecutive rounds where product numbers didn't change after a click, 
    # or when no click could be made.
    no_change_rounds = 0
    
    # Counts consecutive failed attempts to find/click the "Show More" button.
    consecutive_click_failures = 0
    MAX_CONSECUTIVE_CLICK_FAILURES = 3

    # æ ¹æ®æ˜¯å¦æœ‰ç›®æ ‡æ•°é‡è°ƒæ•´æ— å˜åŒ–å®¹å¿åº¦
    if target_count > 0:
        max_no_change = 5   # æœ‰ç›®æ ‡æ—¶æ›´å®½å®¹ï¼Œå› ä¸ºæˆ‘ä»¬ç”¨è¿›åº¦æ§åˆ¶
    else:
        max_no_change = 3   # æ— ç›®æ ‡æ—¶ä¸¥æ ¼ä¸€äº›
    
    # Corrected while loop condition using parentheses for implicit line continuation
    while (click_count < max_clicks and
           no_change_rounds < max_no_change and
           consecutive_click_failures < MAX_CONSECUTIVE_CLICK_FAILURES):
        
        LOG.info(f"ğŸš€ ç¬¬ {click_count + 1}/{max_clicks} è½®åŠ è½½æ›´å¤šç»“æœ (æ— äº§å“å˜åŒ–è½®æ¬¡: {no_change_rounds}/{max_no_change}, è¿ç»­ç‚¹å‡»å¤±è´¥: {consecutive_click_failures}/{MAX_CONSECUTIVE_CLICK_FAILURES})...")
        
        current_products = len(page.query_selector_all("a[href*='&Product=']"))
        monitor_progress(current_products, target_count, f"ç¬¬{click_count + 1}è½®å¼€å§‹å‰")
        
        # æ™ºèƒ½åœæ­¢é€»è¾‘ (based on target_count and progress)
        if target_count > 0:
            current_progress = (current_products / target_count) * 100
            if current_progress >= 100.0:
                LOG.info(f"ğŸ¯ è¿›åº¦å·²è¾¾ {current_progress:.1f}%ï¼Œç›®æ ‡å®Œæˆï¼(è·³è¿‡æœ€ç»ˆç¡®è®¤)")
                return 
            elif current_progress >= 95.0 and no_change_rounds >= 2:
                LOG.info(f"ğŸ¯ è¿›åº¦å·²è¾¾ {current_progress:.1f}%ï¼Œä¸”è¿ç»­ {no_change_rounds} è½®æ— å˜åŒ–ï¼Œè®¤ä¸ºæŠ“å–å®Œæˆ (ä¸»å¾ªç¯)")
                break 
            # Inner "fast retry" logic if progress < 95%
            elif current_progress < 95.0:
                LOG.info(f"ğŸš€ å½“å‰è¿›åº¦ {current_progress:.1f}% < 95%ï¼Œå°è¯•å¿«é€Ÿç‚¹å‡»/æ»šåŠ¨...")
                time.sleep(random.uniform(1.0, 2.0))
                
                if click_show_more_if_any(page, target_count):
                    consecutive_click_failures = 0 # Reset on successful click attempt
                    click_count += 1 # Increment main loop/attempt counter
                    after_quick_click_products = len(page.query_selector_all("a[href*='&Product=']"))
                    if after_quick_click_products > current_products:
                        no_change_rounds = 0
                        LOG.info(f"âš¡ å¿«é€Ÿæ¨¡å¼ç‚¹å‡»ï¼šäº§å“æ•°é‡å¢åŠ  {current_products} â†’ {after_quick_click_products}")
                    else:
                        no_change_rounds += 1
                        LOG.info(f"âš¡ å¿«é€Ÿæ¨¡å¼ç‚¹å‡»ï¼šæ— å¢é•¿ï¼Œç´¯è®¡æ— äº§å“å˜åŒ–è½®æ¬¡ {no_change_rounds}")
                    # Check target achievement immediately after a successful click
                    if target_count > 0 and after_quick_click_products >= target_count:
                        LOG.info(f"ğŸ¯ å¿«é€Ÿæ¨¡å¼ç‚¹å‡»åå·²è¾¾ç›®æ ‡äº§å“æ•°é‡: {after_quick_click_products}/{target_count} (è·³è¿‡æœ€ç»ˆç¡®è®¤)")
                        return
                    continue # Continue to next iteration of the main while loop
                else: # click_show_more_if_any returned False in fast mode
                    consecutive_click_failures += 1
                    LOG.info(f"âš¡ å¿«é€Ÿæ¨¡å¼ï¼šæœªæ‰¾åˆ°Show MoreæŒ‰é’® (è¿ç»­ç‚¹å‡»å¤±è´¥: {consecutive_click_failures})ï¼Œå°†æ»šåŠ¨é‡è¯•")
                    scroll_full(page, current_products, target_count)
                    # No click was made, so product count didn't change due to a click.
                    # This round effectively had no change in products due to a click.
                    no_change_rounds += 1 
                # If consecutive_click_failures reached limit here, the main while loop condition will catch it.
                click_count += 1 # Increment main loop/attempt counter even if click failed, as an attempt was made
                continue

        # Default behavior (not in <95% progress fast retry, or if target_count is 0)
        scroll_full(page, current_products, target_count)
        
        if click_show_more_if_any(page, target_count):
            consecutive_click_failures = 0 # Reset on successful click attempt
            # click_count is incremented at the end of the loop iteration
            
            after_click_products = len(page.query_selector_all("a[href*='&Product=']"))
            monitor_progress(after_click_products, target_count, f"ç¬¬{click_count + 1}æ¬¡(å°è¯•)ç‚¹å‡»å")
            
            if after_click_products == current_products:
                no_change_rounds += 1
                LOG.warning(f"âš ï¸ ç‚¹å‡»Show Moreåäº§å“æ•°é‡æ²¡æœ‰å¢åŠ  (æ— äº§å“å˜åŒ–è½®æ¬¡: {no_change_rounds}/{max_no_change})")
            else:
                no_change_rounds = 0  # Reset no_change_rounds for product count
                
            if target_count > 0 and after_click_products >= target_count:
                LOG.info(f"ğŸ¯ å·²è¾¾åˆ°ç›®æ ‡äº§å“æ•°é‡: {after_click_products}/{target_count} (è·³è¿‡æœ€ç»ˆç¡®è®¤)")
                return
        else: # click_show_more_if_any returned False
            consecutive_click_failures += 1
            no_change_rounds += 1 # No click, so no change in products from a click
            LOG.warning(f"âš ï¸ æœªæ‰¾åˆ°æˆ–æœªèƒ½ç‚¹å‡»Show MoreæŒ‰é’® (è¿ç»­ç‚¹å‡»å¤±è´¥: {consecutive_click_failures}/{MAX_CONSECUTIVE_CLICK_FAILURES}, æ— äº§å“å˜åŒ–è½®æ¬¡: {no_change_rounds})")

        click_count += 1 # Increment main loop iteration counter

    # Logging reasons for exiting the main while loop
    if click_count >= max_clicks:
        LOG.warning(f"âš ï¸ ä¸»åŠ è½½é˜¶æ®µå› è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•° ({max_clicks}) è€Œåœæ­¢")
    elif no_change_rounds >= max_no_change:
        LOG.info(f"âœ… ä¸»åŠ è½½é˜¶æ®µå› è¿ç»­ {max_no_change} è½®æ— äº§å“æ•°é‡å˜åŒ–è€Œåœæ­¢")
    elif consecutive_click_failures >= MAX_CONSECUTIVE_CLICK_FAILURES:
        LOG.warning(f"âš ï¸ ä¸»åŠ è½½é˜¶æ®µå› è¿ç»­ {MAX_CONSECUTIVE_CLICK_FAILURES} æ¬¡æœªèƒ½ç‚¹å‡»Show MoreæŒ‰é’®è€Œåœæ­¢")
        
    # æœ€åçš„å½»åº•ç¡®è®¤æ»šåŠ¨
    LOG.info("ğŸ”„ å¼€å§‹æœ€ç»ˆå½»åº•ç¡®è®¤é˜¶æ®µ...")
    final_scroll_rounds = 5 
    consecutive_no_change_final = 0 # Renamed to avoid clash if this script was part of a class
    consecutive_no_button_final = 0 # Renamed

    for final_scroll_iter in range(final_scroll_rounds): # Renamed loop variable
        before_final = len(page.query_selector_all("a[href*='&Product=']"))
        LOG.info(f"ğŸ“Š ç¬¬ {final_scroll_iter + 1}/{final_scroll_rounds} è½®æœ€ç»ˆç¡®è®¤å¼€å§‹ï¼Œå½“å‰äº§å“æ•°: {before_final}")
        
        scroll_full(page, before_final, target_count)
        time.sleep(2) 
        page.evaluate("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)
        
        LOG.info(f"  ğŸ” ç¬¬ {final_scroll_iter + 1} è½®ï¼šæ£€æŸ¥æ˜¯å¦è¿˜æœ‰Show MoreæŒ‰é’®...")
        button_was_clicked_this_round = click_show_more_if_any(page, target_count)
        
        if button_was_clicked_this_round:
            LOG.info(f"  ğŸ¯ ç¬¬ {final_scroll_iter + 1} è½®ï¼šå‘ç°å¹¶ç‚¹å‡»äº†Show MoreæŒ‰é’®ï¼ç»§ç»­æ£€æŸ¥...")
            time.sleep(3) 
            consecutive_no_change_final = 0 
            consecutive_no_button_final = 0 
        else:
            consecutive_no_button_final += 1
            LOG.info(f"  âŒ ç¬¬ {final_scroll_iter + 1} è½®ï¼šæœªæ‰¾åˆ°/ç‚¹å‡»Show MoreæŒ‰é’® (è¿ç»­æœªæ‰¾åˆ°: {consecutive_no_button_final})")
            if consecutive_no_button_final >= 3: # Threshold for consecutive no button
                LOG.info(f"ğŸ¯ è¿ç»­ {consecutive_no_button_final} è½®æœªæ‰¾åˆ°/ç‚¹å‡»Show MoreæŒ‰é’®ï¼Œç¡®è®¤å·²åˆ°é¡µé¢åº•éƒ¨ï¼")
                break
        
        after_final = len(page.query_selector_all("a[href*='&Product=']"))
        LOG.info(f"ğŸ“Š ç¬¬ {final_scroll_iter + 1} è½®æœ€ç»ˆç¡®è®¤ç»“æœ: {before_final} â†’ {after_final}")
        
        if after_final == before_final:
            consecutive_no_change_final += 1
            LOG.info(f"  âœ… ç¬¬ {final_scroll_iter + 1} è½®æ— æ–°å¢äº§å“ (è¿ç»­æ— å˜åŒ–: {consecutive_no_change_final})")
            if consecutive_no_change_final >= 3: # Threshold for consecutive no new products
                LOG.info(f"ğŸ¯ è¿ç»­ {consecutive_no_change_final} è½®æœ€ç»ˆç¡®è®¤æ— å˜åŒ–ï¼Œç¡®è®¤æŠ“å–å®Œæˆï¼")
                break
        else:
            consecutive_no_change_final = 0 
            LOG.info(f"  ğŸ†• ç¬¬ {final_scroll_iter + 1} è½®å‘ç°æ–°äº§å“: +{after_final - before_final}")
    
    final_count = len(page.query_selector_all("a[href*='&Product=']"))
    LOG.info(f"ğŸ load_all_resultså®Œæˆï¼Œæœ€ç»ˆäº§å“é“¾æ¥æ•°: {final_count}")
    if target_count > 0:
        final_progress = (final_count / target_count) * 100
        LOG.info(f"ğŸ“Š æœ€ç»ˆè¿›åº¦: {final_progress:.1f}% ({final_count}/{target_count})")


def collect_all_product_links(page, leaf_url: str) -> list:
    """ä¸»æŠ“å–å‡½æ•°ï¼šè®¿é—® leaf é¡µé¢ï¼Œæ»šåŠ¨+ç‚¹å‡»åŠ è½½å…¨éƒ¨äº§å“ï¼Œå¹¶æ”¶é›†é“¾æ¥"""
    
    # ä¿®æ”¹URLä»¥æ”¯æŒæ›´å¤§çš„PageSize
    enhanced_url = append_page_size(leaf_url, 500)
    LOG.info(f"ğŸŒ è®¿é—®å¢å¼ºURL: {enhanced_url}")
    
    page.goto(enhanced_url)
    page.wait_for_load_state("networkidle")
    time.sleep(5)  # ç­‰å¾…é¡µé¢åŠ è½½
    
    # æ£€æµ‹æ˜¯å¦ä¸ºå¶èŠ‚ç‚¹å¹¶è·å–ç›®æ ‡æ•°é‡
    is_leaf, target_count = detect_leaf_node_and_target_count(page)
    
    # è®°å½•åˆå§‹äº§å“æ•°é‡
    initial_elements = page.query_selector_all("a[href*='&Product=']")
    LOG.info(f"ğŸ“Š é¡µé¢åˆå§‹åŠ è½½çš„äº§å“é“¾æ¥æ•°: {len(initial_elements)}")
    
    # å¦‚æœä¸æ˜¯å¶èŠ‚ç‚¹ä¸”æ²¡æœ‰äº§å“é“¾æ¥ï¼Œç›´æ¥é€€å‡º
    if not is_leaf and len(initial_elements) == 0:
        LOG.error("âŒ æ£€æµ‹åˆ°éå¶èŠ‚ç‚¹é¡µé¢ä¸”æ— äº§å“é“¾æ¥ï¼Œåœæ­¢æŠ“å–")
        return [], {
            "extracted_count": 0,
            "target_count": 0,
            "progress_percentage": 0.0,
            "completion_status": "non_leaf_page",
            "error": "Page is not a leaf node with products"
        }
    
    if not is_leaf:
        LOG.warning("âš ï¸ é¡µé¢ä¼¼ä¹ä¸æ˜¯å¶èŠ‚ç‚¹ï¼Œä½†å‘ç°äº§å“é“¾æ¥ï¼Œç»§ç»­å°è¯•æŠ“å–...")
    
    if target_count > 0:
        LOG.info(f"ğŸ¯ ç›®æ ‡äº§å“æ€»æ•°: {target_count}")
        expected_progress = (len(initial_elements) / target_count) * 100
        LOG.info(f"ğŸ“ˆ åˆå§‹è¿›åº¦: {expected_progress:.1f}%")
    
    # åŠ è½½æ‰€æœ‰ç»“æœ
    load_all_results(page, target_count)
    
    # æ”¶é›†æ‰€æœ‰é“¾æ¥
    seen = set()
    all_links = extract_products_on_page(page, seen)
    
    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    final_count = len(all_links)
    LOG.info(f"ğŸ¯ æœ€ç»ˆæŠ“å–ç»“æœ: {final_count} ä¸ªäº§å“é“¾æ¥")
    
    # è®¡ç®—è¿›åº¦ä¿¡æ¯
    progress_info = {
        "extracted_count": final_count,
        "target_count": target_count,
        "progress_percentage": 0.0,
        "completion_status": "unknown"
    }
    
    if target_count > 0:
        final_progress = (final_count / target_count) * 100
        missing_count = target_count - final_count
        progress_info["progress_percentage"] = round(final_progress, 1)
        
        LOG.info(f"ğŸ“Š å®Œæˆåº¦: {final_progress:.1f}% ({final_count}/{target_count})")
        if missing_count > 0:
            LOG.warning(f"âš ï¸ å¯èƒ½é—æ¼: {missing_count} ä¸ªäº§å“")
            progress_info["completion_status"] = "partial"
        else:
            LOG.info("âœ… å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼")
            progress_info["completion_status"] = "complete"
    else:
        LOG.info("ğŸ“Š æœªæ£€æµ‹åˆ°ç›®æ ‡æ•°é‡ï¼ŒæŒ‰å®é™…æŠ“å–ç»“æœç»Ÿè®¡")
        progress_info["completion_status"] = "no_target"
    
    return all_links, progress_info


def tp_code_from_url(url: str) -> str:
    """ä» leaf URL æå– TP ç¼–ç ï¼Œä¾‹ TP01002002006"""
    qs_part = urlparse(url).query
    params = parse_qs(qs_part)
    cp = params.get('CatalogPath', [''])[0]
    if cp.startswith('TRACEPARTS:'):
        cp = cp.split(':',1)[1]
    return cp


def main():
    # è¯»å–å‘½ä»¤è¡Œå‚æ•°
    #leaf_url = sys.argv[1] if len(sys.argv) > 1 else "https://www.traceparts.cn/en/search/traceparts-classification-mechanical-components-bearings-bearing-blocks-flanged-block-bearings?CatalogPath=TRACEPARTS%3ATP01002002002"
    # æµ‹è¯•ç”¨ä¾‹ï¼šä½¿ç”¨å¸¦PageSizeå‚æ•°çš„bearingå¤§ç±»é¡µé¢
    # ç¤ºä¾‹å…¥å£ï¼ˆleafï¼‰URLï¼š
    # https://www.traceparts.cn/en/search/traceparts-classification-mechanical-components-bearings-bearing-blocks-pillow-block-bearings-pillow-block-bearings-plain-bearings?CatalogPath=TRACEPARTS%3ATP01002002003003
    # é»˜è®¤leaf_urlä¸ºç”µæœºæ§åˆ¶ç±»ç›®ï¼Œå¦‚éœ€æµ‹è¯•å…¶ä»–ç±»ç›®å¯æ›¿æ¢URLæˆ–é€šè¿‡å‘½ä»¤è¡Œå‚æ•°ä¼ å…¥
    # é»˜è®¤leaf_urlä¸ºâ€œLettersâ€ç±»ç›®ï¼Œå¦‚éœ€æµ‹è¯•å…¶ä»–ç±»ç›®å¯æ›¿æ¢URLæˆ–é€šè¿‡å‘½ä»¤è¡Œå‚æ•°ä¼ å…¥
    leaf_url = sys.argv[1] if len(sys.argv) > 1 else "https://www.traceparts.cn/en/search/traceparts-classification-manufacturing-engineering-information-technology-software-and-general-drawings-for-software-symbols-computer-dummies-general-drawings-symbols-computer-dummies-graphical-symbols-letters?CatalogPath=TRACEPARTS%3ATP02003002001002002"

    tp_code = tp_code_from_url(leaf_url) or "UNKNOWN"

    with sync_playwright() as p:
        # åˆ›å»ºstealthæµè§ˆå™¨
        headless_status = "æ— å¤´æ¨¡å¼" if HEADLESS_MODE else "æœ‰å¤´æ¨¡å¼"
        LOG.info(f"ğŸ–¥ï¸ å¯åŠ¨æµè§ˆå™¨ ({headless_status})")
        browser, ctx, page = stealth11i.create_stealth_browser(p, headless=HEADLESS_MODE)
        
        try:
            # é¦–å…ˆè¿›è¡Œç™»å½•ï¼ˆå¯é€‰ï¼‰
            if not SKIP_LOGIN:
                LOG.info("ğŸ” å¼€å§‹stealthç™»å½•æµç¨‹...")
                if EMAIL == "SearcherKerry36154@hotmail.com" or PASSWORD == "Vsn220mh@":
                    LOG.info("âœ… ä½¿ç”¨é¢„è®¾å‡­æ®è¿›è¡Œç™»å½•")
                
                if stealth11i.stealth_login(page, EMAIL, PASSWORD):
                    LOG.info("âœ… ç™»å½•æˆåŠŸï¼")
                else:
                    LOG.warning("âš ï¸ ç™»å½•å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•æŠ“å–...")
            else:
                LOG.info("â­ï¸ è·³è¿‡ç™»å½•æµç¨‹")
            
            all_links, progress_info = collect_all_product_links(page, leaf_url)
            
            # æ£€æŸ¥æ˜¯å¦å› ä¸ºéå¶èŠ‚ç‚¹é¡µé¢è€Œé€€å‡º
            if progress_info.get("completion_status") == "non_leaf_page":
                LOG.error("âŒ å› æ£€æµ‹åˆ°éå¶èŠ‚ç‚¹é¡µé¢ï¼Œç¨‹åºç»ˆæ­¢")
                return False
            
            if not all_links:
                LOG.warning("æœªæŠ“å–åˆ°ä»»ä½•äº§å“é“¾æ¥ï¼")
            
            # è¾“å‡ºåˆ°æ–‡ä»¶ï¼ŒåŒ…å«è¿›åº¦ä¿¡æ¯
            os.makedirs("results", exist_ok=True)
            out_file = f"results/product_links_{tp_code}.json"
            
            # å‡†å¤‡å®Œæ•´çš„æ•°æ®ç»“æ„
            output_data = {
                "leaf_url": leaf_url,
                "tp_code": tp_code,
                "total": len(all_links),
                "progress": progress_info,
                "extraction_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "links": all_links
            }
            
            with open(out_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            # æ›´è¯¦ç»†çš„å®Œæˆæ—¥å¿—
            completion_msg = f"âœ… å…±æŠ“å– {len(all_links)} æ¡äº§å“é“¾æ¥"
            if progress_info["target_count"] > 0:
                completion_msg += f" (å®Œæˆåº¦: {progress_info['progress_percentage']}%)"
            completion_msg += f"ï¼Œå·²ä¿å­˜åˆ° {out_file}"
            LOG.info(completion_msg)
            
            return True
        finally:
            browser.close()


if __name__ == "__main__":
    ok = main()
    print("âœ… test-08 æˆåŠŸ" if ok else "âŒ test-08 å¤±è´¥")