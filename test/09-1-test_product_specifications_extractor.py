#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯• 09-1 â€”â€” äº§å“è§„æ ¼é“¾æ¥æå–å™¨ (é‡æ–°è®¾è®¡ç‰ˆ)
ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰äº§å“è§„æ ¼ï¼Œæ— éœ€ç¿»é¡µ
è¿è¡Œ: make test-09-1
"""
import os, sys, time, re, json
from pathlib import Path
from urllib.parse import urlparse, parse_qs, urlencode

# Selenium imports
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait, Select
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, NoSuchElementException
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False
    print("âŒ Selenium æœªå®‰è£…ï¼Œæ— æ³•è¿è¡Œæµ‹è¯•ï¼")
    sys.exit(1)

RESULTS_DIR = Path("results/product_specifications")
RESULTS_DIR.mkdir(parents=True, exist_ok=True)

# é»˜è®¤äº§å“URLï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
# ä¹‹å‰çš„é“å‹æäº§å“URL
# DEFAULT_PRODUCT_URL = "https://www.traceparts.cn/en/product/jlcmc-aluminum-extrusion-txceh161515l100dalka75?Product=90-27122024-029219"
DEFAULT_PRODUCT_URL = "https://www.traceparts.cn/en/product/jw-winco-en-561-plastic-mounting-angle-brackets-type-b-and-c?CatalogPath=TRACEPARTS%3ATP05001&Product=90-05102020-040831"
#DEFAULT_PRODUCT_URL = "https://www.traceparts.cn/en/product/the-timken-company-double-concentric-cartridge-block-qaamc10a050s?CatalogPath=TRACEPARTS%3ATP01002002006&Product=90-31032023-039175"
#DEFAULT_PRODUCT_URL = "https://www.traceparts.cn/en/product/jw-winco-din-787-metric-size-steel-tslot-bolts?CatalogPath=TRACEPARTS%3ATP01001013006&Product=90-04092020-049501"
#DEFAULT_PRODUCT_URL = "https://www.traceparts.cn/en/product/the-timken-company-double-concentric-cartridge-block-qaamc10a050s?CatalogPath=TRACEPARTS%3ATP01002002006&Product=90-31032023-039175"
#DEFAULT_PRODUCT_URL = "https://www.traceparts.cn/en/product/petzoldt-cpleuchten-gmbh-rohrleuchte-sls50-14w-230v?CatalogPath=TRACEPARTS%3ATP12001003&Product=90-13052019-057778"
PRODUCT_URL = os.getenv("TRACEPARTS_PRODUCT_URL", DEFAULT_PRODUCT_URL)

def prepare_driver():
    """å‡†å¤‡Chromeé©±åŠ¨å™¨"""
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')
    options.add_argument('--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
    
    driver = webdriver.Chrome(options=options)
    driver.set_page_load_timeout(40)
    return driver

def scroll_page_fully(driver):
    """å®Œæ•´æ»šåŠ¨é¡µé¢ç¡®ä¿æ‰€æœ‰å†…å®¹åŠ è½½"""
    print("ğŸ”„ æ»šåŠ¨é¡µé¢ç¡®ä¿å†…å®¹å®Œå…¨åŠ è½½...")
    
    # å…ˆæ»šåŠ¨åˆ°åº•éƒ¨
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(2)
    
    # å†æ»šåŠ¨åˆ°é¡¶éƒ¨
    driver.execute_script("window.scrollTo(0, 0);")
    time.sleep(1)
    
    # æœ€åæ»šåŠ¨åˆ°é¡µé¢ä¸­éƒ¨
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight/2);")
    time.sleep(1)

def set_items_per_page_to_all(driver):
    """è®¾ç½®æ¯é¡µæ˜¾ç¤ºé¡¹ç›®æ•°ä¸ºå…¨éƒ¨"""
    print("ğŸ¯ å°è¯•è®¾ç½®æ¯é¡µæ˜¾ç¤ºé¡¹ç›®æ•°ä¸ºå…¨éƒ¨...")
    
    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨åˆ†é¡µæ§ä»¶
    try:
        # æŸ¥æ‰¾æ˜¯å¦æœ‰"Items per page"ç›¸å…³æ–‡æœ¬
        pagination_indicators = [
            "//*[contains(text(), 'Items per page')]",
            "//*[contains(text(), 'items per page')]", 
            "//*[contains(text(), 'out of') and contains(text(), 'items')]",
            "//*[contains(text(), 'Show') and contains(text(), 'entries')]"
        ]
        
        has_pagination = False
        for selector in pagination_indicators:
            try:
                elements = driver.find_elements(By.XPATH, selector)
                if elements and any(elem.is_displayed() for elem in elements):
                    has_pagination = True
                    print(f"  âœ… æ£€æµ‹åˆ°åˆ†é¡µæ§ä»¶: {elements[0].text.strip()[:50]}...")
                    break
            except:
                continue
        
        if not has_pagination:
            print("  â„¹ï¸ æœªæ£€æµ‹åˆ°åˆ†é¡µæ§ä»¶ï¼Œå¯èƒ½æ˜¯å•é¡µé¢ï¼Œç›´æ¥æå–æ•°æ®")
            return False  # è¿”å›Falseè¡¨ç¤ºæ²¡æœ‰åˆ†é¡µï¼Œä½†è¿™æ˜¯æ­£å¸¸æƒ…å†µ
            
    except Exception as e:
        print(f"  âš ï¸ æ£€æµ‹åˆ†é¡µæ§ä»¶æ—¶å‡ºé”™: {e}")
        return False
    
    # ç­–ç•¥1: å¯»æ‰¾åˆ†é¡µåŒºåŸŸä¸­çš„æ•°å­—å’Œä¸‹æ‹‰æ§ä»¶
    try:
        print("  ğŸ” ç­–ç•¥1: æŸ¥æ‰¾åˆ†é¡µåŒºåŸŸçš„æ§ä»¶...")
        
        # å…ˆæŸ¥æ‰¾åŒ…å«"Items per page"çš„åˆ†é¡µå®¹å™¨
        pagination_selectors = [
            "//*[contains(text(), 'Items per page')]",
            "//*[contains(text(), 'items per page')]",
            "//*[contains(text(), 'per page')]",
            "//*[contains(text(), 'out of') and contains(text(), 'items')]"
        ]
        
        pagination_container = None
        for selector in pagination_selectors:
            try:
                elements = driver.find_elements(By.XPATH, selector)
                if elements:
                    # è·å–åŒ…å«åˆ†é¡µä¿¡æ¯çš„æœ€å¤–å±‚å®¹å™¨
                    for elem in elements:
                        # æŸ¥æ‰¾çˆ¶å®¹å™¨
                        for level in range(1, 4):  # å‘ä¸ŠæŸ¥æ‰¾3å±‚
                            try:
                                container = elem.find_element(By.XPATH, f"./ancestor::*[{level}]")
                                container_text = container.text.lower()
                                if 'items per page' in container_text or 'out of' in container_text:
                                    pagination_container = container
                                    print(f"    æ‰¾åˆ°åˆ†é¡µå®¹å™¨ï¼Œæ–‡æœ¬: {container.text[:100]}...")
                                    break
                            except:
                                continue
                        if pagination_container:
                            break
                if pagination_container:
                    break
            except:
                continue
        
        if pagination_container:
            # åœ¨åˆ†é¡µå®¹å™¨ä¸­æŸ¥æ‰¾æ‰€æœ‰å¯ç‚¹å‡»çš„æ•°å­—
            print("    åœ¨åˆ†é¡µå®¹å™¨ä¸­æŸ¥æ‰¾å¯ç‚¹å‡»æ•°å­—...")
            clickable_selectors = [
                ".//select",
                ".//button[text()]",
                ".//a[text()]", 
                ".//*[@role='button']",
                ".//*[contains(@class,'select')]",
                ".//*[contains(@class,'dropdown')]",
                ".//*[contains(@onclick,'')]",
                ".//*[text()='10']",
                ".//*[text()='25']",
                ".//*[text()='50']"
            ]
            
            for selector in clickable_selectors:
                try:
                    elements = pagination_container.find_elements(By.XPATH, selector)
                    for elem in elements:
                        elem_text = elem.text.strip()
                        elem_tag = elem.tag_name
                        
                        print(f"      æ‰¾åˆ°å¯ç‚¹å‡»å…ƒç´ : {elem_tag} '{elem_text}'")
                        
                        # å¦‚æœæ˜¯selectï¼Œæ£€æŸ¥é€‰é¡¹
                        if elem_tag == 'select':
                            options = elem.find_elements(By.TAG_NAME, 'option')
                            option_texts = [opt.text.strip() for opt in options]
                            print(f"        é€‰é¡¹: {option_texts}")
                            
                            # æŸ¥æ‰¾Allæˆ–å¤§æ•°å­—é€‰é¡¹
                            for opt in options:
                                text = opt.text.strip().lower()
                                if text in ['all', 'å…¨éƒ¨'] or (text.isdigit() and int(text) >= 50):
                                    print(f"        âœ… é€‰æ‹©: {opt.text}")
                                    driver.execute_script("arguments[0].scrollIntoView({block:'center'});", opt)
                                    time.sleep(1)
                                    opt.click()
                                    time.sleep(5)
                                    return True
                        
                        # å¦‚æœæ˜¯æ•°å­—æ–‡æœ¬ä¸”å¯ç‚¹å‡»ï¼Œå°è¯•ç‚¹å‡»
                        elif elem.is_displayed() and elem.is_enabled():
                            if elem_text.isdigit() or elem_text.lower() in ['all', 'å…¨éƒ¨']:
                                try:
                                    print(f"        ğŸ–±ï¸ å°è¯•ç‚¹å‡»: {elem_text}")
                                    driver.execute_script("arguments[0].scrollIntoView({block:'center'});", elem)
                                    time.sleep(1)
                                    elem.click()
                                    time.sleep(3)
                                    
                                    # ğŸ¯ å…³é”®æ”¹è¿›ï¼šæ˜ç¡®æŸ¥æ‰¾å¹¶ç‚¹å‡»"All"é€‰é¡¹
                                    print(f"        ğŸ” æŸ¥æ‰¾å¼¹å‡ºèœå•ä¸­çš„Allé€‰é¡¹...")
                                    all_found = False
                                    
                                    # æ›´å…¨é¢çš„Allé€‰é¡¹æŸ¥æ‰¾
                                    all_selectors = [
                                        "//li[normalize-space(.)='All']",
                                        "//div[normalize-space(.)='All']",
                                        "//option[normalize-space(.)='All']",
                                        "//span[normalize-space(.)='All']",
                                        "//button[normalize-space(.)='All']",
                                        "//a[normalize-space(.)='All']",
                                        "//*[@role='option'][normalize-space(.)='All']",
                                        "//*[contains(@class,'option')][normalize-space(.)='All']",
                                        "//*[contains(@class,'menu-item')][normalize-space(.)='All']",
                                        "//li[text()='All']",
                                        "//li[normalize-space(.)='å…¨éƒ¨']"
                                    ]
                                    
                                    for all_sel in all_selectors:
                                        try:
                                            all_options = driver.find_elements(By.XPATH, all_sel)
                                            for all_option in all_options:
                                                if all_option.is_displayed() and all_option.is_enabled():
                                                    print(f"        âœ… æ‰¾åˆ°Allé€‰é¡¹: {all_option.text} ({all_option.tag_name})")
                                                    all_option.click()
                                                    print(f"        âœ… æˆåŠŸé€‰æ‹©Allé€‰é¡¹ï¼")
                                                    time.sleep(5)
                                                    all_found = True
                                                    return True
                                        except Exception as e:
                                            continue
                                    
                                    if not all_found:
                                        # å¦‚æœæ²¡æ‰¾åˆ°Allï¼Œå°è¯•æ‰¾æœ€å¤§æ•°å­—
                                        print(f"        ğŸ” æœªæ‰¾åˆ°Allï¼ŒæŸ¥æ‰¾æœ€å¤§æ•°å­—é€‰é¡¹...")
                                        max_selectors = [
                                            "//li[text()='100']",
                                            "//li[text()='50']", 
                                            "//li[text()='25']",
                                            "//option[text()='100']",
                                            "//option[text()='50']"
                                        ]
                                        
                                        for max_sel in max_selectors:
                                            try:
                                                max_options = driver.find_elements(By.XPATH, max_sel)
                                                for max_option in max_options:
                                                    if max_option.is_displayed():
                                                        print(f"        âœ… é€‰æ‹©æœ€å¤§æ•°å­—: {max_option.text}")
                                                        max_option.click()
                                                        time.sleep(5)
                                                        return True
                                            except:
                                                continue
                                        
                                        print(f"        âš ï¸ ç‚¹å‡»åæœªæ‰¾åˆ°åˆé€‚çš„é€‰é¡¹")
                                    
                                except Exception as e:
                                    print(f"        âŒ ç‚¹å‡»å¤±è´¥: {e}")
                                    
                except Exception as e:
                    print(f"      æŸ¥æ‰¾å…ƒç´ å¤±è´¥: {e}")
                    
    except Exception as e:
        print(f"  âŒ ç­–ç•¥1å¤±è´¥: {e}")
    
    # ç­–ç•¥2: æ›´ç›´æ¥çš„æŸ¥æ‰¾æ–¹å¼ - æŸ¥æ‰¾åŒ…å«å½“å‰é¡µæ•°"10"çš„å¯ç‚¹å‡»å…ƒç´ 
    try:
        print("  ğŸ” ç­–ç•¥2: æŸ¥æ‰¾å½“å‰é¡µæ•°æ§ä»¶...")
        
        # æŸ¥æ‰¾æ˜¾ç¤º"10"çš„å¯ç‚¹å‡»å…ƒç´  (å½“å‰æ¯é¡µæ˜¾ç¤ºæ•°é‡)
        number_selectors = [
            "//select[option[text()='10']]",
            "//*[text()='10' and (@onclick or @role='button' or contains(@class,'select') or contains(@class,'dropdown'))]",
            "//button[text()='10']",
            "//a[text()='10']",
            "//*[@data-value='10']",
            "//*[contains(@class,'pagesize') or contains(@class,'page-size')]"
        ]
        
        for selector in number_selectors:
            try:
                elements = driver.find_elements(By.XPATH, selector)
                for elem in elements:
                    if elem.is_displayed():
                        elem_tag = elem.tag_name
                        elem_text = elem.text.strip()
                        elem_class = elem.get_attribute('class') or ''
                        
                        print(f"    æ‰¾åˆ°æ•°å­—æ§ä»¶: {elem_tag} '{elem_text}' class='{elem_class}'")
                        
                        if elem_tag == 'select':
                            # å¦‚æœæ˜¯selectï¼ŒæŸ¥æ‰¾Allé€‰é¡¹
                            options = elem.find_elements(By.TAG_NAME, 'option')
                            for opt in options:
                                if opt.text.strip().lower() in ['all', 'å…¨éƒ¨'] or (opt.text.strip().isdigit() and int(opt.text.strip()) >= 50):
                                    print(f"    âœ… åœ¨selectä¸­é€‰æ‹©: {opt.text}")
                                    opt.click()
                                    time.sleep(5)
                                    return True
                        else:
                            # å¦‚æœæ˜¯å¯ç‚¹å‡»å…ƒç´ ï¼Œå°è¯•ç‚¹å‡»
                            try:
                                print(f"    ğŸ–±ï¸ ç‚¹å‡»æ•°å­—æ§ä»¶: {elem_text}")
                                driver.execute_script("arguments[0].scrollIntoView({block:'center'});", elem)
                                time.sleep(1)
                                elem.click()
                                time.sleep(3)
                                
                                # æŸ¥æ‰¾å¼¹å‡ºèœå•ä¸­çš„Allé€‰é¡¹
                                all_options = driver.find_elements(By.XPATH, "//li[normalize-space(.)='All'] | //option[normalize-space(.)='All'] | //*[@role='option'][normalize-space(.)='All']")
                                for opt in all_options:
                                    if opt.is_displayed():
                                        opt.click()
                                        print(f"    âœ… é€‰æ‹©äº†Allé€‰é¡¹")
                                        time.sleep(5)
                                        return True
                                        
                            except Exception as e:
                                print(f"    âŒ ç‚¹å‡»æ•°å­—æ§ä»¶å¤±è´¥: {e}")
                                
            except Exception as e:
                print(f"    æŸ¥æ‰¾æ•°å­—æ§ä»¶å¤±è´¥: {e}")
                
    except Exception as e:
        print(f"  âŒ ç­–ç•¥2å¤±è´¥: {e}")
    
    # ç­–ç•¥3: æŸ¥æ‰¾æ‰€æœ‰selectå…ƒç´ ï¼Œä¸“é—¨å¯»æ‰¾åŒ…å«æ•°å­—é€‰é¡¹çš„
    try:
        print("  ğŸ” ç­–ç•¥3: æ£€æŸ¥æ‰€æœ‰selectå…ƒç´ ...")
        
        select_elements = driver.find_elements(By.TAG_NAME, 'select')
        print(f"    é¡µé¢å…±æœ‰ {len(select_elements)} ä¸ªselectå…ƒç´ ")
        
        for i, select_elem in enumerate(select_elements):
            try:
                if not select_elem.is_displayed():
                    continue
                    
                options = select_elem.find_elements(By.TAG_NAME, 'option')
                option_data = []
                has_numbers = False
                
                for opt in options:
                    text = opt.text.strip()
                    value = opt.get_attribute('value')
                    option_data.append(f"{text}({value})")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ•°å­—é€‰é¡¹ï¼ˆåˆ†é¡µç›¸å…³ï¼‰
                    if text.isdigit() and int(text) <= 100:
                        has_numbers = True
                
                print(f"    Select {i+1}: åŒ…å«æ•°å­—={has_numbers}")
                if len(option_data) <= 10:  # åªæ˜¾ç¤ºé€‰é¡¹å°‘çš„select
                    print(f"      é€‰é¡¹: {option_data}")
                
                # å¦‚æœåŒ…å«æ•°å­—é€‰é¡¹ï¼Œå¯èƒ½æ˜¯åˆ†é¡µæ§ä»¶
                if has_numbers:
                    print(f"    ğŸ¯ è¿™å¯èƒ½æ˜¯åˆ†é¡µæ§ä»¶ï¼Œå°è¯•é€‰æ‹©æœ€å¤§å€¼...")
                    
                    # æŸ¥æ‰¾Allæˆ–æœ€å¤§æ•°å­—
                    best_option = None
                    for opt in options:
                        text = opt.text.strip().lower()
                        if text in ['all', 'å…¨éƒ¨']:
                            best_option = opt
                            break
                        elif text.isdigit() and int(text) >= 50:
                            best_option = opt
                    
                    if best_option:
                        print(f"      âœ… é€‰æ‹©: {best_option.text}")
                        driver.execute_script("arguments[0].scrollIntoView({block:'center'});", best_option)
                        time.sleep(1)
                        best_option.click()
                        time.sleep(5)
                        return True
                        
            except Exception as e:
                print(f"    å¤„ç†select {i+1}å¤±è´¥: {e}")
                
    except Exception as e:
        print(f"  âŒ ç­–ç•¥3å¤±è´¥: {e}")
    
    print("  âŒ æ‰€æœ‰ç­–ç•¥éƒ½æœªèƒ½æ‰¾åˆ°å¯ç”¨çš„åˆ†é¡µæ§ä»¶")
    return False

def extract_all_product_specifications(driver):
    """ä¸€æ¬¡æ€§æå–æ‰€æœ‰äº§å“è§„æ ¼"""
    print("ğŸ“‹ å¼€å§‹æå–æ‰€æœ‰äº§å“è§„æ ¼...")
    
    specifications = []
    seen_references = set()
    
    try:
        # ç­‰å¾…é¡µé¢ç¨³å®š
        time.sleep(3)
        
        # å®Œæ•´æ»šåŠ¨é¡µé¢
        scroll_page_fully(driver)
        
        # æ–¹æ³•1: æŸ¥æ‰¾ "Product selection" æˆ–ç±»ä¼¼æ ‡é¢˜ä¸‹çš„è¡¨æ ¼
        print("ğŸ” æŸ¥æ‰¾äº§å“é€‰æ‹©åŒºåŸŸ...")
        
        # æŸ¥æ‰¾äº§å“é€‰æ‹©ç›¸å…³çš„æ ‡é¢˜
        product_section_keywords = [
            'product selection', 'product list', 'product specifications',
            'available products', 'product variants', 'models available',
            'produktauswahl', 'produktliste', 'produktspezifikationen',  # å¾·è¯­
            'sÃ©lection de produits', 'liste des produits',  # æ³•è¯­
            'äº§å“é€‰æ‹©', 'äº§å“åˆ—è¡¨', 'äº§å“è§„æ ¼',  # ä¸­æ–‡
            'specification', 'specifications', 'technical data'
        ]
        
        product_section = None
        table_element = None
        
        # å°è¯•é€šè¿‡æ ‡é¢˜æŸ¥æ‰¾
        for keyword in product_section_keywords:
            # æŸ¥æ‰¾åŒ…å«å…³é”®è¯çš„æ ‡é¢˜å…ƒç´ 
            xpath_selectors = [
                f"//*[contains(translate(text(), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{keyword.lower()}')]",
                f"//h1[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{keyword.lower()}')]",
                f"//h2[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{keyword.lower()}')]",
                f"//h3[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{keyword.lower()}')]",
                f"//h4[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{keyword.lower()}')]",
                f"//div[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), '{keyword.lower()}')]"
            ]
            
            for selector in xpath_selectors:
                try:
                    elements = driver.find_elements(By.XPATH, selector)
                    for elem in elements:
                        if elem.is_displayed() and elem.text.strip():
                            print(f"  âœ… æ‰¾åˆ°ç›¸å…³æ ‡é¢˜: '{elem.text.strip()}'")
                            
                            # æŸ¥æ‰¾è¯¥å…ƒç´ åé¢çš„ç¬¬ä¸€ä¸ªè¡¨æ ¼
                            # å…ˆå°è¯•åœ¨åŒä¸€çˆ¶å®¹å™¨å†…æŸ¥æ‰¾
                            parent = elem.find_element(By.XPATH, "./..")
                            tables = parent.find_elements(By.TAG_NAME, 'table')
                            
                            if not tables:
                                # å°è¯•åœ¨åç»­å…„å¼Ÿå…ƒç´ ä¸­æŸ¥æ‰¾
                                tables = elem.find_elements(By.XPATH, "./following-sibling::*//table")
                            
                            if not tables:
                                # å°è¯•åœ¨æ•´ä¸ªæ–‡æ¡£ä¸­æŸ¥æ‰¾è¯¥å…ƒç´ ä¹‹åçš„è¡¨æ ¼
                                tables = elem.find_elements(By.XPATH, "./following::table")
                            
                            if tables:
                                table_element = tables[0]
                                product_section = elem
                                print(f"  âœ… åœ¨ '{elem.text.strip()}' ä¸‹æ‰¾åˆ°è¡¨æ ¼")
                                break
                                
                except Exception as e:
                    continue
                    
                if table_element:
                    break
            
            if table_element:
                break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨åŸæ–¹æ³•æŸ¥æ‰¾æœ€å¤§çš„è¡¨æ ¼
        if not table_element:
            print("  âš ï¸ æœªæ‰¾åˆ°äº§å“é€‰æ‹©åŒºåŸŸï¼Œå°è¯•æŸ¥æ‰¾æœ€å¤§çš„è¡¨æ ¼...")
            tables = driver.find_elements(By.TAG_NAME, 'table')
            
            if not tables:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•è¡¨æ ¼")
                return specifications
            
            # é€‰æ‹©æœ€å¤§çš„è¡¨æ ¼
            table_element = max(tables, key=lambda t: len(t.find_elements(By.TAG_NAME, 'tr')))
        
        # åˆ†ææ‰¾åˆ°çš„è¡¨æ ¼
        rows = table_element.find_elements(By.TAG_NAME, 'tr')
        print(f"ğŸ“Š åˆ†æè¡¨æ ¼ï¼Œå…± {len(rows)} è¡Œ")
        
        # æ£€æµ‹è¡¨æ ¼ç±»å‹
        is_vertical_table = False
        
        # æ£€æŸ¥å‰å‡ è¡Œæ˜¯å¦éƒ½æ˜¯2åˆ—æ ¼å¼
        two_col_count = 0
        for i, row in enumerate(rows[:5]):  # æ£€æŸ¥å‰5è¡Œ
            cells = row.find_elements(By.CSS_SELECTOR, 'td, th')
            if len(cells) == 2:
                two_col_count += 1
        
        if two_col_count >= 3:  # å¦‚æœè‡³å°‘3è¡Œéƒ½æ˜¯2åˆ—ï¼Œå¯èƒ½æ˜¯çºµå‘è¡¨æ ¼
            is_vertical_table = True
            print("  ğŸ”„ æ£€æµ‹åˆ°çºµå‘è¡¨æ ¼æ ¼å¼ï¼ˆå±æ€§-å€¼å¯¹ï¼‰")
        
        # æå–æ‰€æœ‰å¯èƒ½çš„äº§å“ç¼–å·
        if is_vertical_table:
            # çºµå‘è¡¨æ ¼ï¼šæå–æ‰€æœ‰å€¼ï¼Œæ£€æŸ¥å“ªäº›å¯èƒ½æ˜¯äº§å“ç¼–å·
            print("  ğŸ” ä»çºµå‘è¡¨æ ¼æå–æ•°æ®...")
            for i, row in enumerate(rows):
                cells = row.find_elements(By.CSS_SELECTOR, 'td, th')
                if len(cells) != 2:
                    continue
                
                prop_name = cells[0].text.strip()
                prop_value = cells[1].text.strip()
                
                # æ˜¾ç¤ºæ‰€æœ‰å±æ€§-å€¼å¯¹
                print(f"    è¡Œ {i+1}: '{prop_name}' => '{prop_value}'")
                
                # æ£€æŸ¥å€¼æ˜¯å¦å¯èƒ½æ˜¯äº§å“ç¼–å·ï¼ˆä½¿ç”¨æ›´æ™ºèƒ½çš„åˆ¤æ–­ï¼‰
                if prop_value and len(prop_value) >= 3 and prop_value not in seen_references:
                    # æ™ºèƒ½åˆ¤æ–­ï¼šå¦‚æœçœ‹èµ·æ¥åƒç¼–å·ï¼ˆåŒ…å«æ•°å­—æˆ–ç‰¹æ®Šæ ¼å¼ï¼‰
                    if is_likely_product_reference(prop_value):
                        spec_info = {
                            'reference': prop_value,
                            'row_index': i,
                            'dimensions': '',
                            'weight': '',
                            'property_name': prop_name,
                            'table_type': 'vertical'
                        }
                        
                        specifications.append(spec_info)
                        seen_references.add(prop_value)
                        print(f"  ğŸ“¦ æå–è§„æ ¼: {prop_value} (æ¥è‡ª: {prop_name})")
        
        else:
            # æ¨ªå‘è¡¨æ ¼
            print("  ğŸ“Š æ£€æµ‹åˆ°æ¨ªå‘è¡¨æ ¼æ ¼å¼")
            
            # æŸ¥æ‰¾è¡¨å¤´è¡Œ
            header_row_index = -1
            header_cells = []
            
            for i, row in enumerate(rows):
                cells = row.find_elements(By.CSS_SELECTOR, 'td, th')
                if not cells:
                    continue
                
                # å¦‚æœæ˜¯thå…ƒç´ ï¼Œå¾ˆå¯èƒ½æ˜¯è¡¨å¤´
                th_cells = row.find_elements(By.TAG_NAME, 'th')
                if th_cells and len(th_cells) == len(cells):
                    header_row_index = i
                    header_cells = [cell.text.strip() for cell in cells]
                    print(f"  ğŸ“‹ è¯†åˆ«è¡¨å¤´è¡Œ {i+1}: {header_cells[:5]}...")
                    break
            
            # ç¡®å®šäº§å“ç¼–å·åˆ—ï¼ˆæ ¹æ®åˆ—åï¼‰
            product_columns = []
            if header_cells:
                for j, header in enumerate(header_cells):
                    header_lower = header.lower()
                    
                    # åŒ¹é…å„ç§è¯­è¨€çš„äº§å“ç¼–å·åˆ—å
                    if any(keyword in header_lower for keyword in [
                        'part number', 'part no', 'part#', 'p/n',
                        'product number', 'product code', 'product id',
                        'model', 'model number', 'model no',
                        'reference', 'ref', 'item number', 'item no',
                        'catalog number', 'cat no', 'sku',
                        'bestellnummer', 'artikelnummer', 'teilenummer',  # å¾·è¯­
                        'numÃ©ro', 'rÃ©fÃ©rence',  # æ³•è¯­
                        'nÃºmero', 'codigo',  # è¥¿ç­ç‰™è¯­
                        'å‹å·', 'ç¼–å·', 'æ–™å·'  # ä¸­æ–‡
                    ]):
                        product_columns.append(j)
                        print(f"    âœ“ è¯†åˆ«äº§å“ç¼–å·åˆ— {j+1}: '{header}'")
                        
                # é€šç”¨ç®€åŒ–é€»è¾‘ï¼šåªä½¿ç”¨ç¬¬ä¸€ä¸ªäº§å“ç¼–å·åˆ—
                if len(product_columns) > 1:
                    print(f"    â„¹ï¸ å‘ç° {len(product_columns)} ä¸ªäº§å“ç¼–å·åˆ—ï¼Œåªä½¿ç”¨ç¬¬ä¸€ä¸ªä¸»è¦åˆ—")
                    product_columns = product_columns[:1]
            
            # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°äº§å“ç¼–å·åˆ—ï¼Œä½¿ç”¨æ™ºèƒ½åˆ¤æ–­
            if not product_columns:
                print("    âš ï¸ æœªè¯†åˆ«åˆ°æ˜ç¡®çš„äº§å“ç¼–å·åˆ—ï¼Œå°†ä½¿ç”¨æ™ºèƒ½åˆ¤æ–­")
                use_smart_detection = True
            else:
                use_smart_detection = False
            
            # æå–æ•°æ®è¡Œ
            for i, row in enumerate(rows):
                if i <= header_row_index:  # è·³è¿‡è¡¨å¤´åŠä¹‹å‰çš„è¡Œ
                    continue
                    
                cells = row.find_elements(By.CSS_SELECTOR, 'td, th')
                if not cells:
                    continue
                
                cell_texts = [cell.text.strip() for cell in cells]
                
                # æŸ¥æ‰¾å¯èƒ½çš„äº§å“ç¼–å·
                if use_smart_detection:
                    # æ™ºèƒ½æ£€æµ‹æ¨¡å¼ï¼šæ‰«ææ‰€æœ‰å•å…ƒæ ¼
                    for j, cell_text in enumerate(cell_texts):
                        if cell_text and len(cell_text) >= 3 and cell_text not in seen_references:
                            if is_likely_product_reference(cell_text):
                                spec_info = {
                                    'reference': cell_text,
                                    'row_index': i,
                                    'column_index': j,
                                    'dimensions': extract_dimensions_from_cells(cell_texts),
                                    'weight': extract_weight_from_cells(cell_texts),
                                    'all_cells': cell_texts,
                                    'table_type': 'horizontal'
                                }
                                
                                # å¦‚æœæœ‰è¡¨å¤´ï¼Œæ·»åŠ åˆ—åä¿¡æ¯
                                if header_cells and j < len(header_cells):
                                    spec_info['column_name'] = header_cells[j]
                                
                                specifications.append(spec_info)
                                seen_references.add(cell_text)
                                
                                if len(specifications) <= 10:
                                    print(f"  ğŸ“¦ æå–è§„æ ¼ {len(specifications)}: {cell_text}")
                                
                                # åœ¨æ™ºèƒ½æ¨¡å¼ä¸‹ï¼Œæ¯è¡Œåªå–ç¬¬ä¸€ä¸ªç¬¦åˆæ¡ä»¶çš„
                                break
                else:
                    # ä½¿ç”¨è¯†åˆ«çš„äº§å“ç¼–å·åˆ—
                    for col_idx in product_columns:
                        if col_idx < len(cell_texts):
                            cell_text = cell_texts[col_idx]
                            if cell_text and len(cell_text) >= 3 and cell_text not in seen_references:
                                # å¯¹äº§å“ç¼–å·åˆ—çš„å†…å®¹ï¼Œæ”¾å®½éªŒè¯
                                if cell_text and not cell_text.lower() in ['', 'n/a', 'na', '-', '/', 'none']:
                                    spec_info = {
                                        'reference': cell_text,
                                        'row_index': i,
                                        'column_index': col_idx,
                                        'dimensions': extract_dimensions_from_cells(cell_texts),
                                        'weight': extract_weight_from_cells(cell_texts),
                                        'all_cells': cell_texts,
                                        'table_type': 'horizontal'
                                    }
                                    
                                    # æ·»åŠ åˆ—åä¿¡æ¯
                                    if header_cells and col_idx < len(header_cells):
                                        spec_info['column_name'] = header_cells[col_idx]
                                    
                                    specifications.append(spec_info)
                                    seen_references.add(cell_text)
                                    
                                    if len(specifications) <= 10:
                                        print(f"  ğŸ“¦ æå–è§„æ ¼ {len(specifications)}: {cell_text}")
        
        if len(specifications) > 10:
            print(f"  ... è¿˜æœ‰ {len(specifications) - 10} ä¸ªè§„æ ¼")
            
    except Exception as e:
        print(f"âŒ æå–è§„æ ¼æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"âœ… æ€»å…±æå–åˆ° {len(specifications)} ä¸ªäº§å“è§„æ ¼")
    return specifications

def is_likely_product_reference(text):
    """æ™ºèƒ½åˆ¤æ–­æ–‡æœ¬æ˜¯å¦å¯èƒ½æ˜¯äº§å“ç¼–å·"""
    if not text or len(text) < 3:
        return False
    
    # æ˜æ˜¾çš„æ’é™¤é¡¹
    exclude_patterns = [
        r'^https?://',  # URL
        r'^www\.',      # ç½‘å€
        r'@',           # é‚®ç®±
        r'^\d{4}-\d{2}-\d{2}',  # æ—¥æœŸæ ¼å¼
        r'^\+?\d{10,}$',  # ç”µè¯å·ç 
    ]
    
    for pattern in exclude_patterns:
        if re.search(pattern, text, re.IGNORECASE):
            return False
    
    # æ’é™¤çº¯æè¿°æ€§æ–‡æœ¬ï¼ˆå…¨æ˜¯å¸¸è§è‹±æ–‡å•è¯ï¼‰
    common_words = [
        'description', 'manufacturer', 'material', 'color', 'size',
        'weight', 'length', 'width', 'height', 'diameter', 'thickness'
    ]
    
    text_lower = text.lower()
    if any(text_lower == word for word in common_words):
        return False
    
    # ç§¯æçš„æŒ‡æ ‡ï¼šåŒ…å«è¿™äº›ç‰¹å¾çš„æ›´å¯èƒ½æ˜¯äº§å“ç¼–å·
    positive_indicators = 0
    
    # 1. åŒ…å«æ•°å­—
    if any(c.isdigit() for c in text):
        positive_indicators += 2
    
    # 2. åŒ…å«è¿å­—ç¬¦æˆ–ä¸‹åˆ’çº¿
    if '-' in text or '_' in text:
        positive_indicators += 1
    
    # 3. åŒ…å«å¤§å†™å­—æ¯ï¼ˆä¸æ˜¯å¥å­å¼€å¤´ï¼‰
    if any(c.isupper() for c in text[1:]):
        positive_indicators += 1
    
    # 4. é•¿åº¦é€‚ä¸­ï¼ˆ3-50ä¸ªå­—ç¬¦ï¼‰
    if 3 <= len(text) <= 50:
        positive_indicators += 1
    
    # 5. ç‰¹æ®Šæ ¼å¼æ¨¡å¼
    special_patterns = [
        r'^\d+-\d+-\d+$',  # 5-14230-00
        r'^[A-Z]+\d+',     # SLS50, DIN787
        r'^\d+[A-Z]+',     # 14W, 230V
        r'^[A-Z0-9]+[-_][A-Z0-9]+',  # QAAMC10A050S
        r'^[A-Z]{2,}\d{2,}',  # DIN787, EN561
    ]
    
    for pattern in special_patterns:
        if re.match(pattern, text):
            positive_indicators += 2
            break
    
    # å¦‚æœç§¯ææŒ‡æ ‡è¶³å¤Ÿå¤šï¼Œè®¤ä¸ºæ˜¯äº§å“ç¼–å·
    return positive_indicators >= 3

def is_valid_product_reference_relaxed(text):
    """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦æ˜¯æœ‰æ•ˆçš„äº§å“ç¼–å· - æ”¾å®½ç‰ˆï¼ˆç”¨äºçºµå‘è¡¨æ ¼ï¼‰"""
    # ç›´æ¥ä½¿ç”¨æ–°çš„æ™ºèƒ½åˆ¤æ–­å‡½æ•°
    return is_likely_product_reference(text)

def is_valid_product_reference(text):
    """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦æ˜¯æœ‰æ•ˆçš„äº§å“ç¼–å· - æ”¹è¿›ç‰ˆ"""
    # ç›´æ¥ä½¿ç”¨æ–°çš„æ™ºèƒ½åˆ¤æ–­å‡½æ•°
    return is_likely_product_reference(text)

def extract_dimensions_from_cells(cells):
    """ä»å•å…ƒæ ¼ä¸­æå–å°ºå¯¸ä¿¡æ¯"""
    for cell_text in cells:
        dimension_match = re.search(r'\d+x\d+x?\d*', cell_text)
        if dimension_match:
            return dimension_match.group()
    return ''

def extract_weight_from_cells(cells):
    """ä»å•å…ƒæ ¼ä¸­æå–é‡é‡æˆ–é•¿åº¦ä¿¡æ¯"""
    for cell_text in cells:
        measure_match = re.search(r'(\d+[,\.]\d+|\d+)\s*(mm|kg|m|cm)', cell_text.lower())
        if measure_match:
            return measure_match.group()
    return ''

def extract_base_product_info(product_url):
    """ä»äº§å“URLä¸­æå–åŸºç¡€ä¿¡æ¯"""
    try:
        parsed_url = urlparse(product_url)
        path_parts = parsed_url.path.split('/')
        
        # è·å–åŸºç¡€äº§å“åç§°
        base_product_name = path_parts[-1] if path_parts else "unknown-product"
        
        # è§£ææŸ¥è¯¢å‚æ•°
        query_params = parse_qs(parsed_url.query)
        product_id = query_params.get('Product', ['unknown-id'])[0]
        catalog_path = query_params.get('CatalogPath', ['unknown-catalog'])[0] if 'CatalogPath' in query_params else 'unknown-catalog'
        
        return {
            'base_url': f"{parsed_url.scheme}://{parsed_url.netloc}",
            'base_path': parsed_url.path,
            'base_product_name': base_product_name,
            'product_id': product_id,
            'catalog_path': catalog_path,
            'query_params': query_params
        }
    except Exception as e:
        print(f"âš ï¸ è§£æäº§å“URLå¤±è´¥: {e}")
        return None

def generate_specification_urls(base_info, specifications):
    """æ ¹æ®åŸºç¡€ä¿¡æ¯å’Œè§„æ ¼ç”Ÿæˆç‰¹å®šçš„äº§å“URL"""
    print("ğŸ”— ç”Ÿæˆè§„æ ¼ä¸“ç”¨é“¾æ¥...")
    
    if not base_info:
        print("âŒ ç¼ºå°‘åŸºç¡€äº§å“ä¿¡æ¯")
        return []
    
    spec_urls = []
    
    for spec in specifications:
        try:
            reference = spec.get('reference', '')
            if not reference:
                continue
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            query_params = base_info['query_params'].copy()
            query_params['PartNumber'] = [reference]
            
            # é‡æ–°ç¼–ç æŸ¥è¯¢å­—ç¬¦ä¸²
            query_string = urlencode(query_params, doseq=True)
            
            # æ„å»ºå®Œæ•´URL
            spec_url = f"{base_info['base_url']}{base_info['base_path']}?{query_string}"
            
            spec_url_info = {
                'reference': reference,
                'dimensions': spec.get('dimensions', ''),
                'weight': spec.get('weight', ''),
                'url': spec_url,
                'original_spec_data': spec
            }
            
            spec_urls.append(spec_url_info)
            
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆè§„æ ¼URLæ—¶å‡ºé”™ ({reference}): {e}")
    
    print(f"  âœ… æˆåŠŸç”Ÿæˆ {len(spec_urls)} ä¸ªè§„æ ¼é“¾æ¥")
    return spec_urls

def save_results(base_info, specifications, spec_urls):
    """ä¿å­˜æå–ç»“æœ"""
    timestamp = int(time.time())
    
    # ğŸ¯ æ”¹è¿›çš„JSONæ ¼å¼
    results = {
        'extraction_info': {
            'timestamp': timestamp,
            'extraction_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'base_product_url': PRODUCT_URL,
            'total_specifications_found': len(specifications),
            'total_urls_generated': len(spec_urls)
        },
        'base_product_info': base_info,
        'product_specifications': specifications,
        'specification_urls': spec_urls,
        'summary': {
            'series_distribution': {},
            'specification_samples': []
        }
    }
    
    # åˆ†æäº§å“ç³»åˆ—åˆ†å¸ƒ
    series_stats = {}
    for spec in specifications:
        ref = spec.get('reference', '')
        if ref:
            # å°è¯•æå–äº§å“ç³»åˆ—ï¼Œé€‚é…ä¸åŒæ ¼å¼
            series_patterns = [
                r'(TXCE-[A-Z0-9]+-[0-9]+-[0-9]+)',  # TXCEç³»åˆ—
                r'([A-Z]{2,4}-[0-9]+)',              # EN-561ç±»å‹
                r'([A-Z]+[0-9]+)',                   # ç®€å•å­—æ¯æ•°å­—ç»„åˆ
                r'([A-Z]+-[A-Z0-9]+)'               # é€šç”¨æ ¼å¼
            ]
            
            series = ref  # é»˜è®¤ä½¿ç”¨å®Œæ•´ç¼–å·
            for pattern in series_patterns:
                match = re.match(pattern, ref)
                if match:
                    series = match.group(1)
                    break
            
            if series not in series_stats:
                series_stats[series] = 0
            series_stats[series] += 1
    
    results['summary']['series_distribution'] = series_stats
    
    # æ·»åŠ è§„æ ¼æ ·æœ¬ï¼ˆå‰10ä¸ªï¼‰
    for i, spec in enumerate(specifications[:10]):
        sample = {
            'index': i + 1,
            'reference': spec.get('reference', ''),
            'dimensions': spec.get('dimensions', ''),
            'weight': spec.get('weight', ''),
            'url': spec_urls[i]['url'] if i < len(spec_urls) else ''
        }
        results['summary']['specification_samples'].append(sample)
    
    # ğŸ¯ è·å–å½“å‰å·¥ä½œç›®å½•ï¼Œç”Ÿæˆå®Œæ•´è·¯å¾„
    import os
    current_dir = os.getcwd()
    
    # ä¿å­˜è¯¦ç»†JSONç»“æœ
    json_file = RESULTS_DIR / f"product_specs_complete_{timestamp}.json"
    json_full_path = os.path.join(current_dir, json_file)
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    print(f"ğŸ’¾ å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {json_full_path}")
    
    # ä¿å­˜ç®€åŒ–çš„è§„æ ¼åˆ—è¡¨JSON
    simple_specs = []
    for i, spec in enumerate(specifications):
        simple_spec = {
            'id': i + 1,
            'reference': spec.get('reference', ''),
            'dimensions': spec.get('dimensions', ''),
            'weight': spec.get('weight', ''),
            'series': '',
            'url': spec_urls[i]['url'] if i < len(spec_urls) else ''
        }
        
        # æå–ç³»åˆ—ä¿¡æ¯ï¼Œé€‚é…ä¸åŒæ ¼å¼
        ref = spec.get('reference', '')
        if ref:
            for pattern in [
                r'(TXCE-[A-Z0-9]+-[0-9]+-[0-9]+)',
                r'([A-Z]{2,4}-[0-9]+)',
                r'([A-Z]+[0-9]+)',
                r'([A-Z]+-[A-Z0-9]+)'
            ]:
                match = re.match(pattern, ref)
                if match:
                    simple_spec['series'] = match.group(1)
                    break
            if not simple_spec['series']:
                simple_spec['series'] = ref
        
        simple_specs.append(simple_spec)
    
    simple_json_file = RESULTS_DIR / f"specs_list_{timestamp}.json"
    simple_json_full_path = os.path.join(current_dir, simple_json_file)
    with open(simple_json_file, 'w', encoding='utf-8') as f:
        json.dump({
            'extraction_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'total_count': len(simple_specs),
            'specifications': simple_specs
        }, f, indent=2, ensure_ascii=False)
    print(f"ğŸ“‹ ç®€åŒ–è§„æ ¼åˆ—è¡¨å·²ä¿å­˜åˆ°: {simple_json_full_path}")
    
    # ä¿å­˜ç®€åŒ–çš„URLåˆ—è¡¨
    urls_file = RESULTS_DIR / f"spec_urls_{timestamp}.txt"
    urls_full_path = os.path.join(current_dir, urls_file)
    with open(urls_file, 'w', encoding='utf-8') as f:
        f.write(f"# äº§å“è§„æ ¼é“¾æ¥åˆ—è¡¨\n")
        f.write(f"# åŸºç¡€äº§å“: {PRODUCT_URL}\n")
        f.write(f"# ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"# æ‰¾åˆ° {len(spec_urls)} ä¸ªè§„æ ¼\n\n")
        
        for spec_url_info in spec_urls:
            f.write(f"# {spec_url_info['reference']} ({spec_url_info['dimensions']})\n")
            f.write(f"{spec_url_info['url']}\n\n")
    
    print(f"ğŸ“„ URLåˆ—è¡¨å·²ä¿å­˜åˆ°: {urls_full_path}")
    
    # è¾“å‡ºç»“æœæ‘˜è¦
    print("\n" + "="*80)
    print("ğŸ“‹ æå–ç»“æœæ‘˜è¦")
    print("="*80)
    print(f"åŸºç¡€äº§å“URL: {PRODUCT_URL}")
    print(f"æ‰¾åˆ°è§„æ ¼æ•°é‡: {len(specifications)}")
    print(f"ç”Ÿæˆé“¾æ¥æ•°é‡: {len(spec_urls)}")
    
    if series_stats:
        print(f"\nğŸ“Š äº§å“ç³»åˆ—åˆ†å¸ƒ:")
        for series, count in sorted(series_stats.items()):
            print(f"  {series}: {count} ä¸ªè§„æ ¼")
    
    print("\nğŸ”— è§„æ ¼é“¾æ¥åˆ—è¡¨ (æ˜¾ç¤ºå‰10ä¸ª):")
    for i, spec_url_info in enumerate(spec_urls[:10], 1):
        print(f"{i:2d}. {spec_url_info['reference']} ({spec_url_info['dimensions']})")
        print(f"    {spec_url_info['url']}")
    if len(spec_urls) > 10:
        print(f"... è¿˜æœ‰ {len(spec_urls) - 10} ä¸ªé“¾æ¥")
    
    print(f"\nğŸ’¾ ç”Ÿæˆæ–‡ä»¶å®Œæ•´è·¯å¾„:")
    print(f"  ğŸ“‹ å®Œæ•´JSON: {json_full_path}")
    print(f"  ğŸ“‹ ç®€åŒ–JSON: {simple_json_full_path}")
    print(f"  ğŸ“„ URLåˆ—è¡¨: {urls_full_path}")
    print("="*80)

def main():
    print("ğŸ¯ äº§å“è§„æ ¼é“¾æ¥æå–å™¨ (é‡æ–°è®¾è®¡ç‰ˆ)")
    print(f"ğŸ“ ç›®æ ‡äº§å“: {PRODUCT_URL}")
    print("ğŸ”„ ç­–ç•¥: ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®ï¼Œæ— ç¿»é¡µ")
    
    if not SELENIUM_AVAILABLE:
        print("âŒ Selenium æœªå®‰è£…ï¼Œæ— æ³•è¿è¡Œï¼")
        return False
    
    # æå–åŸºç¡€äº§å“ä¿¡æ¯
    base_info = extract_base_product_info(PRODUCT_URL)
    if not base_info:
        print("âŒ æ— æ³•è§£æåŸºç¡€äº§å“ä¿¡æ¯")
        return False
    
    print(f"ğŸ“¦ äº§å“ID: {base_info['product_id']}")
    
    driver = prepare_driver()
    
    try:
        # è®¿é—®äº§å“é¡µé¢
        print(f"ğŸŒ è®¿é—®äº§å“é¡µé¢...")
        driver.get(PRODUCT_URL)
        time.sleep(3)
        
        # æˆªå›¾ä¿å­˜åˆå§‹çŠ¶æ€
        screenshot_path = RESULTS_DIR / f"initial_page_{int(time.time())}.png"
        driver.save_screenshot(str(screenshot_path))
        print(f"ğŸ“¸ åˆå§‹é¡µé¢æˆªå›¾: {screenshot_path}")
        
        # å°è¯•è®¾ç½®æ¯é¡µæ˜¾ç¤ºä¸ºå…¨éƒ¨
        items_per_page_success = set_items_per_page_to_all(driver)
        
        if items_per_page_success:
            print("âœ… æˆåŠŸè®¾ç½®æ˜¾ç¤ºå…¨éƒ¨é¡¹ç›®")
            # å†æ¬¡æˆªå›¾ç¡®è®¤
            final_screenshot = RESULTS_DIR / f"after_show_all_{int(time.time())}.png"
            driver.save_screenshot(str(final_screenshot))
            print(f"ğŸ“¸ è®¾ç½®åæˆªå›¾: {final_screenshot}")
        else:
            print("â„¹ï¸ å•é¡µé¢æ¨¡å¼ï¼šç›´æ¥æå–å½“å‰é¡µé¢æ•°æ®")
        
        # ç¡®ä¿é¡µé¢å®Œå…¨åŠ è½½
        scroll_page_fully(driver)
        
        # æå–æ‰€æœ‰è§„æ ¼ä¿¡æ¯
        specifications = extract_all_product_specifications(driver)
        
        if not specifications:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•äº§å“è§„æ ¼")
            return False
        
        # ç”Ÿæˆè§„æ ¼URL
        spec_urls = generate_specification_urls(base_info, specifications)
        
        if not spec_urls:
            print("âŒ æœªèƒ½ç”Ÿæˆä»»ä½•è§„æ ¼URL")
            return False
        
        # ä¿å­˜ç»“æœ
        save_results(base_info, specifications, spec_urls)
        
        print("âœ… è§„æ ¼é“¾æ¥æå–å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æå–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False
    finally:
        driver.quit()

if __name__ == '__main__':
    success = main()
    print("âœ… test-09-1 æˆåŠŸ" if success else "âŒ test-09-1 å¤±è´¥") 