#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯• 09-1 â€”â€” äº§å“è§„æ ¼é“¾æ¥æå–å™¨ (é‡æ–°è®¾è®¡ç‰ˆ)
ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰äº§å“è§„æ ¼ï¼Œæ— éœ€ç¿»é¡µ
è¿è¡Œ: make test-09-1
"""
import os, sys, time, re, json
from pathlib import Path
from urllib.parse import urlparse, parse_qs, urlencode

# Selenium imports
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait, Select
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, NoSuchElementException
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False
    print("âŒ Selenium æœªå®‰è£…ï¼Œæ— æ³•è¿è¡Œæµ‹è¯•ï¼")
    sys.exit(1)

RESULTS_DIR = Path("results/product_specifications")
RESULTS_DIR.mkdir(parents=True, exist_ok=True)

# é»˜è®¤äº§å“URLï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
DEFAULT_PRODUCT_URL = "https://www.traceparts.cn/en/product/jlcmc-aluminum-extrusion-txceh161515l100dalka75?Product=90-27122024-029219"
PRODUCT_URL = os.getenv("TRACEPARTS_PRODUCT_URL", DEFAULT_PRODUCT_URL)

def prepare_driver():
    """å‡†å¤‡Chromeé©±åŠ¨å™¨"""
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')
    options.add_argument('--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
    
    driver = webdriver.Chrome(options=options)
    driver.set_page_load_timeout(40)
    return driver

def scroll_page_fully(driver):
    """å®Œæ•´æ»šåŠ¨é¡µé¢ç¡®ä¿æ‰€æœ‰å†…å®¹åŠ è½½"""
    print("ğŸ”„ æ»šåŠ¨é¡µé¢ç¡®ä¿å†…å®¹å®Œå…¨åŠ è½½...")
    
    # å…ˆæ»šåŠ¨åˆ°åº•éƒ¨
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(2)
    
    # å†æ»šåŠ¨åˆ°é¡¶éƒ¨
    driver.execute_script("window.scrollTo(0, 0);")
    time.sleep(1)
    
    # æœ€åæ»šåŠ¨åˆ°é¡µé¢ä¸­éƒ¨
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight/2);")
    time.sleep(1)

def set_items_per_page_to_all(driver):
    """è®¾ç½®æ¯é¡µæ˜¾ç¤ºé¡¹ç›®æ•°ä¸ºå…¨éƒ¨"""
    print("ğŸ¯ å°è¯•è®¾ç½®æ¯é¡µæ˜¾ç¤ºé¡¹ç›®æ•°ä¸ºå…¨éƒ¨...")
    
    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨åˆ†é¡µæ§ä»¶
    try:
        # æŸ¥æ‰¾æ˜¯å¦æœ‰"Items per page"ç›¸å…³æ–‡æœ¬
        pagination_indicators = [
            "//*[contains(text(), 'Items per page')]",
            "//*[contains(text(), 'items per page')]", 
            "//*[contains(text(), 'out of') and contains(text(), 'items')]",
            "//*[contains(text(), 'Show') and contains(text(), 'entries')]"
        ]
        
        has_pagination = False
        for selector in pagination_indicators:
            try:
                elements = driver.find_elements(By.XPATH, selector)
                if elements and any(elem.is_displayed() for elem in elements):
                    has_pagination = True
                    print(f"  âœ… æ£€æµ‹åˆ°åˆ†é¡µæ§ä»¶: {elements[0].text.strip()[:50]}...")
                    break
            except:
                continue
        
        if not has_pagination:
            print("  â„¹ï¸ æœªæ£€æµ‹åˆ°åˆ†é¡µæ§ä»¶ï¼Œå¯èƒ½æ˜¯å•é¡µé¢ï¼Œç›´æ¥æå–æ•°æ®")
            return False  # è¿”å›Falseè¡¨ç¤ºæ²¡æœ‰åˆ†é¡µï¼Œä½†è¿™æ˜¯æ­£å¸¸æƒ…å†µ
            
    except Exception as e:
        print(f"  âš ï¸ æ£€æµ‹åˆ†é¡µæ§ä»¶æ—¶å‡ºé”™: {e}")
        return False
    
    # ç­–ç•¥1: å¯»æ‰¾åˆ†é¡µåŒºåŸŸä¸­çš„æ•°å­—å’Œä¸‹æ‹‰æ§ä»¶
    try:
        print("  ğŸ” ç­–ç•¥1: æŸ¥æ‰¾åˆ†é¡µåŒºåŸŸçš„æ§ä»¶...")
        
        # å…ˆæŸ¥æ‰¾åŒ…å«"Items per page"çš„åˆ†é¡µå®¹å™¨
        pagination_selectors = [
            "//*[contains(text(), 'Items per page')]",
            "//*[contains(text(), 'items per page')]",
            "//*[contains(text(), 'per page')]",
            "//*[contains(text(), 'out of') and contains(text(), 'items')]"
        ]
        
        pagination_container = None
        for selector in pagination_selectors:
            try:
                elements = driver.find_elements(By.XPATH, selector)
                if elements:
                    # è·å–åŒ…å«åˆ†é¡µä¿¡æ¯çš„æœ€å¤–å±‚å®¹å™¨
                    for elem in elements:
                        # æŸ¥æ‰¾çˆ¶å®¹å™¨
                        for level in range(1, 4):  # å‘ä¸ŠæŸ¥æ‰¾3å±‚
                            try:
                                container = elem.find_element(By.XPATH, f"./ancestor::*[{level}]")
                                container_text = container.text.lower()
                                if 'items per page' in container_text or 'out of' in container_text:
                                    pagination_container = container
                                    print(f"    æ‰¾åˆ°åˆ†é¡µå®¹å™¨ï¼Œæ–‡æœ¬: {container.text[:100]}...")
                                    break
                            except:
                                continue
                        if pagination_container:
                            break
                if pagination_container:
                    break
            except:
                continue
        
        if pagination_container:
            # åœ¨åˆ†é¡µå®¹å™¨ä¸­æŸ¥æ‰¾æ‰€æœ‰å¯ç‚¹å‡»çš„æ•°å­—
            print("    åœ¨åˆ†é¡µå®¹å™¨ä¸­æŸ¥æ‰¾å¯ç‚¹å‡»æ•°å­—...")
            clickable_selectors = [
                ".//select",
                ".//button[text()]",
                ".//a[text()]", 
                ".//*[@role='button']",
                ".//*[contains(@class,'select')]",
                ".//*[contains(@class,'dropdown')]",
                ".//*[contains(@onclick,'')]",
                ".//*[text()='10']",
                ".//*[text()='25']",
                ".//*[text()='50']"
            ]
            
            for selector in clickable_selectors:
                try:
                    elements = pagination_container.find_elements(By.XPATH, selector)
                    for elem in elements:
                        elem_text = elem.text.strip()
                        elem_tag = elem.tag_name
                        
                        print(f"      æ‰¾åˆ°å¯ç‚¹å‡»å…ƒç´ : {elem_tag} '{elem_text}'")
                        
                        # å¦‚æœæ˜¯selectï¼Œæ£€æŸ¥é€‰é¡¹
                        if elem_tag == 'select':
                            options = elem.find_elements(By.TAG_NAME, 'option')
                            option_texts = [opt.text.strip() for opt in options]
                            print(f"        é€‰é¡¹: {option_texts}")
                            
                            # æŸ¥æ‰¾Allæˆ–å¤§æ•°å­—é€‰é¡¹
                            for opt in options:
                                text = opt.text.strip().lower()
                                if text in ['all', 'å…¨éƒ¨'] or (text.isdigit() and int(text) >= 50):
                                    print(f"        âœ… é€‰æ‹©: {opt.text}")
                                    driver.execute_script("arguments[0].scrollIntoView({block:'center'});", opt)
                                    time.sleep(1)
                                    opt.click()
                                    time.sleep(5)
                                    return True
                        
                        # å¦‚æœæ˜¯æ•°å­—æ–‡æœ¬ä¸”å¯ç‚¹å‡»ï¼Œå°è¯•ç‚¹å‡»
                        elif elem.is_displayed() and elem.is_enabled():
                            if elem_text.isdigit() or elem_text.lower() in ['all', 'å…¨éƒ¨']:
                                try:
                                    print(f"        ğŸ–±ï¸ å°è¯•ç‚¹å‡»: {elem_text}")
                                    driver.execute_script("arguments[0].scrollIntoView({block:'center'});", elem)
                                    time.sleep(1)
                                    elem.click()
                                    time.sleep(3)
                                    
                                    # ğŸ¯ å…³é”®æ”¹è¿›ï¼šæ˜ç¡®æŸ¥æ‰¾å¹¶ç‚¹å‡»"All"é€‰é¡¹
                                    print(f"        ğŸ” æŸ¥æ‰¾å¼¹å‡ºèœå•ä¸­çš„Allé€‰é¡¹...")
                                    all_found = False
                                    
                                    # æ›´å…¨é¢çš„Allé€‰é¡¹æŸ¥æ‰¾
                                    all_selectors = [
                                        "//li[normalize-space(.)='All']",
                                        "//div[normalize-space(.)='All']",
                                        "//option[normalize-space(.)='All']",
                                        "//span[normalize-space(.)='All']",
                                        "//button[normalize-space(.)='All']",
                                        "//a[normalize-space(.)='All']",
                                        "//*[@role='option'][normalize-space(.)='All']",
                                        "//*[contains(@class,'option')][normalize-space(.)='All']",
                                        "//*[contains(@class,'menu-item')][normalize-space(.)='All']",
                                        "//li[text()='All']",
                                        "//li[normalize-space(.)='å…¨éƒ¨']"
                                    ]
                                    
                                    for all_sel in all_selectors:
                                        try:
                                            all_options = driver.find_elements(By.XPATH, all_sel)
                                            for all_option in all_options:
                                                if all_option.is_displayed() and all_option.is_enabled():
                                                    print(f"        âœ… æ‰¾åˆ°Allé€‰é¡¹: {all_option.text} ({all_option.tag_name})")
                                                    all_option.click()
                                                    print(f"        âœ… æˆåŠŸé€‰æ‹©Allé€‰é¡¹ï¼")
                                                    time.sleep(5)
                                                    all_found = True
                                                    return True
                                        except Exception as e:
                                            continue
                                    
                                    if not all_found:
                                        # å¦‚æœæ²¡æ‰¾åˆ°Allï¼Œå°è¯•æ‰¾æœ€å¤§æ•°å­—
                                        print(f"        ğŸ” æœªæ‰¾åˆ°Allï¼ŒæŸ¥æ‰¾æœ€å¤§æ•°å­—é€‰é¡¹...")
                                        max_selectors = [
                                            "//li[text()='100']",
                                            "//li[text()='50']", 
                                            "//li[text()='25']",
                                            "//option[text()='100']",
                                            "//option[text()='50']"
                                        ]
                                        
                                        for max_sel in max_selectors:
                                            try:
                                                max_options = driver.find_elements(By.XPATH, max_sel)
                                                for max_option in max_options:
                                                    if max_option.is_displayed():
                                                        print(f"        âœ… é€‰æ‹©æœ€å¤§æ•°å­—: {max_option.text}")
                                                        max_option.click()
                                                        time.sleep(5)
                                                        return True
                                            except:
                                                continue
                                        
                                        print(f"        âš ï¸ ç‚¹å‡»åæœªæ‰¾åˆ°åˆé€‚çš„é€‰é¡¹")
                                    
                                except Exception as e:
                                    print(f"        âŒ ç‚¹å‡»å¤±è´¥: {e}")
                                    
                except Exception as e:
                    print(f"      æŸ¥æ‰¾å…ƒç´ å¤±è´¥: {e}")
                    
    except Exception as e:
        print(f"  âŒ ç­–ç•¥1å¤±è´¥: {e}")
    
    # ç­–ç•¥2: æ›´ç›´æ¥çš„æŸ¥æ‰¾æ–¹å¼ - æŸ¥æ‰¾åŒ…å«å½“å‰é¡µæ•°"10"çš„å¯ç‚¹å‡»å…ƒç´ 
    try:
        print("  ğŸ” ç­–ç•¥2: æŸ¥æ‰¾å½“å‰é¡µæ•°æ§ä»¶...")
        
        # æŸ¥æ‰¾æ˜¾ç¤º"10"çš„å¯ç‚¹å‡»å…ƒç´  (å½“å‰æ¯é¡µæ˜¾ç¤ºæ•°é‡)
        number_selectors = [
            "//select[option[text()='10']]",
            "//*[text()='10' and (@onclick or @role='button' or contains(@class,'select') or contains(@class,'dropdown'))]",
            "//button[text()='10']",
            "//a[text()='10']",
            "//*[@data-value='10']",
            "//*[contains(@class,'pagesize') or contains(@class,'page-size')]"
        ]
        
        for selector in number_selectors:
            try:
                elements = driver.find_elements(By.XPATH, selector)
                for elem in elements:
                    if elem.is_displayed():
                        elem_tag = elem.tag_name
                        elem_text = elem.text.strip()
                        elem_class = elem.get_attribute('class') or ''
                        
                        print(f"    æ‰¾åˆ°æ•°å­—æ§ä»¶: {elem_tag} '{elem_text}' class='{elem_class}'")
                        
                        if elem_tag == 'select':
                            # å¦‚æœæ˜¯selectï¼ŒæŸ¥æ‰¾Allé€‰é¡¹
                            options = elem.find_elements(By.TAG_NAME, 'option')
                            for opt in options:
                                if opt.text.strip().lower() in ['all', 'å…¨éƒ¨'] or (opt.text.strip().isdigit() and int(opt.text.strip()) >= 50):
                                    print(f"    âœ… åœ¨selectä¸­é€‰æ‹©: {opt.text}")
                                    opt.click()
                                    time.sleep(5)
                                    return True
                        else:
                            # å¦‚æœæ˜¯å¯ç‚¹å‡»å…ƒç´ ï¼Œå°è¯•ç‚¹å‡»
                            try:
                                print(f"    ğŸ–±ï¸ ç‚¹å‡»æ•°å­—æ§ä»¶: {elem_text}")
                                driver.execute_script("arguments[0].scrollIntoView({block:'center'});", elem)
                                time.sleep(1)
                                elem.click()
                                time.sleep(3)
                                
                                # æŸ¥æ‰¾å¼¹å‡ºèœå•ä¸­çš„Allé€‰é¡¹
                                all_options = driver.find_elements(By.XPATH, "//li[normalize-space(.)='All'] | //option[normalize-space(.)='All'] | //*[@role='option'][normalize-space(.)='All']")
                                for opt in all_options:
                                    if opt.is_displayed():
                                        opt.click()
                                        print(f"    âœ… é€‰æ‹©äº†Allé€‰é¡¹")
                                        time.sleep(5)
                                        return True
                                        
                            except Exception as e:
                                print(f"    âŒ ç‚¹å‡»æ•°å­—æ§ä»¶å¤±è´¥: {e}")
                                
            except Exception as e:
                print(f"    æŸ¥æ‰¾æ•°å­—æ§ä»¶å¤±è´¥: {e}")
                
    except Exception as e:
        print(f"  âŒ ç­–ç•¥2å¤±è´¥: {e}")
    
    # ç­–ç•¥3: æŸ¥æ‰¾æ‰€æœ‰selectå…ƒç´ ï¼Œä¸“é—¨å¯»æ‰¾åŒ…å«æ•°å­—é€‰é¡¹çš„
    try:
        print("  ğŸ” ç­–ç•¥3: æ£€æŸ¥æ‰€æœ‰selectå…ƒç´ ...")
        
        select_elements = driver.find_elements(By.TAG_NAME, 'select')
        print(f"    é¡µé¢å…±æœ‰ {len(select_elements)} ä¸ªselectå…ƒç´ ")
        
        for i, select_elem in enumerate(select_elements):
            try:
                if not select_elem.is_displayed():
                    continue
                    
                options = select_elem.find_elements(By.TAG_NAME, 'option')
                option_data = []
                has_numbers = False
                
                for opt in options:
                    text = opt.text.strip()
                    value = opt.get_attribute('value')
                    option_data.append(f"{text}({value})")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ•°å­—é€‰é¡¹ï¼ˆåˆ†é¡µç›¸å…³ï¼‰
                    if text.isdigit() and int(text) <= 100:
                        has_numbers = True
                
                print(f"    Select {i+1}: åŒ…å«æ•°å­—={has_numbers}")
                if len(option_data) <= 10:  # åªæ˜¾ç¤ºé€‰é¡¹å°‘çš„select
                    print(f"      é€‰é¡¹: {option_data}")
                
                # å¦‚æœåŒ…å«æ•°å­—é€‰é¡¹ï¼Œå¯èƒ½æ˜¯åˆ†é¡µæ§ä»¶
                if has_numbers:
                    print(f"    ğŸ¯ è¿™å¯èƒ½æ˜¯åˆ†é¡µæ§ä»¶ï¼Œå°è¯•é€‰æ‹©æœ€å¤§å€¼...")
                    
                    # æŸ¥æ‰¾Allæˆ–æœ€å¤§æ•°å­—
                    best_option = None
                    for opt in options:
                        text = opt.text.strip().lower()
                        if text in ['all', 'å…¨éƒ¨']:
                            best_option = opt
                            break
                        elif text.isdigit() and int(text) >= 50:
                            best_option = opt
                    
                    if best_option:
                        print(f"      âœ… é€‰æ‹©: {best_option.text}")
                        driver.execute_script("arguments[0].scrollIntoView({block:'center'});", best_option)
                        time.sleep(1)
                        best_option.click()
                        time.sleep(5)
                        return True
                        
            except Exception as e:
                print(f"    å¤„ç†select {i+1}å¤±è´¥: {e}")
                
    except Exception as e:
        print(f"  âŒ ç­–ç•¥3å¤±è´¥: {e}")
    
    print("  âŒ æ‰€æœ‰ç­–ç•¥éƒ½æœªèƒ½æ‰¾åˆ°å¯ç”¨çš„åˆ†é¡µæ§ä»¶")
    return False

def extract_all_product_specifications(driver):
    """ä¸€æ¬¡æ€§æå–æ‰€æœ‰äº§å“è§„æ ¼"""
    print("ğŸ“‹ å¼€å§‹æå–æ‰€æœ‰äº§å“è§„æ ¼...")
    
    specifications = []
    seen_references = set()
    
    try:
        # ç­‰å¾…é¡µé¢ç¨³å®š
        time.sleep(3)
        
        # å®Œæ•´æ»šåŠ¨é¡µé¢
        scroll_page_fully(driver)
        
        # æŸ¥æ‰¾è¡¨æ ¼
        print("ğŸ” æŸ¥æ‰¾äº§å“è§„æ ¼è¡¨æ ¼...")
        tables = driver.find_elements(By.TAG_NAME, 'table')
        
        if not tables:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•è¡¨æ ¼")
            return specifications
        
        # é€‰æ‹©æœ€å¤§çš„è¡¨æ ¼
        best_table = max(tables, key=lambda t: len(t.find_elements(By.TAG_NAME, 'tr')))
        rows = best_table.find_elements(By.TAG_NAME, 'tr')
        
        print(f"ğŸ“Š æ‰¾åˆ°æœ€ä½³è¡¨æ ¼ï¼Œå…± {len(rows)} è¡Œ")
        
        # åˆ†æè¡¨æ ¼ç»“æ„
        header_row = None
        data_rows = []
        
        for i, row in enumerate(rows):
            cells = row.find_elements(By.CSS_SELECTOR, 'td, th')
            if not cells:
                continue
                
            cell_texts = [cell.text.strip() for cell in cells]
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºè¡¨å¤´è¡Œ
            is_header = any(keyword in ' '.join(cell_texts).lower() for keyword in [
                'part number', 'product', 'reference', 'model', 'specification'
            ])
            
            if is_header and header_row is None:
                header_row = i
                print(f"  ğŸ“‹ è¯†åˆ«è¡¨å¤´è¡Œ {i+1}: {cell_texts[:3]}...")
            elif not is_header and len(cell_texts) > 1:
                data_rows.append({'index': i, 'cells': cell_texts})
        
        print(f"  ğŸ“Š è¯†åˆ«å‡º {len(data_rows)} è¡Œæ•°æ®")
        
        # æå–äº§å“è§„æ ¼
        for row_info in data_rows:
            row_index = row_info['index']
            cells = row_info['cells']
            
            # æŸ¥æ‰¾äº§å“ç¼–å·
            found_reference = None
            for cell_text in cells:
                if is_valid_product_reference(cell_text) and cell_text not in seen_references:
                    found_reference = cell_text
                    break
            
            if found_reference:
                spec_info = {
                    'reference': found_reference,
                    'row_index': row_index,
                    'dimensions': extract_dimensions_from_cells(cells),
                    'weight': extract_weight_from_cells(cells),
                    'all_cells': cells
                }
                
                specifications.append(spec_info)
                seen_references.add(found_reference)
                
                if len(specifications) <= 10:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    print(f"  ğŸ“¦ è§„æ ¼ {len(specifications)}: {found_reference} ({spec_info['dimensions']})")
        
        if len(specifications) > 10:
            print(f"  ... è¿˜æœ‰ {len(specifications) - 10} ä¸ªè§„æ ¼")
            
    except Exception as e:
        print(f"âŒ æå–è§„æ ¼æ—¶å‡ºé”™: {e}")
    
    print(f"âœ… æ€»å…±æå–åˆ° {len(specifications)} ä¸ªäº§å“è§„æ ¼")
    return specifications

def is_valid_product_reference(text):
    """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦æ˜¯æœ‰æ•ˆçš„äº§å“ç¼–å·"""
    if not text or len(text) < 5:
        return False
    
    # æ’é™¤æ˜æ˜¾çš„äº§å“æè¿°
    if any(desc_word in text.lower() for desc_word in [
        'aluminum', 'extrusion', 'description', 'purchasing', 'links', 
        'manufacturer', 'jlcmc', 'product page'
    ]):
        return False
    
    # å¿…é¡»åŒ…å«TXCE-å¼€å¤´çš„äº§å“ç¼–å·æ¨¡å¼
    if not re.search(r'^TXCE-[A-Z0-9]+-[0-9]+-[0-9]+-L[0-9]', text):
        return False
    
    # è¿›ä¸€æ­¥éªŒè¯ï¼šå¿…é¡»æœ‰å­—æ¯å’Œæ•°å­—
    if not (any(char.isalpha() for char in text) and any(char.isdigit() for char in text)):
        return False
    
    # æ’é™¤è¿‡é•¿çš„æ–‡æœ¬ï¼ˆå¯èƒ½æ˜¯æè¿°ï¼‰
    if len(text) > 50:
        return False
        
    return True

def extract_dimensions_from_cells(cells):
    """ä»å•å…ƒæ ¼ä¸­æå–å°ºå¯¸ä¿¡æ¯"""
    for cell_text in cells:
        dimension_match = re.search(r'\d+x\d+x?\d*', cell_text)
        if dimension_match:
            return dimension_match.group()
    return ''

def extract_weight_from_cells(cells):
    """ä»å•å…ƒæ ¼ä¸­æå–é‡é‡æˆ–é•¿åº¦ä¿¡æ¯"""
    for cell_text in cells:
        measure_match = re.search(r'(\d+[,\.]\d+|\d+)\s*(mm|kg|m|cm)', cell_text.lower())
        if measure_match:
            return measure_match.group()
    return ''

def extract_base_product_info(product_url):
    """ä»äº§å“URLä¸­æå–åŸºç¡€ä¿¡æ¯"""
    try:
        parsed_url = urlparse(product_url)
        path_parts = parsed_url.path.split('/')
        
        # è·å–åŸºç¡€äº§å“åç§°
        base_product_name = path_parts[-1] if path_parts else "unknown-product"
        
        # è§£ææŸ¥è¯¢å‚æ•°
        query_params = parse_qs(parsed_url.query)
        product_id = query_params.get('Product', ['unknown-id'])[0]
        catalog_path = query_params.get('CatalogPath', ['unknown-catalog'])[0] if 'CatalogPath' in query_params else 'unknown-catalog'
        
        return {
            'base_url': f"{parsed_url.scheme}://{parsed_url.netloc}",
            'base_path': parsed_url.path,
            'base_product_name': base_product_name,
            'product_id': product_id,
            'catalog_path': catalog_path,
            'query_params': query_params
        }
    except Exception as e:
        print(f"âš ï¸ è§£æäº§å“URLå¤±è´¥: {e}")
        return None

def generate_specification_urls(base_info, specifications):
    """æ ¹æ®åŸºç¡€ä¿¡æ¯å’Œè§„æ ¼ç”Ÿæˆç‰¹å®šçš„äº§å“URL"""
    print("ğŸ”— ç”Ÿæˆè§„æ ¼ä¸“ç”¨é“¾æ¥...")
    
    if not base_info:
        print("âŒ ç¼ºå°‘åŸºç¡€äº§å“ä¿¡æ¯")
        return []
    
    spec_urls = []
    
    for spec in specifications:
        try:
            reference = spec.get('reference', '')
            if not reference:
                continue
            
            # æ„å»ºæŸ¥è¯¢å‚æ•°
            query_params = base_info['query_params'].copy()
            query_params['PartNumber'] = [reference]
            
            # é‡æ–°ç¼–ç æŸ¥è¯¢å­—ç¬¦ä¸²
            query_string = urlencode(query_params, doseq=True)
            
            # æ„å»ºå®Œæ•´URL
            spec_url = f"{base_info['base_url']}{base_info['base_path']}?{query_string}"
            
            spec_url_info = {
                'reference': reference,
                'dimensions': spec.get('dimensions', ''),
                'weight': spec.get('weight', ''),
                'url': spec_url,
                'original_spec_data': spec
            }
            
            spec_urls.append(spec_url_info)
            
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆè§„æ ¼URLæ—¶å‡ºé”™ ({reference}): {e}")
    
    print(f"  âœ… æˆåŠŸç”Ÿæˆ {len(spec_urls)} ä¸ªè§„æ ¼é“¾æ¥")
    return spec_urls

def save_results(base_info, specifications, spec_urls):
    """ä¿å­˜æå–ç»“æœ"""
    timestamp = int(time.time())
    
    # ğŸ¯ æ”¹è¿›çš„JSONæ ¼å¼
    results = {
        'extraction_info': {
            'timestamp': timestamp,
            'extraction_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'base_product_url': PRODUCT_URL,
            'total_specifications_found': len(specifications),
            'total_urls_generated': len(spec_urls)
        },
        'base_product_info': base_info,
        'product_specifications': specifications,
        'specification_urls': spec_urls,
        'summary': {
            'series_distribution': {},
            'specification_samples': []
        }
    }
    
    # åˆ†æäº§å“ç³»åˆ—åˆ†å¸ƒ
    series_stats = {}
    for spec in specifications:
        ref = spec.get('reference', '')
        if ref.startswith('TXCE-'):
            # æå–äº§å“ç³»åˆ—
            series_match = re.match(r'(TXCE-[A-Z0-9]+-[0-9]+-[0-9]+)', ref)
            if series_match:
                series = series_match.group(1)
                if series not in series_stats:
                    series_stats[series] = 0
                series_stats[series] += 1
    
    results['summary']['series_distribution'] = series_stats
    
    # æ·»åŠ è§„æ ¼æ ·æœ¬ï¼ˆå‰10ä¸ªï¼‰
    for i, spec in enumerate(specifications[:10]):
        sample = {
            'index': i + 1,
            'reference': spec.get('reference', ''),
            'dimensions': spec.get('dimensions', ''),
            'weight': spec.get('weight', ''),
            'url': spec_urls[i]['url'] if i < len(spec_urls) else ''
        }
        results['summary']['specification_samples'].append(sample)
    
    # ä¿å­˜è¯¦ç»†JSONç»“æœ
    json_file = RESULTS_DIR / f"product_specs_complete_{timestamp}.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    print(f"ğŸ’¾ å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {json_file}")
    
    # ä¿å­˜ç®€åŒ–çš„è§„æ ¼åˆ—è¡¨JSON
    simple_specs = []
    for i, spec in enumerate(specifications):
        simple_spec = {
            'id': i + 1,
            'reference': spec.get('reference', ''),
            'dimensions': spec.get('dimensions', ''),
            'weight': spec.get('weight', ''),
            'series': '',
            'url': spec_urls[i]['url'] if i < len(spec_urls) else ''
        }
        
        # æå–ç³»åˆ—ä¿¡æ¯
        ref = spec.get('reference', '')
        if ref.startswith('TXCE-'):
            series_match = re.match(r'(TXCE-[A-Z0-9]+-[0-9]+-[0-9]+)', ref)
            if series_match:
                simple_spec['series'] = series_match.group(1)
        
        simple_specs.append(simple_spec)
    
    simple_json_file = RESULTS_DIR / f"specs_list_{timestamp}.json"
    with open(simple_json_file, 'w', encoding='utf-8') as f:
        json.dump({
            'extraction_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'total_count': len(simple_specs),
            'specifications': simple_specs
        }, f, indent=2, ensure_ascii=False)
    print(f"ğŸ“‹ ç®€åŒ–è§„æ ¼åˆ—è¡¨å·²ä¿å­˜åˆ°: {simple_json_file}")
    
    # ä¿å­˜ç®€åŒ–çš„URLåˆ—è¡¨
    urls_file = RESULTS_DIR / f"spec_urls_{timestamp}.txt"
    with open(urls_file, 'w', encoding='utf-8') as f:
        f.write(f"# äº§å“è§„æ ¼é“¾æ¥åˆ—è¡¨\n")
        f.write(f"# åŸºç¡€äº§å“: {PRODUCT_URL}\n")
        f.write(f"# ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"# æ‰¾åˆ° {len(spec_urls)} ä¸ªè§„æ ¼\n\n")
        
        for spec_url_info in spec_urls:
            f.write(f"# {spec_url_info['reference']} ({spec_url_info['dimensions']})\n")
            f.write(f"{spec_url_info['url']}\n\n")
    
    print(f"ğŸ“„ URLåˆ—è¡¨å·²ä¿å­˜åˆ°: {urls_file}")
    
    # è¾“å‡ºç»“æœæ‘˜è¦
    print("\n" + "="*80)
    print("ğŸ“‹ æå–ç»“æœæ‘˜è¦")
    print("="*80)
    print(f"åŸºç¡€äº§å“URL: {PRODUCT_URL}")
    print(f"æ‰¾åˆ°è§„æ ¼æ•°é‡: {len(specifications)}")
    print(f"ç”Ÿæˆé“¾æ¥æ•°é‡: {len(spec_urls)}")
    
    if series_stats:
        print(f"\nğŸ“Š äº§å“ç³»åˆ—åˆ†å¸ƒ:")
        for series, count in sorted(series_stats.items()):
            print(f"  {series}: {count} ä¸ªè§„æ ¼")
    
    print("\nğŸ”— è§„æ ¼é“¾æ¥åˆ—è¡¨ (æ˜¾ç¤ºå‰10ä¸ª):")
    for i, spec_url_info in enumerate(spec_urls[:10], 1):
        print(f"{i:2d}. {spec_url_info['reference']} ({spec_url_info['dimensions']})")
        print(f"    {spec_url_info['url']}")
    if len(spec_urls) > 10:
        print(f"... è¿˜æœ‰ {len(spec_urls) - 10} ä¸ªé“¾æ¥")
    
    print(f"\nğŸ’¾ æ–‡ä»¶è¾“å‡º:")
    print(f"  ğŸ“‹ å®Œæ•´JSON: {json_file.name}")
    print(f"  ğŸ“‹ ç®€åŒ–JSON: {simple_json_file.name}")
    print(f"  ğŸ“„ URLåˆ—è¡¨: {urls_file.name}")
    print("="*80)

def main():
    print("ğŸ¯ äº§å“è§„æ ¼é“¾æ¥æå–å™¨ (é‡æ–°è®¾è®¡ç‰ˆ)")
    print(f"ğŸ“ ç›®æ ‡äº§å“: {PRODUCT_URL}")
    print("ğŸ”„ ç­–ç•¥: ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®ï¼Œæ— ç¿»é¡µ")
    
    if not SELENIUM_AVAILABLE:
        print("âŒ Selenium æœªå®‰è£…ï¼Œæ— æ³•è¿è¡Œï¼")
        return False
    
    # æå–åŸºç¡€äº§å“ä¿¡æ¯
    base_info = extract_base_product_info(PRODUCT_URL)
    if not base_info:
        print("âŒ æ— æ³•è§£æåŸºç¡€äº§å“ä¿¡æ¯")
        return False
    
    print(f"ğŸ“¦ äº§å“ID: {base_info['product_id']}")
    
    driver = prepare_driver()
    
    try:
        # è®¿é—®äº§å“é¡µé¢
        print(f"ğŸŒ è®¿é—®äº§å“é¡µé¢...")
        driver.get(PRODUCT_URL)
        time.sleep(3)
        
        # æˆªå›¾ä¿å­˜åˆå§‹çŠ¶æ€
        screenshot_path = RESULTS_DIR / f"initial_page_{int(time.time())}.png"
        driver.save_screenshot(str(screenshot_path))
        print(f"ğŸ“¸ åˆå§‹é¡µé¢æˆªå›¾: {screenshot_path}")
        
        # å°è¯•è®¾ç½®æ¯é¡µæ˜¾ç¤ºä¸ºå…¨éƒ¨
        items_per_page_success = set_items_per_page_to_all(driver)
        
        if items_per_page_success:
            print("âœ… æˆåŠŸè®¾ç½®æ˜¾ç¤ºå…¨éƒ¨é¡¹ç›®")
            # å†æ¬¡æˆªå›¾ç¡®è®¤
            final_screenshot = RESULTS_DIR / f"after_show_all_{int(time.time())}.png"
            driver.save_screenshot(str(final_screenshot))
            print(f"ğŸ“¸ è®¾ç½®åæˆªå›¾: {final_screenshot}")
        else:
            print("âš ï¸ æœªèƒ½è®¾ç½®æ˜¾ç¤ºå…¨éƒ¨ï¼Œå°†å°è¯•æå–å½“å‰é¡µé¢æ•°æ®")
        
        # ç¡®ä¿é¡µé¢å®Œå…¨åŠ è½½
        scroll_page_fully(driver)
        
        # æå–æ‰€æœ‰è§„æ ¼ä¿¡æ¯
        specifications = extract_all_product_specifications(driver)
        
        if not specifications:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•äº§å“è§„æ ¼")
            return False
        
        # ç”Ÿæˆè§„æ ¼URL
        spec_urls = generate_specification_urls(base_info, specifications)
        
        if not spec_urls:
            print("âŒ æœªèƒ½ç”Ÿæˆä»»ä½•è§„æ ¼URL")
            return False
        
        # ä¿å­˜ç»“æœ
        save_results(base_info, specifications, spec_urls)
        
        print("âœ… è§„æ ¼é“¾æ¥æå–å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"âŒ æå–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False
    finally:
        driver.quit()

if __name__ == '__main__':
    success = main()
    print("âœ… test-09-1 æˆåŠŸ" if success else "âŒ test-09-1 å¤±è´¥") 