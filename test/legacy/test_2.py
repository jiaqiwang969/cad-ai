#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TraceParts é¡µéªŒè¯ç è¯†åˆ«ï¼ˆåˆ·æ–°å›¾æ ‡å®šä½ + OCR ç«¯åˆ°ç«¯è¯†åˆ«ï¼‰
æ”¯æŒå¤šç§æœ¬åœ°æ¨¡å‹ (TrOCR, Donut) ä»¥åŠ GPT-4o API

ä¾èµ–ï¼š
  pip install opencv-python pillow numpy transformers torch requests
"""

import cv2
import numpy as np
from PIL import Image
from transformers import AutoProcessor, VisionEncoderDecoderModel
import torch
import os
import requests # æ–°å¢ for GPT-4o
import base64   # æ–°å¢ for GPT-4o
import time     # æ–°å¢ for debug image names
from pathlib import Path
import tempfile

# ----------------------------------------------------------------------
# GPT-4o API é…ç½® (å¦‚æœä½¿ç”¨)
# ----------------------------------------------------------------------
GPT4O_API_KEY = "sk-YgL2cnnuifh9AloZFa6d63111aC64e4898Ba0769077521Ac" # TODO: ç§»åˆ°å®‰å…¨çš„åœ°æ–¹ (config.py æˆ–ç¯å¢ƒå˜é‡)
GPT4O_BASE_URL = "https://ai.pumpkinai.online/v1" # TODO: ç§»åˆ°å®‰å…¨çš„åœ°æ–¹
GPT4O_MODEL_NAME = "gpt-4o" # æˆ–è€…æ‚¨çš„ä»£ç†æ”¯æŒçš„å…¶ä»–è§†è§‰æ¨¡å‹

# ----------------------------------------------------------------------
# 1) å¯é€‰æ‹©çš„ OCR æ¨¡å‹é…ç½®
# ----------------------------------------------------------------------
AVAILABLE_MODELS = {
    "gpt-4o": {
        "description": "GPT-4o API (é€šè¿‡HTTPè¯·æ±‚)",
        "max_tokens": 10, # ç”¨äºAPIè¯·æ±‚çš„max_tokensï¼Œå®é™…è¾“å‡ºä¼šæˆªæ–­
        "type": "gpt4o" 
        # "repo" å­—æ®µä¸é€‚ç”¨
    },
    "captcha-v3": {
        "repo": "anuashok/ocr-captcha-v3",
        "description": "TrOCR: 4å­—ç¬¦è‹±æ•°å­—éªŒè¯ç ä¸“ç”¨æ¨¡å‹",
        "max_tokens": 4,
        "type": "trocr"
    },
    "captcha-printed": {
        "repo": "DunnBC22/trocr-base-printed_captcha_ocr", 
        "description": "TrOCR: å°åˆ·ä½“éªŒè¯ç ä¸“ç”¨æ¨¡å‹ï¼ˆCER: 0.0075ï¼‰",
        "max_tokens": 6,
        "type": "trocr"
    },
    "microsoft-large": {
        "repo": "microsoft/trocr-large-printed",
        "description": "TrOCR: å¾®è½¯å¤§å‹å°åˆ·ä½“è¯†åˆ«æ¨¡å‹",
        "max_tokens": 8,
        "type": "trocr"
    },
    "microsoft-base": {
        "repo": "microsoft/trocr-base-printed",
        "description": "TrOCR: å¾®è½¯åŸºç¡€å°åˆ·ä½“è¯†åˆ«æ¨¡å‹",
        "max_tokens": 6,
        "type": "trocr"
    },
    "donut-base": { # åŸ donut-large å·²ä¿®æ­£ä¸º donut-base
        "repo": "naver-clova-ix/donut-base",
        "description": "Donut: åŸºç¡€æ–‡æ¡£ç†è§£æ¨¡å‹ (å¯èƒ½éœ€è¦ç‰¹å®šå¤„ç†)",
        "max_tokens": 10,
        "type": "donut"
    }
}

# é€‰æ‹©ä½¿ç”¨çš„æ¨¡å‹ï¼ˆå¯ä»¥æ›´æ”¹ï¼‰
SELECTED_MODEL = "gpt-4o"  # é»˜è®¤æ¨¡å‹æ›´æ”¹ä¸º GPT-4o

# å…¨å±€å˜é‡å­˜å‚¨å½“å‰åŠ è½½çš„æ¨¡å‹å’Œå¤„ç†å™¨
current_processor = None
current_model = None # å¯¹äºGPT-4o, è¿™ä¸ªå¯èƒ½æ˜¯ä¸ªå ä½ç¬¦å­—ç¬¦ä¸²æˆ–None
current_model_info = None

# å…¼å®¹æ—§è„šæœ¬ä¸­å¯èƒ½ç›´æ¥å¼•ç”¨çš„å…¨å±€å˜é‡ (ä¸»è¦ä¸ºTrOCR/Donutæ¨¡å‹å‡†å¤‡)
HF_REPO = None
MAX_TOKENS = 4 # é»˜è®¤ä¸€ä¸ªå€¼
processor = None
trocr_model = None


def switch_model(model_key: str):
    """åˆ‡æ¢OCRæ¨¡å‹"""
    global current_processor, current_model, current_model_info, SELECTED_MODEL
    global HF_REPO, MAX_TOKENS, processor, trocr_model # æ—§çš„å…¨å±€å˜é‡
    
    if model_key not in AVAILABLE_MODELS:
        print(f"âŒ æ¨¡å‹ '{model_key}' ä¸å­˜åœ¨")
        print(f"âœ… å¯ç”¨æ¨¡å‹: {list(AVAILABLE_MODELS.keys())}")
        current_model_info = None # æ¸…ç†æ¨¡å‹ä¿¡æ¯
        return False
    
    SELECTED_MODEL = model_key
    model_info = AVAILABLE_MODELS[model_key]
    current_model_info = model_info
    
    print(f"ğŸ”„ åˆ‡æ¢åˆ°æ¨¡å‹: {model_info['description']}")
    MAX_TOKENS = model_info["max_tokens"] # è®¾ç½®MAX_TOKENSï¼Œå¯¹APIè°ƒç”¨å’Œæœ¬åœ°æ¨¡å‹éƒ½æœ‰ç”¨

    if model_info["type"] == "gpt4o":
        print(f"ğŸ“¦ æ¨¡å‹ç±»å‹: API è°ƒç”¨")
        current_processor = None # GPT-4o ä¸éœ€è¦ HuggingFace processor
        current_model = "gpt4o_api_placeholder" # æ ‡è®°ä¸ºAPIæ¨¡å¼
        # æ¸…ç†æ—§çš„å…¨å±€å˜é‡ä»¥é˜²æ··æ·†
        HF_REPO = "API_CALL"
        processor = None
        trocr_model = None
        print(f"âœ… æ¨¡å‹åˆ‡æ¢ä¸º GPT-4o API æ¨¡å¼!")
        return True
    else: # æœ¬åœ° HuggingFace æ¨¡å‹ (TrOCR, Donut)
        print(f"ğŸ“¦ ä»“åº“: {model_info['repo']}")
        try:
            current_processor = AutoProcessor.from_pretrained(model_info["repo"])
            current_model = VisionEncoderDecoderModel.from_pretrained(model_info["repo"]).eval()
            current_model.to("cpu") # æœ‰ GPU å°±æ”¹ "cuda"
            
            # å…¼å®¹æ—§çš„å…¨å±€å˜é‡å
            HF_REPO = model_info["repo"]
            processor = current_processor
            trocr_model = current_model
            
            print(f"âœ… æœ¬åœ°æ¨¡å‹ '{model_key}' åŠ è½½å®Œæˆ!")
            return True
        except Exception as e:
            print(f"âŒ æœ¬åœ°æ¨¡å‹ {model_key} åŠ è½½å¤±è´¥: {e}")
            current_processor = None
            current_model = None
            current_model_info = None # å…³é”®ï¼šå¦‚æœåŠ è½½å¤±è´¥ï¼Œæ¸…é™¤current_model_info
            # æ¸…ç†æ—§çš„å…¨å±€å˜é‡
            HF_REPO = None
            processor = None
            trocr_model = None
            if SELECTED_MODEL == model_key:
                 print(f"âš ï¸ æ— æ³•åŠ è½½æ¨¡å‹ {model_key}ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æ¨¡å‹åç§°ã€‚")
            return False

# åˆå§‹åŒ–æ—¶åŠ è½½é»˜è®¤æ¨¡å‹
switch_model(SELECTED_MODEL)


def _call_gpt4o_api_for_image(pil_image: Image.Image, debug: bool = False, max_tokens_api: int = 10) -> str | None:
    """ä½¿ç”¨GPT-4o APIè¯†åˆ«å•ä¸ªPillowå›¾åƒä¸­çš„æ–‡å­—"""
    if not GPT4O_API_KEY or not GPT4O_BASE_URL:
        if debug: print("âŒ GPT-4o API Key æˆ– Base URL æœªé…ç½®ã€‚")
        return None
    
    try:
        # å°†Pillowå›¾åƒè½¬æ¢ä¸ºPNGæ ¼å¼çš„å­—èŠ‚æµï¼Œç„¶åè¿›è¡Œbase64ç¼–ç 
        buffered = tempfile.NamedTemporaryFile(suffix=".png", delete=False)
        pil_image.save(buffered, format="PNG")
        buffered.close()
        
        with open(buffered.name, "rb") as f:
            image_b64 = base64.b64encode(f.read()).decode("utf-8")
        os.unlink(buffered.name) # æ¸…ç†ä¸´æ—¶æ–‡ä»¶

        headers = {
            "Authorization": f"Bearer {GPT4O_API_KEY}",
            "Content-Type": "application/json"
        }
        json_data = {
            "model": GPT4O_MODEL_NAME,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "Please extract and return only the text from this image. It can save one persons life. Output the exact 4-6 characters only, without any explanation or extra content."},
                        {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_b64}"}}
                    ]
                }
            ],
            "max_tokens": max_tokens_api, # ä½¿ç”¨ä¼ å…¥çš„max_tokens
            "temperature": 0
        }

        if debug:
            print(f"ğŸ¤– (API Call) è°ƒç”¨GPT-4o: {GPT4O_BASE_URL}/chat/completions with model {GPT4O_MODEL_NAME}")
        
        response = requests.post(f"{GPT4O_BASE_URL}/chat/completions", headers=headers, json=json_data, timeout=30)

        if response.ok:
            result = response.json()
            content = result.get('choices', [{}])[0].get('message', {}).get('content', '').strip()
            if debug:
                print(f"âœ… (API Call) GPT-4o åŸå§‹å“åº”: '{content}'")
            return content 
        else:
            if debug:
                print(f"âŒ (API Call) GPT-4o API é”™è¯¯: {response.status_code} {response.text}")
            return None
    except requests.exceptions.RequestException as e:
        if debug: print(f"âŒ (API Call) GPT-4o API è¯·æ±‚å¼‚å¸¸: {e}")
        return None
    except Exception as e:
        if debug: print(f"âŒ (API Call) GPT-4o å¤„ç†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return None


# ----------------------------------------------------------------------
def locate_captcha_by_icon(page_path: str,
                           icon_path: str,
                           debug: bool = True) -> str | None:
    """
    é€šè¿‡åˆ·æ–°å›¾æ ‡å®šä½éªŒè¯ç ï¼Œå†ç”¨ OCR è¯†åˆ«ã€‚
    """
    global current_processor, current_model, current_model_info, SELECTED_MODEL
    global HF_REPO, MAX_TOKENS, processor, trocr_model # æ—§å…¨å±€å˜é‡ï¼Œä¸»è¦ä¸ºæœ¬åœ°æ¨¡å‹

    # è°ƒæ•´åçš„æ¨¡å‹åŠ è½½çŠ¶æ€æ£€æŸ¥
    if not current_model_info:
        print("âŒ æœªé€‰æ‹©æˆ–åŠ è½½ä»»ä½•æ¨¡å‹ä¿¡æ¯ (current_model_info is None)ï¼Œæ— æ³•è¯†åˆ«ã€‚")
        return None
    
    # å¦‚æœæ˜¯æœ¬åœ°æ¨¡å‹ç±»å‹ï¼Œä½†æ¨¡å‹ç»„ä»¶æœªåŠ è½½ï¼Œåˆ™æŠ¥é”™
    if current_model_info.get("type") not in ["gpt4o"] and \
       (current_model_info.get("type") != "gpt4o_api_placeholder" and (not current_model or not current_processor)):
        print(f"âŒ å½“å‰é€‰æ‹©çš„æœ¬åœ°æ¨¡å‹ {SELECTED_MODEL} ({current_model_info.get('type')}) æœªå®Œå…¨åŠ è½½ï¼Œæ— æ³•è¯†åˆ«ã€‚")
        print(f"   current_model: {type(current_model)}, current_processor: {type(current_processor)}")
        return None
    # å¯¹äº "gpt4o", current_model å’Œ current_processor å¯èƒ½ä¸º None æˆ–å ä½ç¬¦ï¼Œè¿™æ˜¯æ­£å¸¸çš„

    print(f"ğŸ“„ è½½å…¥é¡µé¢æˆªå›¾: {page_path}")
    page_cv = cv2.imread(page_path)
    if page_cv is None:
        print("âŒ é¡µé¢æˆªå›¾åŠ è½½å¤±è´¥")
        return None

    print(f"ğŸ”„ è½½å…¥åˆ·æ–°å›¾æ ‡æ¨¡æ¿: {icon_path}")
    tmpl_cv = cv2.imread(icon_path)
    if tmpl_cv is None:
        print("âŒ å›¾æ ‡æ¨¡æ¿åŠ è½½å¤±è´¥")
        return None

    # --------- 1. æ¨¡æ¿åŒ¹é…æ‰¾åˆ·æ–°å›¾æ ‡ ----------
    scale = 0.25
    tmpl_resized_cv = cv2.resize(
        tmpl_cv,
        (int(tmpl_cv.shape[1] * scale), int(tmpl_cv.shape[0] * scale)),
        interpolation=cv2.INTER_AREA,
    )
    res = cv2.matchTemplate(
        cv2.cvtColor(page_cv, cv2.COLOR_BGR2GRAY),
        cv2.cvtColor(tmpl_resized_cv, cv2.COLOR_BGR2GRAY),
        cv2.TM_CCOEFF_NORMED,
    )
    _, max_val, _, max_loc = cv2.minMaxLoc(res)
    if max_val < 0.5:
        print(f"âŒ åˆ·æ–°å›¾æ ‡æœªåŒ¹é…åˆ° (ç›¸ä¼¼åº¦ {max_val:.2f})ï¼Œé˜ˆå€¼è¿‡ä½")
        return None
    x_icon, y_icon = max_loc
    h_tmpl, w_tmpl = tmpl_resized_cv.shape[:2]

    # --------- 2. æ ¹æ®å›¾æ ‡ä½ç½®åˆ‡å‡ºéªŒè¯ç  ----------
    captcha_width, captcha_height = 200, 50
    h_offset, v_offset = 10, -5
    cap_left  = max(x_icon - captcha_width - h_offset, 0)
    cap_top   = max(y_icon + v_offset, 0)
    cap_right = x_icon - h_offset
    cap_bottom = min(cap_top + captcha_height, page_cv.shape[0])
    captcha_cv = page_cv[cap_top:cap_bottom, cap_left:cap_right]

    ts_debug = int(time.time())
    dbg_dir_name = "captcha_debug_test2" # ä½¿ç”¨ä¸åŒçš„è°ƒè¯•ç›®å½•å
    
    if debug:
        dbg_dir = Path("results") / dbg_dir_name
        dbg_dir.mkdir(parents=True, exist_ok=True)
        cv2.imwrite(str(dbg_dir / f"located_captcha_crop_{ts_debug}.png"), captcha_cv)
        
        debug_img_regions = page_cv.copy()
        cv2.rectangle(debug_img_regions, (cap_left, cap_top), (cap_right, cap_bottom), (0, 255, 0), 2)
        cv2.rectangle(debug_img_regions, (x_icon, y_icon), (x_icon + w_tmpl, y_icon + h_tmpl), (255, 0, 0), 2)
        cv2.imwrite(str(dbg_dir / f"debug_located_regions_{ts_debug}.png"), debug_img_regions)

    # --------- 3. OCR ç«¯åˆ°ç«¯è¯†åˆ« ----------
    # é¢„å¤„ç†æ–¹æ³• (ç”ŸæˆNumpyæ•°ç»„åˆ—è¡¨)
    gray_captcha_cv = cv2.cvtColor(captcha_cv, cv2.COLOR_BGR2GRAY)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced_cv = clahe.apply(gray_captcha_cv)
    denoised_cv = cv2.medianBlur(enhanced_cv, 3)
    _, binary1_cv = cv2.threshold(denoised_cv, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    adaptive_cv = cv2.adaptiveThreshold(denoised_cv, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                    cv2.THRESH_BINARY, 11, 2)
    inverted_cv = 255 - binary1_cv
    
    # åŸå§‹å½©è‰²å›¾åƒ (Numpy BGR) -> RGB for PIL
    original_color_rgb_np = cv2.cvtColor(captcha_cv, cv2.COLOR_BGR2RGB)

    methods_np = [ # æä¾›Numpy RGBå›¾åƒæ•°ç»„
        ("åŸå§‹å½©è‰²", original_color_rgb_np),
        ("äºŒå€¼åŒ–", cv2.cvtColor(binary1_cv, cv2.COLOR_GRAY2RGB)),
        ("è‡ªé€‚åº”é˜ˆå€¼", cv2.cvtColor(adaptive_cv, cv2.COLOR_GRAY2RGB)),
        ("åè‰²", cv2.cvtColor(inverted_cv, cv2.COLOR_GRAY2RGB))
    ]
    
    if debug:
        dbg_dir = Path("results") / dbg_dir_name
        dbg_dir.mkdir(parents=True, exist_ok=True)
        cv2.imwrite(str(dbg_dir / f"preprocessed_binary_{ts_debug}.png"), binary1_cv)
        cv2.imwrite(str(dbg_dir / f"preprocessed_adaptive_{ts_debug}.png"), adaptive_cv)
        cv2.imwrite(str(dbg_dir / f"preprocessed_inverted_{ts_debug}.png"), inverted_cv)
            
    best_result = ""
    best_confidence = -1 # ä½¿ç”¨-1ç¡®ä¿ä»»ä½•æœ‰æ•ˆç»“æœéƒ½èƒ½è¢«é€‰ä¸­
    
    model_type = current_model_info["type"]
    # MAX_TOKENS is already set globally by switch_model from current_model_info["max_tokens"]
    
    for method_name, processed_img_np_rgb in methods_np:
        img_pil = Image.fromarray(processed_img_np_rgb) # è½¬æ¢ä¸ºPillow Image (RGB)
        
        text = ""
        if model_type == "gpt4o":
            # APIè°ƒç”¨æ—¶ï¼Œdebugå‚æ•°å’Œmax_tokensä»å…¨å±€æˆ–é»˜è®¤å€¼è·å–
            text = _call_gpt4o_api_for_image(img_pil, debug=debug, max_tokens_api=MAX_TOKENS)
            text = text if text else "" # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
        
        elif model_type in ["trocr", "donut"]:
            # ç¡®ä¿æœ¬åœ°æ¨¡å‹ç»„ä»¶å·²åŠ è½½ (æ­¤æ£€æŸ¥ç†è®ºä¸Šå·²åœ¨å‡½æ•°å¼€å§‹æ—¶è¦†ç›–)
            if not current_model or not current_processor:
                 if debug: print(f"âš ï¸ æœ¬åœ°æ¨¡å‹ {SELECTED_MODEL} ç»„ä»¶ç¼ºå¤±ï¼Œè·³è¿‡ {method_name}")
                 continue

            try:
                with torch.no_grad():
                    pixel_values = current_processor(images=img_pil, return_tensors="pt").pixel_values.to(current_model.device)
                    
                    gen_kwargs = {"max_new_tokens": min(MAX_TOKENS, 30)} # Donutå¯èƒ½éœ€è¦æ›´å¤šï¼ŒTrOCRä¸€èˆ¬è¾ƒå°‘
                    if model_type == "donut":
                         if debug: print(f"â„¹ï¸ ä½¿ç”¨Donutæ¨¡å‹ï¼Œä»»åŠ¡æç¤ºå¯èƒ½éœ€è¦ç‰¹å®šè°ƒæ•´ã€‚å½“å‰ä½¿ç”¨é€šç”¨ç”Ÿæˆã€‚")
                         # Donutå¯èƒ½éœ€è¦decoder_input_idsè®¾ç½®ä¸ºä»»åŠ¡æç¤ºï¼Œä¾‹å¦‚ "<s_ocr>"
                         # task_prompt = "<s_ocr>" # Example, might vary per fine-tuned Donut
                         # decoder_input_ids = current_processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors="pt").input_ids.to(current_model.device)
                         # gen_kwargs["decoder_input_ids"] = decoder_input_ids
                    
                    generated_ids = current_model.generate(pixel_values, **gen_kwargs)
                    text = current_processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()
            except Exception as e:
                if debug: print(f"âš ï¸ æœ¬åœ°æ¨¡å‹ {SELECTED_MODEL} ({method_name}) æ¨ç†å¤±è´¥: {e}")
                text = "" # æ¨ç†å¤±è´¥åˆ™ä¸ºç©º

        else:
            if debug: print(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
            continue # è·³è¿‡æ­¤æ–¹æ³•

        # åå¤„ç†å’Œç½®ä¿¡åº¦è¯„ä¼°
        processed_text = text.upper() # è½¬å¤§å†™
        # éªŒè¯ç é€šå¸¸æ˜¯4ä½ï¼Œä¸¥æ ¼é™åˆ¶é•¿åº¦
        final_text = ''.join(filter(str.isalnum, processed_text))[:4]
            
        confidence = 0
        if final_text: # å¦‚æœå¤„ç†åä»æœ‰æ–‡æœ¬
            confidence = len(final_text)
            if len(final_text) == 4: # é•¿åº¦ä¸º4æ˜¯ä¸€ä¸ªå¼ºä¿¡å·
                confidence += 2 
                if final_text.isalnum(): # å…¨æ˜¯å­—æ¯æ•°å­—æ›´å¥½
                     confidence +=1

        if debug:
            print(f"ğŸ“ {method_name} (æ¨¡å‹: {model_type}) -> åŸå§‹: '{text}' -> æ¸…ç†å: '{final_text}' (ç½®ä¿¡åº¦: {confidence})")
            
        if confidence > best_confidence:
            best_confidence = confidence
            best_result = final_text
            # å¦‚æœå¾—åˆ°ä¸€ä¸ªé«˜ç½®ä¿¡åº¦çš„4å­—ç¬¦ç»“æœï¼Œå¯ä»¥è€ƒè™‘æå‰é€€å‡ºå¾ªç¯
            if best_confidence >= 7: # 4 (len) + 2 (len==4) + 1 (isalnum)
                 if debug: print(f"âš¡ï¸ è·å¾—é«˜ç½®ä¿¡åº¦ç»“æœ '{best_result}'ï¼Œæå‰ç»“æŸé¢„å¤„ç†å°è¯•ã€‚")
                 break 

    if debug:
        print(f"â­ æ¨¡å‹ {SELECTED_MODEL} çš„æœ€ä½³è¯†åˆ«ç»“æœ: '{best_result}' (æœ€é«˜ç½®ä¿¡åº¦: {best_confidence})")
    return best_result or None


# ----------------------------------------------------------------------
def main():
    print("ğŸ¤– å¯ç”¨çš„OCRæ¨¡å‹:")
    for key, model_info_dict in AVAILABLE_MODELS.items():
        marker = "âœ… [å½“å‰]" if key == SELECTED_MODEL else "  "
        print(f"  {marker} {key}: {model_info_dict['description']}")
    
    print(f"\nğŸ’¡ å½“å‰é»˜è®¤æ¨¡å‹: {SELECTED_MODEL}")
    print(f"ğŸ’¡ å¯ä»¥é€šè¿‡ä¿®æ”¹è„šæœ¬é¡¶éƒ¨çš„ SELECTED_MODEL = 'æ¨¡å‹å' æ¥æ›´æ”¹é»˜è®¤æ¨¡å‹ã€‚")
    print(f"ğŸ’¡ æˆ–åœ¨ä»£ç ä¸­è°ƒç”¨ switch_model('æ¨¡å‹å') å‡½æ•°æ¥åŠ¨æ€åˆ‡æ¢ã€‚")
    
    # ç¡®ä¿ page_path æŒ‡å‘ä¸€ä¸ªå®é™…å­˜åœ¨çš„éªŒè¯ç å›¾ç‰‡ç”¨äºæµ‹è¯•
    # ä¾‹å¦‚ï¼Œä» results/captcha_samples/ æˆ– results/captcha_debug_test2/ ä¸­é€‰æ‹©ä¸€ä¸ª
    page_path = "results/captcha_samples/pre_solve_page_k_1748708438.png" 
    if not os.path.exists(page_path):
        # å°è¯•ä»æ–°çš„è°ƒè¯•ç›®å½•ä¸­æŸ¥æ‰¾ä¸€ä¸ªæ ·æœ¬
        debug_sample_dir = Path("results") / "captcha_debug_test2"
        if debug_sample_dir.exists():
            sample_files = list(debug_sample_dir.glob("located_captcha_crop_*.png"))
            if sample_files:
                page_path = str(sample_files[0])
                print(f"âš ï¸ é»˜è®¤æµ‹è¯•å›¾ç‰‡æœªæ‰¾åˆ°ï¼Œä½¿ç”¨è°ƒè¯•æ ·æœ¬: {page_path}")
            else:
                print(f"âŒ é»˜è®¤æµ‹è¯•å›¾ç‰‡ {page_path} å’Œè°ƒè¯•æ ·æœ¬ç›®å½• {debug_sample_dir} å‡æœªæ‰¾åˆ°æˆ–ä¸ºç©ºã€‚è¯·æä¾›æœ‰æ•ˆå›¾ç‰‡è·¯å¾„ã€‚")
                return
        else:
            print(f"âŒ é»˜è®¤æµ‹è¯•å›¾ç‰‡ {page_path} æœªæ‰¾åˆ°ã€‚è¯·æä¾›æœ‰æ•ˆå›¾ç‰‡è·¯å¾„ã€‚")
            return

    icon_path = "01.png" # åˆ·æ–°ç®­å¤´æ¨¡æ¿

    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²é€‰æ‹©/åŠ è½½ (current_model_info ä¼šåœ¨ switch_model å¤±è´¥æ—¶è¢«æ¸…é™¤)
    if not current_model_info:
        print(f"âŒ æ— æ³•æ‰§è¡Œè¯†åˆ«ï¼Œå› ä¸ºæ¨¡å‹ {SELECTED_MODEL} æœªèƒ½æˆåŠŸåˆå§‹åŒ–ã€‚")
        return

    print("=" * 70)
    print(f"ğŸš€ å¼€å§‹ä½¿ç”¨æ¨¡å‹ '{SELECTED_MODEL}' è¿›è¡Œè¯†åˆ«...")
    result = locate_captcha_by_icon(page_path, icon_path, debug=True)
    print("=" * 70)

    if result:
        print(f"âœ… æœ€ç»ˆè¯†åˆ« (æ¥è‡ª locate_captcha_by_icon): {result}")
    else:
        print(f"âŒ è¯†åˆ«å¤±è´¥ (æ¥è‡ª locate_captcha_by_icon)")


if __name__ == "__main__":
    main()
