#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰‹åŠ¨æ£€æŸ¥é¡µé¢å†…å®¹
"""

import requests
import re

def manual_check():
    """æ‰‹åŠ¨æ£€æŸ¥é¡µé¢å†…å®¹"""
    
    test_url = "https://www.traceparts.cn/en/search/traceparts-classification-mechanical-components-bearings-bearing-blocks-pillow-block-bearings?CatalogPath=TRACEPARTS%3ATP01002002003&PageSize=100"
    
    print("ğŸ” æ‰‹åŠ¨æ£€æŸ¥é¡µé¢å†…å®¹...")
    print(f"ğŸ“ URL: {test_url}")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    try:
        print("\nğŸ“¡ ä½¿ç”¨requestsè·å–é¡µé¢...")
        response = requests.get(test_url, headers=headers, timeout=15)
        response.raise_for_status()
        
        page_text = response.text
        print(f"ğŸ“„ é¡µé¢å¤§å°: {len(page_text)} å­—ç¬¦")
        
        # æ£€æŸ¥å…³é”®æ¨¡å¼
        print("\nğŸ” æ£€æŸ¥å…³é”®æ¨¡å¼:")
        
        # 1. æ£€æŸ¥æ•°å­—+results
        results_matches = re.findall(r'\b\d{1,3}(?:,\d{3})*\s+results?\b|\b\d{4,}\s+results?\b', page_text, re.IGNORECASE)
        print(f"   â€¢ æ•°å­—+results åŒ¹é…: {results_matches}")
        
        # 2. æ£€æŸ¥Producté“¾æ¥
        product_count = page_text.count('&Product=')
        print(f"   â€¢ Producté“¾æ¥æ•°é‡: {product_count}")
        
        # 3. æ£€æŸ¥Sort by
        has_sort_by = 'Sort by' in page_text
        print(f"   â€¢ Sort by: {has_sort_by}")
        
        # 4. æŸ¥æ‰¾ä¸€äº›å…³é”®å­—æ®µ
        print(f"\nğŸ“Š å…³é”®å­—æ®µæ£€æŸ¥:")
        print(f"   â€¢ 'results' å‡ºç°æ¬¡æ•°: {page_text.lower().count('results')}")
        print(f"   â€¢ 'product' å‡ºç°æ¬¡æ•°: {page_text.lower().count('product')}")
        print(f"   â€¢ '0 results': {'æ˜¯' if '0 results' in page_text.lower() else 'å¦'}")
        
        # 5. æ£€æŸ¥åˆ†ç±»é“¾æ¥
        classification_links = page_text.count('traceparts-classification-')
        print(f"   â€¢ åˆ†ç±»é“¾æ¥æ•°é‡: {classification_links}")
        
        # 6. æŸ¥æ‰¾åˆ†ç±»é“¾æ¥ç‰‡æ®µ
        if classification_links > 0:
            print(f"\nğŸ“ åˆ†ç±»é“¾æ¥ç‰‡æ®µ:")
            classification_matches = re.findall(r'href="[^"]*traceparts-classification-[^"]*"', page_text)
            for i, match in enumerate(classification_matches[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"   {i+1}: {match}")
        
        # 7. æŸ¥çœ‹é¡µé¢ç‰‡æ®µ
        if 'results' in page_text.lower():
            print(f"\nğŸ“ åŒ…å«'results'çš„ç‰‡æ®µ:")
            lines = page_text.split('\n')
            for i, line in enumerate(lines):
                if 'results' in line.lower():
                    print(f"   è¡Œ{i}: {line.strip()[:100]}...")
                    if i > 3:  # åªæ˜¾ç¤ºå‰å‡ ä¸ª
                        break
        
        # æœ€ç»ˆåˆ¤æ–­
        has_numbered_results = bool(results_matches) and not re.search(r'\b0\s+results?\b', page_text, re.IGNORECASE)
        has_product_links = product_count > 0
        is_leaf = has_numbered_results or has_product_links
        
        print(f"\nğŸ“Š æœ€ç»ˆåˆ¤æ–­:")
        print(f"   â€¢ æœ‰æ•ˆæ•°å­—ç»“æœ: {has_numbered_results}")
        print(f"   â€¢ æœ‰äº§å“é“¾æ¥: {has_product_links}")
        print(f"   â€¢ æ˜¯å¶èŠ‚ç‚¹: {'âœ… æ˜¯' if is_leaf else 'âŒ å¦'}")
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")

if __name__ == "__main__":
    manual_check()