#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ä¸¤é˜¶æ®µåˆ†ç¦»çš„ç®¡é“
===============
é˜¶æ®µ1ï¼šä½¿ç”¨ç®€å•Seleniumæ–¹æ³•æ„å»ºåˆ†ç±»æ ‘ï¼ˆtest-06é£æ ¼ï¼‰
é˜¶æ®µ2ï¼šä½¿ç”¨é«˜çº§Playwrightç­–ç•¥æå–äº§å“ï¼ˆtest-08é£æ ¼ï¼‰
"""

import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from src.crawler.classification_enhanced import EnhancedClassificationCrawler
from src.crawler.ultimate_products_v2 import UltimateProductLinksCrawlerV2

def test_classification_stage():
    """æµ‹è¯•é˜¶æ®µ1ï¼šåˆ†ç±»æ ‘æ„å»ºï¼ˆtest-06é£æ ¼ï¼‰"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•é˜¶æ®µ1ï¼šåˆ†ç±»æ ‘æ„å»ºï¼ˆç®€å•Seleniumæ–¹æ³•ï¼‰")
    
    try:
        # åˆ›å»ºåˆ†ç±»çˆ¬å–å™¨
        classifier = EnhancedClassificationCrawler(headless=True)
        
        # æ„å»ºåˆ†ç±»æ ‘
        tree, leaves = classifier.crawl_full_tree_enhanced()
        
        if tree and leaves:
            print(f"âœ… é˜¶æ®µ1æˆåŠŸï¼šæ„å»ºäº†åˆ†ç±»æ ‘ï¼Œå…± {len(leaves)} ä¸ªå¶èŠ‚ç‚¹")
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªå¶èŠ‚ç‚¹
            print("ğŸ“ å‰5ä¸ªå¶èŠ‚ç‚¹:")
            for i, leaf in enumerate(leaves[:5]):
                print(f"   {i+1}. {leaf['name']} (L{leaf['level']}) - {leaf['url'][:80]}...")
            
            return leaves[:3]  # è¿”å›å‰3ä¸ªå¶èŠ‚ç‚¹ç”¨äºæµ‹è¯•é˜¶æ®µ2
        else:
            print("âŒ é˜¶æ®µ1å¤±è´¥ï¼šæœªèƒ½æ„å»ºåˆ†ç±»æ ‘")
            return []
            
    except Exception as e:
        print(f"âŒ é˜¶æ®µ1å¼‚å¸¸: {e}")
        return []

def test_products_stage(test_leaves):
    """æµ‹è¯•é˜¶æ®µ2ï¼šäº§å“æå–ï¼ˆtest-08é£æ ¼ï¼‰"""
    print("\nğŸš€ å¼€å§‹æµ‹è¯•é˜¶æ®µ2ï¼šäº§å“æå–ï¼ˆé«˜çº§Playwrightç­–ç•¥ï¼‰")
    
    if not test_leaves:
        print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„å¶èŠ‚ç‚¹è¿›è¡Œæµ‹è¯•")
        return
    
    try:
        # åˆ›å»ºäº§å“çˆ¬å–å™¨
        products_crawler = UltimateProductLinksCrawlerV2(headless=True)
        
        for i, leaf in enumerate(test_leaves):
            print(f"\nğŸ“¦ æµ‹è¯•å¶èŠ‚ç‚¹ {i+1}: {leaf['name']}")
            
            try:
                # æå–äº§å“é“¾æ¥
                products, progress_info = products_crawler.collect_all_product_links(leaf['url'])
                
                if products:
                    print(f"âœ… æˆåŠŸæå– {len(products)} ä¸ªäº§å“")
                    print(f"ğŸ“Š è¿›åº¦ä¿¡æ¯: {progress_info}")
                    
                    # æ˜¾ç¤ºå‰å‡ ä¸ªäº§å“ï¼ˆå®Œæ•´URLï¼‰
                    print(f"ğŸ”— å‰3ä¸ªäº§å“é“¾æ¥ï¼ˆå®Œæ•´URLï¼‰:")
                    for j, product_url in enumerate(products[:3]):
                        # ä»URLä¸­æå–äº§å“åç§°ï¼ˆç®€åŒ–æ˜¾ç¤ºï¼‰
                        product_name = product_url.split('Product=')[-1].split('&')[0] if 'Product=' in product_url else 'Unknown'
                        print(f"   {j+1}. äº§å“å: {product_name}")
                        print(f"       å®Œæ•´URL: {product_url}")
                        print()
                else:
                    print(f"âš ï¸ æœªæ‰¾åˆ°äº§å“")
                    
            except Exception as e:
                print(f"âŒ å¶èŠ‚ç‚¹ {leaf['name']} äº§å“æå–å¤±è´¥: {e}")
        
        print("\nâœ… é˜¶æ®µ2æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ é˜¶æ®µ2å¼‚å¸¸: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ æµ‹è¯•ä¸¤é˜¶æ®µåˆ†ç¦»çš„ç®¡é“")
    print("=" * 50)
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logging.basicConfig(level=logging.INFO)
    
    # æµ‹è¯•é˜¶æ®µ1ï¼šåˆ†ç±»æ ‘æ„å»º
    test_leaves = test_classification_stage()
    
    # æµ‹è¯•é˜¶æ®µ2ï¼šäº§å“æå–
    test_products_stage(test_leaves)
    
    print("\n" + "=" * 50)
    print("ğŸ ä¸¤é˜¶æ®µåˆ†ç¦»ç®¡é“æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    main()