#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éªŒè¯ç è¯†åˆ«æ¨¡å— - é€šè¿‡åˆ·æ–°å›¾æ ‡å®šä½å¹¶è¯†åˆ«éªŒè¯ç 
æ”¯æŒpytesseract, TrOCRå¤šæ¨¡å‹è¯†åˆ«, ä»¥åŠGPT-4o API
"""

import cv2
import numpy as np
from PIL import Image
import pytesseract
import os
import tempfile
from pathlib import Path
import requests
import base64
import time

# TrOCRç›¸å…³å¯¼å…¥ï¼ˆå¯é€‰ï¼Œå¦‚æœå¯¼å…¥å¤±è´¥åˆ™å›é€€åˆ°pytesseractï¼‰
try:
    import torch
    from transformers import TrOCRProcessor, VisionEncoderDecoderModel
    TROCR_AVAILABLE = True
    print("ğŸ¤– TrOCRæ¨¡å—å·²åŠ è½½")
except ImportError:
    TROCR_AVAILABLE = False
    print("âš ï¸ TrOCRæ¨¡å—æœªå®‰è£…ï¼Œå°†ä½¿ç”¨pytesseract")

# GPT-4o API é…ç½® (ä» test_4o.py è·å–)
GPT4O_API_KEY = "sk-YgL2cnnuifh9AloZFa6d63111aC64e4898Ba0769077521Ac" # TODO: Move to config or env
GPT4O_BASE_URL = "https://ai.pumpkinai.online/v1" # TODO: Move to config or env
GPT4O_MODEL_NAME = "gpt-4o"

# TrOCRæ¨¡å‹é…ç½®
AVAILABLE_MODELS = {
    "captcha-v3": {
        "repo": "anuashok/ocr-captcha-v3",
        "description": "4å­—ç¬¦è‹±æ•°å­—éªŒè¯ç ä¸“ç”¨æ¨¡å‹",
        "max_tokens": 4
    },
    "microsoft-large": {
        "repo": "microsoft/trocr-large-printed",
        "description": "å¾®è½¯å¤§å‹å°åˆ·ä½“è¯†åˆ«æ¨¡å‹",
        "max_tokens": 8
    },
    "microsoft-base": {
        "repo": "microsoft/trocr-base-printed",
        "description": "å¾®è½¯åŸºç¡€å°åˆ·ä½“è¯†åˆ«æ¨¡å‹",
        "max_tokens": 6
    }
}

class CaptchaSolver:
    """éªŒè¯ç è¯†åˆ«å™¨ - æ”¯æŒpytesseract, TrOCRå¤šæ¨¡å‹, å’ŒGPT-4o API"""
    
    def __init__(self, icon_template_path=["01.png", "02.png"], debug=False, 
                 ocr_method="auto", trocr_model="microsoft-large"):
        """
        åˆå§‹åŒ–éªŒè¯ç è¯†åˆ«å™¨
        
        Args:
            icon_template_path: åˆ·æ–°å›¾æ ‡æ¨¡æ¿è·¯å¾„ï¼ˆå¯ä»¥æ˜¯å•ä¸ªè·¯å¾„æˆ–è·¯å¾„åˆ—è¡¨ï¼‰
            debug: æ˜¯å¦å¼€å¯è°ƒè¯•æ¨¡å¼ï¼ˆä¿å­˜ä¸­é—´å›¾ç‰‡ï¼‰
            ocr_method: OCRæ–¹æ³•é€‰æ‹© ("auto", "pytesseract", "trocr", "gpt4o")
            trocr_model: TrOCRæ¨¡å‹é€‰æ‹© (è§AVAILABLE_MODELS)
        """
        # æ”¯æŒå•ä¸ªè·¯å¾„æˆ–è·¯å¾„åˆ—è¡¨
        if isinstance(icon_template_path, str):
            self.icon_template_paths = [icon_template_path]
        else:
            self.icon_template_paths = icon_template_path
        self.debug = debug
        self.icon_templates = []  # å­˜å‚¨å¤šä¸ªæ¨¡æ¿
        
        # OCRæ–¹æ³•é…ç½®
        self.ocr_method = ocr_method
        self.trocr_model_key = trocr_model
        self.processor = None
        self.trocr_model = None
        self.extra_prompt = ""  # é¢å¤–çš„ GPT æç¤ºï¼Œå¯åœ¨è¿è¡Œæ—¶åŠ¨æ€ä¿®æ”¹
        
        # éªŒè¯ç åŒºåŸŸå‚æ•°ï¼ˆç›¸å¯¹äºåˆ·æ–°å›¾æ ‡çš„ä½ç½®ï¼‰
        self.captcha_width = 200
        self.captcha_height = 50
        self.h_offset = 10
        self.v_offset = -5
        
        self._load_icon_template()
        
        if self.ocr_method in ("auto", "trocr"):
            self._init_trocr_model()
    
    def _init_trocr_model(self):
        """åˆå§‹åŒ–TrOCRæ¨¡å‹"""
        if not TROCR_AVAILABLE:
            if self.ocr_method == "trocr" or (self.ocr_method == "auto" and self.debug):
                print("âš ï¸ TrOCRä¸å¯ç”¨ï¼Œæ— æ³•åˆå§‹åŒ–TrOCRæ¨¡å‹ã€‚")
            if self.ocr_method == "trocr": # If explicitly TroCR, it can't work
                 print("âš ï¸ TrOCRæ–¹æ³•æŒ‡å®šä½†æ¨¡å—ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥å®‰è£…æˆ–åˆ‡æ¢æ–¹æ³•ã€‚")
            return
        
        if self.ocr_method in ("auto", "trocr"):
            try:
                if self.trocr_model_key not in AVAILABLE_MODELS:
                    print(f"âŒ TrOCRæ¨¡å‹ '{self.trocr_model_key}' ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹ 'microsoft-large'")
                    self.trocr_model_key = "microsoft-large"
                
                model_info = AVAILABLE_MODELS[self.trocr_model_key]
                repo = model_info["repo"]
                
                if self.debug:
                    print(f"ğŸ¤– åŠ è½½TrOCRæ¨¡å‹: {model_info['description']}")
                    print(f"ğŸ“¦ ä»“åº“: {repo}")
                
                self.processor = TrOCRProcessor.from_pretrained(repo)
                self.trocr_model = VisionEncoderDecoderModel.from_pretrained(repo).eval()
                self.trocr_model.to("cpu")
                
                if self.debug:
                    print("âœ… TrOCRæ¨¡å‹åŠ è½½å®Œæˆ")
                    
            except Exception as e:
                print(f"âŒ TrOCRæ¨¡å‹ '{self.trocr_model_key}' åŠ è½½å¤±è´¥: {e}")
                self.processor = None # Ensure processor is also None on failure
                self.trocr_model = None
                if self.ocr_method == "trocr": # If TroCR was explicitly chosen and failed
                    print("âš ï¸ TrOCRè¯†åˆ«å°†ä¸å¯ç”¨ã€‚")
    
    def switch_trocr_model(self, model_key):
        """åˆ‡æ¢TrOCRæ¨¡å‹"""
        if not TROCR_AVAILABLE:
            print("âš ï¸ TrOCRæ¨¡å—ä¸å¯ç”¨ï¼Œæ— æ³•åˆ‡æ¢æ¨¡å‹ã€‚")
            return False
        
        if model_key not in AVAILABLE_MODELS:
            print(f"âŒ æ¨¡å‹ '{model_key}' ä¸å­˜åœ¨")
            print(f"âœ… å¯ç”¨æ¨¡å‹: {list(AVAILABLE_MODELS.keys())}")
            return False
        
        self.trocr_model_key = model_key
        self._init_trocr_model() # Re-initialize with the new key
        return True if self.trocr_model and self.processor else False

    def _load_icon_template(self):
        """åŠ è½½å¹¶ç¼©æ”¾åˆ·æ–°å›¾æ ‡æ¨¡æ¿"""
        self.icon_templates = []
        loaded_count = 0
        
        for template_path in self.icon_template_paths:
            if os.path.exists(template_path):
                tmpl = cv2.imread(template_path)
                if tmpl is not None:
                    scale_factor = 0.25
                    new_width = int(tmpl.shape[1] * scale_factor)
                    new_height = int(tmpl.shape[0] * scale_factor)
                    scaled_template = cv2.resize(tmpl, (new_width, new_height), 
                                               interpolation=cv2.INTER_AREA)
                    self.icon_templates.append({
                        'template': scaled_template,
                        'path': template_path,
                        'size': (new_width, new_height)
                    })
                    loaded_count += 1
                    if self.debug:
                        print(f"ğŸ“ å›¾æ ‡æ¨¡æ¿ '{template_path}' ç¼©æ”¾åˆ°: {new_width}x{new_height}")
                else:
                    if self.debug:
                        print(f"âš ï¸ æ— æ³•åŠ è½½å›¾æ ‡æ¨¡æ¿: {template_path}")
            else:
                if self.debug:
                    print(f"âš ï¸ å›¾æ ‡æ¨¡æ¿ä¸å­˜åœ¨: {template_path}")
        
        if loaded_count == 0:
            raise FileNotFoundError(f"æ‰€æœ‰å›¾æ ‡æ¨¡æ¿éƒ½æ— æ³•åŠ è½½: {self.icon_template_paths}")
        
        if self.debug:
            print(f"âœ…  {loaded_count} ä¸ªå›¾æ ‡æ¨¡æ¿")
    
    def solve_from_screenshot(self, screenshot_path):
        """ä»æˆªå›¾æ–‡ä»¶ä¸­è¯†åˆ«éªŒè¯ç """
        page = cv2.imread(screenshot_path)
        if page is None:
            print(f"âŒ æ— æ³•åŠ è½½æˆªå›¾: {screenshot_path}")
            return None
        return self._solve_from_image(page)
    
    def solve_from_playwright_page(self, page, return_bbox=False):
        """ä»Playwrighté¡µé¢ä¸­è¯†åˆ«éªŒè¯ç """
        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
            tmp_path = tmp.name
        try:
            page.screenshot(path=tmp_path)
            result_data = self.solve_from_screenshot(tmp_path) # This now returns a dict or None
            if return_bbox:
                return result_data # Pass the whole dict
            return result_data["text"] if result_data else None
        finally:
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)
    
    def _solve_from_image(self, image):
        """ä»OpenCVå›¾åƒä¸­è¯†åˆ«éªŒè¯ç """
        original_image_for_debug = image.copy()
        icon_pos = self._locate_refresh_icon(image)
        if icon_pos is None:
            return None
        
        x_icon, y_icon = icon_pos
        
        cap_left = max(x_icon - self.captcha_width - self.h_offset, 0)
        cap_top = max(y_icon + self.v_offset, 0)
        cap_right = x_icon - self.h_offset
        cap_bottom = min(cap_top + self.captcha_height, image.shape[0])
        
        captcha_crop_cv2 = image[cap_top:cap_bottom, cap_left:cap_right]
        
        if self.debug:
            self._save_debug_images(original_image_for_debug,
                                  x_icon, y_icon, 
                                  cap_left, cap_top, cap_right, cap_bottom, 
                                  captcha_crop_cv2)
        
        text = self._ocr_captcha(captcha_crop_cv2) # Pass OpenCV image
        
        # ä½¿ç”¨åŒ¹é…åˆ°çš„æ¨¡æ¿å°ºå¯¸
        if hasattr(self, 'last_matched_template') and self.last_matched_template:
            width, height = self.last_matched_template['size']
        else:
            # å…œåº•ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡æ¿çš„å°ºå¯¸
            width, height = self.icon_templates[0]['size'] if self.icon_templates else (32, 32)
        
        return {
            "text": text,
            "icon_bbox": {"x": x_icon, "y": y_icon, "width": width, "height": height}
        }
    
    def _locate_refresh_icon(self, image):
        """åœ¨å›¾åƒä¸­å®šä½åˆ·æ–°å›¾æ ‡"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        best_match = None
        best_score = 0
        best_template_info = None
        
        # å°è¯•æ‰€æœ‰æ¨¡æ¿ï¼Œæ‰¾åˆ°æœ€ä½³åŒ¹é…
        for template_info in self.icon_templates:
            template = template_info['template']
            template_path = template_info['path']
            
            gray_tmpl = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)
            
            res = cv2.matchTemplate(gray, gray_tmpl, cv2.TM_CCOEFF_NORMED)
            _, max_val, _, max_loc = cv2.minMaxLoc(res)
            
            if self.debug:
                print(f"ğŸ” æ¨¡æ¿ '{template_path}' åŒ¹é…ç›¸ä¼¼åº¦: {max_val:.2f}")
            
            if max_val > best_score:
                best_score = max_val
                best_match = max_loc
                best_template_info = template_info
        
        if best_score < 0.5:
            if self.debug:
                print(f"âŒ æ‰€æœ‰åˆ·æ–°å›¾æ ‡æ¨¡æ¿éƒ½æœªåŒ¹é…åˆ° (æœ€ä½³ç›¸ä¼¼åº¦: {best_score:.2f})")
            return None
        
        if self.debug:
            print(f"âœ… åˆ·æ–°å›¾æ ‡å·²å®šä½ (ä½¿ç”¨æ¨¡æ¿: {best_template_info['path']}), ç›¸ä¼¼åº¦: {best_score:.2f}")
        
        # å­˜å‚¨æœ€ä½³åŒ¹é…çš„æ¨¡æ¿ä¿¡æ¯ï¼Œä¾›è°ƒè¯•ä½¿ç”¨
        self.last_matched_template = best_template_info
        return best_match
    
    def _apply_ocr_corrections(self, text):
        """ä¿æŒåŸå§‹è¯†åˆ«ç»“æœï¼Œä¸åšä»»ä½•å¤„ç†"""
        if not text: 
            return ""
        # åªå»é™¤é¦–å°¾ç©ºæ ¼ï¼Œä¿æŒåŸå§‹å¤§å°å†™å’Œé•¿åº¦
        return text.strip()

    def _ocr_captcha_gpt4o(self, captcha_img_cv2, extra_prompt: str = ""):
        """ä½¿ç”¨GPT-4o APIè¯†åˆ«éªŒè¯ç å›¾åƒ (OpenCVæ ¼å¼è¾“å…¥)"""
        if not GPT4O_API_KEY or not GPT4O_BASE_URL or not GPT4O_MODEL_NAME:
            print("âŒ GPT-4o API Key, Base URL, or Model Name æœªé…ç½®ï¼Œæ— æ³•ä½¿ç”¨GPT-4oè¯†åˆ«")
            return None
        
        try:
            _, buffer = cv2.imencode('.png', captcha_img_cv2)
            image_b64 = base64.b64encode(buffer).decode("utf-8")

            headers = {
                "Authorization": f"Bearer {GPT4O_API_KEY}",
                "Content-Type": "application/json"
            }
            prompt_text = ("Please extract and return only the text from this image. "
                           "Output the exact characters only, without any explanation or extra content.")
            if extra_prompt:
                prompt_text = extra_prompt + " " + prompt_text

            json_data = {
                "model": GPT4O_MODEL_NAME,
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt_text},
                            {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_b64}"}}
                        ]
                    }
                ],
                "max_tokens": 10,
                "temperature": 0
            }

            if self.debug:
                print(f"ğŸ¤– è°ƒç”¨GPT-4o API: {GPT4O_BASE_URL}/chat/completions with model {GPT4O_MODEL_NAME}")
            
            response = requests.post(f"{GPT4O_BASE_URL}/chat/completions", headers=headers, json=json_data, timeout=30)

            if response.ok:
                result = response.json()
                content = result.get('choices', [{}])[0].get('message', {}).get('content', '').strip()
                if self.debug:
                    print(f"âœ… GPT-4o åŸå§‹å“åº”: {content}")
                # Correction is now handled by _apply_ocr_corrections
                return content 
            else:
                if self.debug:
                    print(f"âŒ GPT-4o API é”™è¯¯: {response.status_code} {response.text}")
                return None
        except requests.exceptions.RequestException as e:
            if self.debug:
                print(f"âŒ GPT-4o API è¯·æ±‚å¼‚å¸¸: {e}")
            return None
        except Exception as e:
            if self.debug:
                print(f"âŒ GPT-4o å¤„ç†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            return None

    def _ocr_captcha_trocr(self, captcha_img_pil): # Expects Pillow Image
        """ä½¿ç”¨TrOCRæ¨¡å‹è¯†åˆ«éªŒè¯ç  (Pillow Image è¾“å…¥)"""
        if not TROCR_AVAILABLE or not self.trocr_model or not self.processor:
            if self.debug: print("TrOCRä¸å¯ç”¨æˆ–æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰§è¡ŒTrOCRè¯†åˆ«ã€‚")
            return None
        
        best_result = ""
        best_confidence = -1 
        
        model_max_tokens = AVAILABLE_MODELS.get(self.trocr_model_key, {}).get("max_tokens", 4)

        # Preprocessing similar to test_2.py
        cv_img_for_preprocessing = cv2.cvtColor(np.array(captcha_img_pil), cv2.COLOR_RGB2BGR)
        gray_captcha = cv2.cvtColor(cv_img_for_preprocessing, cv2.COLOR_BGR2GRAY)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(gray_captcha)
        denoised = cv2.medianBlur(enhanced, 3)
        _, binary1 = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        adaptive = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                        cv2.THRESH_BINARY, 11, 2)
        inverted = 255 - binary1

        # Include original color image from PIL input
        methods = [
            ("åŸå§‹å½©è‰²", captcha_img_pil), 
            ("äºŒå€¼åŒ–", Image.fromarray(cv2.cvtColor(binary1, cv2.COLOR_GRAY2RGB))),
            ("è‡ªé€‚åº”é˜ˆå€¼", Image.fromarray(cv2.cvtColor(adaptive, cv2.COLOR_GRAY2RGB))),
            ("åè‰²", Image.fromarray(cv2.cvtColor(inverted, cv2.COLOR_GRAY2RGB)))
        ]
        
        for method_name, processed_img_pil in methods:
            try:
                with torch.no_grad():
                    pixel_values = self.processor(images=processed_img_pil, return_tensors="pt").pixel_values.to(self.trocr_model.device)
                    generated_ids = self.trocr_model.generate(pixel_values, max_new_tokens=min(model_max_tokens, 10)) # Truncate to 10 for safety, will be cut by corrections
                    text = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()
                
                confidence = len(text)
                if len(text) == 4 and text.isalnum(): # Basic confidence
                    confidence += 2
                
                if self.debug:
                    print(f"ğŸ“ TrOCR ({method_name}) è¯†åˆ«ç»“æœ: '{text}' (ç½®ä¿¡åº¦: {confidence})")
                
                if confidence > best_confidence:
                    best_confidence = confidence
                    best_result = text
                    if len(best_result) == 4 and best_result.isalnum(): # Good enough, stop early
                        break 
            except Exception as e:
                if self.debug:
                    print(f"âš ï¸ TrOCR ({method_name}) å¤„ç†å¼‚å¸¸: {e}")
        
        if self.debug:
            print(f"ğŸ“ TrOCR æœ€ä½³è¯†åˆ«: '{best_result}'")
        return best_result if best_result else None

    def _ocr_captcha_pytesseract(self, captcha_img_pil): # Expects Pillow Image
        """ä½¿ç”¨pytesseractè¯†åˆ«éªŒè¯ç  (Pillow Imageè¾“å…¥)"""
        try:
            # Pytesseract often works better with some preprocessing
            gray_pil = captcha_img_pil.convert('L')
            # Optionally, apply thresholding if it helps
            # enhanced_pil = gray_pil.point(lambda x: 0 if x < 128 else 255, '1')
            
            custom_config = r'--oem 3 --psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'
            text = pytesseract.image_to_string(gray_pil, config=custom_config).strip()
            
            if self.debug:
                print(f"ğŸ“ Pytesseract è¯†åˆ«ç»“æœ: '{text}'")
            return text
        except Exception as e:
            if self.debug:
                print(f"âŒ Pytesseract OCR å¤±è´¥: {e}")
            return None

    def _ocr_captcha(self, captcha_img_cv2): # Expects OpenCV image
        """æ ¸å¿ƒOCRè¯†åˆ«é€»è¾‘ï¼Œæ ¹æ®ocr_methodé€‰æ‹©ä¸åŒæ–¹æ³•"""
        # ç»Ÿä¸€ï¼Œåªä½¿ç”¨ GPT-4o
        if self.debug:
            print("å°è¯•ä½¿ç”¨ GPT-4o è¿›è¡Œ OCR è¯†åˆ«...")

        text = self._ocr_captcha_gpt4o(captcha_img_cv2, self.extra_prompt)
        # é‡ç½®é¢å¤–æç¤ºï¼Œé¿å…å½±å“ä¸‹æ¬¡è°ƒç”¨
        self.extra_prompt = ""

        final_text = self._apply_ocr_corrections(text if text else "")

        if self.debug:
            print(f"æœ€ç»ˆ OCR ç»“æœ: '{final_text}'")

        return final_text


    def _save_debug_images(self, original_image, x_icon, y_icon, 
                          cap_left, cap_top, cap_right, cap_bottom, captcha_cv2_crop):
        """ä¿å­˜è°ƒè¯•è¿‡ç¨‹ä¸­çš„å›¾åƒ"""
        dbg_dir = Path("results") / "captcha_debug"
        dbg_dir.mkdir(parents=True, exist_ok=True)
        
        ts = int(time.time()) # Add timestamp to filenames to avoid overwrites

        # 1. ä¿å­˜åŸå§‹æˆªå›¾ (å¦‚æœå°šæœªä¿å­˜æˆ–éœ€è¦æ¯æ¬¡éƒ½ä¿å­˜æ–°ç‰ˆæœ¬)
        cv2.imwrite(str(dbg_dir / f"original_screenshot_for_debug_{ts}.png"), original_image)

        # 2. ä¿å­˜å®šä½å’Œè£å‰ªåŒºåŸŸçš„è°ƒè¯•å›¾
        debug_img_regions = original_image.copy()
        # ç»˜åˆ¶éªŒè¯ç åŒºåŸŸ (ç»¿è‰²)
        cv2.rectangle(debug_img_regions, (cap_left, cap_top), (cap_right, cap_bottom), (0, 255, 0), 2)
        # ç»˜åˆ¶å›¾æ ‡åŒºåŸŸ (è“è‰²)
        if hasattr(self, 'last_matched_template') and self.last_matched_template:
            w_tmpl, h_tmpl = self.last_matched_template['size']
        else:
            # å…œåº•ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡æ¿çš„å°ºå¯¸
            w_tmpl, h_tmpl = self.icon_templates[0]['size'] if self.icon_templates else (32, 32)
        cv2.rectangle(debug_img_regions, (x_icon, y_icon), (x_icon + w_tmpl, y_icon + h_tmpl), (255, 0, 0), 2)
        cv2.imwrite(str(dbg_dir / f"debug_located_regions_{ts}.png"), debug_img_regions)

        # 3. ä¿å­˜è£å‰ªå‡ºçš„éªŒè¯ç æœ¬èº«
        cv2.imwrite(str(dbg_dir / f"located_captcha_crop_{ts}.png"), captcha_cv2_crop)
        
        # 4. (å¯é€‰) ä¿å­˜TrOCRé¢„å¤„ç†åçš„å›¾åƒ (å¯ä»¥åœ¨_ocr_captcha_trocrå†…éƒ¨å®Œæˆ)
        # Example: cv2.imwrite(str(dbg_dir / f"trocr_preprocessed_binary_{ts}.png"), binary_image_from_trocr)

        if self.debug:
            print(f"ğŸ’¾ è°ƒè¯•å›¾ç‰‡å·²ä¿å­˜åˆ°: {dbg_dir.resolve()}")


def solve_captcha_from_screenshot(screenshot_path, icon_path=["01.png", "02.png"], debug=False, 
                                 ocr_method="auto", trocr_model="microsoft-large"):
    solver = CaptchaSolver(icon_template_path=icon_path, debug=debug, 
                           ocr_method=ocr_method, trocr_model=trocr_model)
    return solver.solve_from_screenshot(screenshot_path)

def solve_captcha_from_playwright(page, icon_path=["01.png", "02.png"], debug=False,
                                 ocr_method="auto", trocr_model="microsoft-large"):
    solver = CaptchaSolver(icon_template_path=icon_path, debug=debug, 
                           ocr_method=ocr_method, trocr_model=trocr_model)
    # Ensure this returns the dictionary
    return solver.solve_from_playwright_page(page, return_bbox=True)


def solve_base64_captcha(b64_png, debug=False, ocr_method="auto", trocr_model="microsoft-large"):
    """
    ä»Base64ç¼–ç çš„PNGå›¾åƒå­—ç¬¦ä¸²ä¸­è¯†åˆ«éªŒè¯ç 
    """
    try:
        img_data = base64.b64decode(b64_png)
        with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
            tmp.write(img_data)
            tmp_path = tmp.name
        
        solver = CaptchaSolver(debug=debug, ocr_method=ocr_method, trocr_model=trocr_model)
        # Assuming solve_from_screenshot now returns a dict: {"text": "...", "icon_bbox": ...}
        # For base64, icon_bbox might not be relevant or calculable without full page context.
        # This function might need to be re-thought if icon location is critical from base64.
        # For now, just extract text.
        result_data = solver.solve_from_screenshot(tmp_path)
        return result_data["text"] if result_data else None

    except Exception as e:
        if debug:
            print(f"âŒ Base64è§£ç æˆ–è¯†åˆ«å¤±è´¥: {e}")
        return None
    finally:
        if 'tmp_path' in locals() and os.path.exists(tmp_path):
            os.unlink(tmp_path)

def solve_file(path, debug=False, ocr_method="auto", trocr_model="microsoft-large"):
    """
    ç›´æ¥ä»å›¾åƒæ–‡ä»¶è¯†åˆ«éªŒè¯ç  (æ­¤å‡½æ•°ç°åœ¨æ›´åƒæ˜¯ solve_captcha_from_screenshot çš„åŒ…è£…å™¨)
    """
    solver = CaptchaSolver(debug=debug, ocr_method=ocr_method, trocr_model=trocr_model)
    # Assuming solve_from_screenshot now returns a dict
    result_data = solver.solve_from_screenshot(path)
    return result_data["text"] if result_data else None

# Example Usage (for direct script testing if needed)
if __name__ == '__main__':
    # Create a dummy screenshot for testing
    dummy_image_path = "results/captcha_samples/page_before_format_select_1748699648.png"
    # Ensure the dummy image exists or provide a valid path
    if not os.path.exists(dummy_image_path):
        print(f"æµ‹è¯•å›¾ç‰‡ {dummy_image_path} ä¸å­˜åœ¨ï¼Œè¯·å…ˆå‡†å¤‡ã€‚")
    else:
        print(f"--- æµ‹è¯• CaptchaSolver with GPT-4o (æŒ‡å®š) ---")
        solver_gpt4o = CaptchaSolver(debug=True, ocr_method="gpt4o")
        result_gpt4o = solver_gpt4o.solve_from_screenshot(dummy_image_path)
        print(f"GPT-4o (æŒ‡å®š) ç»“æœ: {result_gpt4o}")

        print(f"\\n--- æµ‹è¯• CaptchaSolver with auto (GPT-4o -> TrOCR -> Pytesseract) ---")
        solver_auto = CaptchaSolver(debug=True, ocr_method="auto", trocr_model="microsoft-base")
        result_auto = solver_auto.solve_from_screenshot(dummy_image_path)
        print(f"Auto ç»“æœ: {result_auto}")

        print(f"\\n--- æµ‹è¯• CaptchaSolver with TrOCR only ---")
        solver_trocr = CaptchaSolver(debug=True, ocr_method="trocr", trocr_model="microsoft-base")
        result_trocr = solver_trocr.solve_from_screenshot(dummy_image_path)
        print(f"TrOCR (æŒ‡å®š) ç»“æœ: {result_trocr}")

        print(f"\\n--- æµ‹è¯• CaptchaSolver with Pytesseract only ---")
        solver_pytesseract = CaptchaSolver(debug=True, ocr_method="pytesseract")
        result_pytesseract = solver_pytesseract.solve_from_screenshot(dummy_image_path)
        print(f"Pytesseract (æŒ‡å®š) ç»“æœ: {result_pytesseract}") 